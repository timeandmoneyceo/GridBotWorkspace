{
  "file_path": "C:\\Users\\805Sk\\GridBotWorkspace\\automated_debugging_strategy\\GridbotBackup.py",
  "timestamp": "20250914_124912",
  "total_candidates": 10,
  "applied_optimizations": 0,
  "success_rate": 0.0,
  "results": [
    {
      "candidate": {
        "function_name": "train_pytorch_predictor",
        "file_path": "C:\\Users\\805Sk\\GridBotWorkspace\\automated_debugging_strategy\\GridbotBackup.py",
        "line_start": 2589,
        "line_end": 2775,
        "code_snippet": "def train_pytorch_predictor(trade_data, ohlcv_data, lookback_minutes=64, num_epochs=config.PYTORCH_NUM_EPOCHS):  # Align with PYTORCH_LOOKBACK\n    try:\n        if ohlcv_data is None or ohlcv_data.empty:\n            logger.error(\"OHLCV data is None or empty\")\n            return None, None, None\n        if trade_data is None or trade_data.empty:\n            logger.warning(\"Trade data is None or empty, using OHLCV only\")\n            trade_data = ohlcv_data[[\"timestamp\"]].assign(trades=0)\n        else:\n            trade_data = trade_data.copy()\n\n        required_columns = [\"timestamp\", \"close\", \"volume\", \"rsi\", \"ema\", \"high\", \"low\"]\n        missing_columns = [col for col in required_columns if col not in ohlcv_data.columns]\n        if missing_columns:\n            logger.error(f\"Missing required columns in ohlcv_data: {missing_columns}\")\n            return None, None, None\n\n        # Ensure timestamps\n        ohlcv_data = ohlcv_data.copy()\n        trade_data = trade_data.copy()\n        ohlcv_data[\"timestamp\"] = pd.to_datetime(ohlcv_data[\"timestamp\"], errors=\"coerce\").dt.tz_convert(\"UTC\")\n        ohlcv_data[\"timestamp\"] = ohlcv_data[\"timestamp\"].fillna(pd.Timestamp.now(tz=\"UTC\"))\n        trade_data[\"timestamp\"] = pd.to_datetime(trade_data[\"timestamp\"], errors=\"coerce\").dt.tz_convert(\"UTC\")\n        trade_data[\"timestamp\"] = trade_data[\"timestamp\"].fillna(pd.Timestamp.now(tz=\"UTC\"))\n\n        merged_data = (\n            ohlcv_data[[\"timestamp\", \"close\", \"volume\", \"rsi\", \"ema\", \"high\", \"low\"]]\n            .merge(trade_data[[\"timestamp\", \"trades\"]], on=\"timestamp\", how=\"left\")\n            .fillna({\"trades\": 0})\n        )\n\n        if len(merged_data) < lookback_minutes + 2:\n            logger.error(f\"Insufficient data: {len(merged_data)} samples, need at least {lookback_minutes + 2}\")\n            return None, None, None\n\n        # Compute 18 features\n        merged_data[\"macd\"], merged_data[\"macd_signal\"] = compute_macd(merged_data[\"close\"])\n        merged_data[\"bollinger_upper\"], merged_data[\"bollinger_lower\"] = compute_bollinger(merged_data[\"close\"])\n        merged_data[\"momentum\"] = compute_momentum(merged_data[\"close\"])\n        merged_data[\"volume_trend\"] = compute_volume_trend(merged_data[\"volume\"])\n        merged_data[\"atr\"] = compute_atr(merged_data[\"high\"], merged_data[\"low\"], merged_data[\"close\"])\n        merged_data[\"vwap\"] = compute_vwap(merged_data)\n        merged_data = compute_additional_features(merged_data)\n        merged_data[\"volatility\"] = (\n            merged_data[\"close\"].pct_change().rolling(config.VOLATILITY_WINDOW, min_periods=1).std() * 100\n        )\n        features = [\n            \"close\", \"volume\", \"trades\", \"rsi\", \"ema\", \"volatility\", \"macd\", \"macd_signal\",\n            \"bollinger_upper\", \"bollinger_lower\", \"momentum\", \"volume_trend\", \"atr\", \"vwap\",\n            \"price_spread\", \"returns\", \"volume_change\", \"trade_intensity\"\n        ]\n        merged_data[\"target\"] = merged_data[\"close\"].shift(-1).fillna(merged_data[\"close\"].iloc[-1])  # Next close price\n\n        # Validate and fill NaN values\n        merged_data = merged_data[features + [\"target\"]].fillna(\n            {\n                \"rsi\": 50.0,\n                \"ema\": merged_data[\"close\"].mean(),\n                \"volatility\": 0.1,\n                \"macd\": 0.0,\n                \"macd_signal\": 0.0,\n                \"bollinger_upper\": merged_data[\"close\"].mean(),\n                \"bollinger_lower\": merged_data[\"close\"].mean(),\n                \"momentum\": 0.0,\n                \"volume_trend\": 0.0,\n                \"atr\": merged_data[\"close\"].mean() * 0.01,\n                \"vwap\": merged_data[\"close\"].mean(),\n                \"price_spread\": 0.0,\n                \"returns\": 0.0,\n                \"volume_change\": 0.0,\n                \"trade_intensity\": 0.0,\n                \"trades\": 0,\n                \"target\": merged_data[\"close\"].mean(),\n            }\n        )\n\n        # Validate numeric features\n        for feature in features + [\"target\"]:\n            if not pd.api.types.is_numeric_dtype(merged_data[feature]):\n                logger.error(f\"Feature {feature} contains non-numeric values\")\n                return None, None, None\n\n        # Scale features\n        feature_scaler = MinMaxScaler()\n        logger.debug(f\"Fitting feature scaler with features: {features}\")\n        feature_scaler.fit(merged_data[features])\n        scaled_features = feature_scaler.transform(merged_data[features])\n        if hasattr(feature_scaler, \"feature_names_in_\"):\n            logger.info(f\"PyTorch feature scaler names: {feature_scaler.feature_names_in_.tolist()}\")\n\n        # Scale target\n        target_scaler = MinMaxScaler()\n        y = merged_data[\"target\"].values.reshape(-1, 1)\n        target_scaler.fit(y)\n        y_scaled = target_scaler.transform(y).flatten()\n        logger.debug(f\"Target scaler: min={target_scaler.data_min_[0]:.2f}, max={target_scaler.data_max_[0]:.2f}\")\n\n        # Prepare sequences\n        X, y_train = [], []\n        for i in range(lookback_minutes, len(scaled_features)):\n            X.append(scaled_features[i - lookback_minutes : i])\n            y_train.append(y_scaled[i])\n        X = np.array(X)\n        y_train = np.array(y_train)\n\n        train_size = int(len(X) * 0.8)\n        if train_size < 10 or len(X) - train_size < 5:\n            logger.error(f\"Insufficient split: Train {train_size}, Test {len(X) - train_size}\")\n            return None, None, None\n\n        X_train, X_test = X[:train_size], X[train_size:]\n        y_train, y_test = y_train[:train_size], y_train[train_size:]\n\n        X_train = torch.FloatTensor(X_train).to(config.DEVICE)\n        y_train = torch.FloatTensor(y_train).view(-1, 1).to(config.DEVICE)\n        X_test = torch.FloatTensor(X_test).to(config.DEVICE)\n        y_test = torch.FloatTensor(y_test).view(-1, 1).to(config.DEVICE)\n\n        # Initialize model\n        model = LSTMPricePredictor(\n            input_size=len(features),\n            hidden_size=config.PYTORCH_HIDDEN_SIZE,\n            num_layers=config.PYTORCH_NUM_LAYERS,\n            dropout=config.PYTORCH_DROPOUT\n        ).to(config.DEVICE)\n        criterion = nn.MSELoss()\n        optimizer = optim.Adam(model.parameters(), lr=config.PYTORCH_LEARNING_RATE)\n        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n\n        # Training loop\n        best_test_loss = float('inf')\n        patience = 20\n        counter = 0\n        for epoch in range(num_epochs):\n            model.train()\n            optimizer.zero_grad()\n            outputs = model(X_train)\n            loss = criterion(outputs, y_train)\n            loss.backward()\n            optimizer.step()\n\n            model.eval()\n            with torch.no_grad():\n                test_outputs = model(X_test)\n                test_loss = criterion(test_outputs, y_test)\n\n            scheduler.step(test_loss)\n\n            if test_loss < best_test_loss:\n                best_test_loss = test_loss\n                counter = 0\n            else:\n                counter += 1\n                if counter >= patience:\n                    logger.info(f\"Early stopping at epoch {epoch + 1}\")\n                    break\n\n            if (epoch + 1) % 20 == 0:\n                logger.info(\n                    f\"PyTorch Epoch {epoch + 1}/{num_epochs}, Train Loss: {loss.item():.6f}, Test Loss: {test_loss.item():.6f}\"\n                )\n\n        # Save scalers\n        feature_scaler_file = \"client_pytorch_scaler.pkl\"\n        target_scaler_file = \"client_pytorch_target_scaler.pkl\"\n        if os.path.exists(feature_scaler_file):\n            os.remove(feature_scaler_file)\n            logger.info(f\"Removed existing feature scaler file: {feature_scaler_file}\")\n        if os.path.exists(target_scaler_file):\n            os.remove(target_scaler_file)\n            logger.info(f\"Removed existing target scaler file: {target_scaler_file}\")\n        joblib.dump(feature_scaler, feature_scaler_file)\n        joblib.dump(target_scaler, target_scaler_file)\n        logger.info(f\"Saved feature scaler to {feature_scaler_file}\")\n        logger.info(f\"Saved target scaler to {target_scaler_file}\")\n\n        logger.info(\n            f\"PyTorch Training Data: samples={len(merged_data)}, \"\n            f\"last_close={merged_data['close'].iloc[-1]:.2f}, last_volume={merged_data['volume'].iloc[-1]:.2f}, \"\n            f\"last_trades={merged_data['trades'].iloc[-1]:.0f}, rsi={merged_data['rsi'].iloc[-1]:.2f}, \"\n            f\"ema={merged_data['ema'].iloc[-1]:.2f}, atr={merged_data['atr'].iloc[-1]:.2f}, \"\n            f\"vwap={merged_data['vwap'].iloc[-1]:.2f}, Features: {features}\"\n        )\n        return model, feature_scaler, target_scaler\n    except Exception as e:\n        logger.error(f\"Error training PyTorch model: {e}\")\n        return None, None, None",
        "performance_issues": [
          "String concatenation in loop - consider join()",
          "Complex comprehension - consider breaking down",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "Long function - consider refactoring"
        ],
        "optimization_priority": 7,
        "estimated_impact": "medium"
      },
      "success": false,
      "original_performance": {
        "execution_time": 0.0,
        "memory_usage": null,
        "cpu_usage": null,
        "function_calls": 0,
        "profile_data": null
      },
      "optimized_performance": null,
      "improvement_ratio": null,
      "applied": false,
      "error": "LLM optimization failed: 'QwenAgentInterface' object has no attribute 'generate_targeted_optimization'"
    },
    {
      "candidate": {
        "function_name": "calculate_locked_funds",
        "file_path": "C:\\Users\\805Sk\\GridBotWorkspace\\automated_debugging_strategy\\GridbotBackup.py",
        "line_start": 3203,
        "line_end": 3225,
        "code_snippet": "def calculate_locked_funds(buy_orders, sell_orders, current_price):\n    locked_usd = 0\n    locked_eth = 0\n    for order in buy_orders:\n        try:\n            price = order.get(\"price\", current_price)\n            size = order.get(\"size\", order.get(\"amount\", 0))\n            feature = order.get(\"feature\", \"base\")\n            locked_usd += size * price\n        except Exception as e:\n            logger.error(\n                f\"Error calculating locked USD for order {order.get('id', 'unknown')}, feature={feature}: {e}\"\n            )\n    for order in sell_orders:\n        try:\n            size = order.get(\"size\", order.get(\"amount\", 0))\n            feature = order.get(\"feature\", \"base\")\n            locked_eth += size\n        except Exception as e:\n            logger.error(\n                f\"Error calculating locked ETH for order {order.get('id', 'unknown')}, feature={feature}: {e}\"\n            )\n    return locked_usd, locked_eth",
        "performance_issues": [
          "String concatenation in loop - consider join()",
          "String concatenation in loop - consider join()"
        ],
        "optimization_priority": 7,
        "estimated_impact": "high"
      },
      "success": false,
      "original_performance": {
        "execution_time": 0.0,
        "memory_usage": null,
        "cpu_usage": null,
        "function_calls": 0,
        "profile_data": null
      },
      "optimized_performance": null,
      "improvement_ratio": null,
      "applied": false,
      "error": "LLM optimization failed: 'QwenAgentInterface' object has no attribute 'generate_optimization'"
    },
    {
      "candidate": {
        "function_name": "sync_balances",
        "file_path": "C:\\Users\\805Sk\\GridBotWorkspace\\automated_debugging_strategy\\GridbotBackup.py",
        "line_start": 3228,
        "line_end": 3277,
        "code_snippet": "def sync_balances(exchange):\n    try:\n        for attempt in range(3):\n            balance = exchange.fetch_balance()\n            eth = float(balance[\"ETH\"][\"free\"]) if \"ETH\" in balance else bot_state[\"eth_balance\"]\n            usd = float(balance[\"USD\"][\"free\"]) if \"USD\" in balance else bot_state[\"usd_balance\"]\n\n            # --- MODIFIED: Reserve funds for Supertrend AND Breakout ---\n            reserved_eth = 0.0\n            if is_supertrend_in_position():\n                reserved_eth += config.STRATEGY_POSITION_SIZE\n                logger.info(f\"Supertrend is in position. Reserving {config.STRATEGY_POSITION_SIZE} ETH.\")\n\n            if bot_state.get(\"breakout_position\", {}).get(\"active\") and bot_state[\"breakout_position\"][\"side\"] == \"buy\":\n                breakout_size = bot_state[\"breakout_position\"].get(\"size\", 0.0)\n                reserved_eth += breakout_size\n                logger.info(f\"Breakout position is active. Reserving {breakout_size} ETH.\")\n\n            if reserved_eth > 0:\n                if eth >= reserved_eth:\n                    eth -= reserved_eth\n                    logger.info(f\"Total reserved: {reserved_eth} ETH. Grid bot available ETH: {eth:.6f}\")\n                else:\n                    logger.warning(f\"Not enough free ETH to reserve for strategies. Free: {eth}, Needed: {reserved_eth}\")\n            # --- END MODIFICATION ---\n\n            if usd < config.MIN_USD_BALANCE:\n                logger.warning(f\"USD balance {usd:.2f} below minimum {config.MIN_USD_BALANCE:.2f}, pausing trading\")\n                bot_state[\"paused\"] = True\n            if eth != bot_state[\"eth_balance\"] or usd != bot_state[\"usd_balance\"]:\n                logger.info(\n                    f\"Balance updated (attempt {attempt + 1}/3): ETH {bot_state['eth_balance']:.6f} -> {eth:.6f}, USD {bot_state['usd_balance']:.2f} -> {usd:.2f}\"\n                )\n            bot_state[\"eth_balance\"] = eth\n            bot_state[\"usd_balance\"] = usd\n            time.sleep(exchange.rateLimit / 1000)\n            return eth, usd\n    except ccxt.AuthenticationError as e:\n        logger.error(f\"Authentication error syncing balances: {e}\")\n        bot_state[\"paused\"] = True\n        return bot_state[\"eth_balance\"], bot_state[\"usd_balance\"]\n    except Exception as e:\n        logger.error(f\"Balance sync failed: {e}\")\n        if attempt < 2:\n            logger.info(f\"Retrying balance sync, attempt {attempt + 2}/3\")\n            time.sleep(1)\n        else:\n            logger.error(\"Failed to sync balances after 3 attempts\")\n            bot_state[\"paused\"] = True\n            return bot_state[\"eth_balance\"], bot_state[\"usd_balance\"]",
        "performance_issues": [
          "String concatenation in loop - consider join()",
          "String concatenation in loop - consider join()"
        ],
        "optimization_priority": 7,
        "estimated_impact": "high"
      },
      "success": false,
      "original_performance": {
        "execution_time": 0.0,
        "memory_usage": null,
        "cpu_usage": null,
        "function_calls": 0,
        "profile_data": null
      },
      "optimized_performance": null,
      "improvement_ratio": null,
      "applied": false,
      "error": "LLM optimization failed: 'QwenAgentInterface' object has no attribute 'generate_optimization'"
    },
    {
      "candidate": {
        "function_name": "place_sell_after_buy",
        "file_path": "C:\\Users\\805Sk\\GridBotWorkspace\\automated_debugging_strategy\\GridbotBackup.py",
        "line_start": 3338,
        "line_end": 3424,
        "code_snippet": "def place_sell_after_buy(exchange, order_id, price, size, feature=None, feature_order_id=None):\n    try:\n        ticker = exchange.fetch_ticker(config.SYMBOL)\n        current_ask = float(ticker[\"ask\"])\n        sell_price = max(price + config.GRID_SIZE, current_ask + 0.01)\n        sell_price = float(exchange.price_to_precision(config.SYMBOL, sell_price))\n        eth, _ = sync_balances(exchange)\n        adjusted_size = min(\n            eth,\n            float(exchange.amount_to_precision(config.SYMBOL, size * config.SELL_SIZE_MULTIPLIER)),\n        )\n        if adjusted_size < config.MIN_POSITION_SIZE:\n            logger.warning(\n                f\"Adjusted sell size {adjusted_size:.6f} below minimum {config.MIN_POSITION_SIZE:.6f}, skipping sell order\"\n            )\n            return None\n        # Find the buy order's feature if not provided\n        if feature is None:\n            feature = \"base\"\n            for order in bot_state[\"buy_orders\"]:\n                if order[\"id\"] == order_id:\n                    feature = order.get(\"feature\", \"base\")\n                    break\n        # Generate feature_order_id if not provided and feature is not base\n        if feature != \"base\" and feature_order_id is None:\n            feature_order_id = str(uuid4())\n        logger.info(\n            f\"Placing sell after buy {order_id} at {sell_price:.2f} with size {adjusted_size:.6f}, feature={feature}, feature_order_id={feature_order_id}\"\n        )\n\n        for attempt in range(3):\n            if eth >= adjusted_size:\n                try:\n                    # Check if order placement is enabled\n                    if not getattr(config, \"ENABLE_ORDER_PLACEMENT\", False):\n                        # Simulation mode - create a fake order\n                        import uuid\n                        fake_order_id = f\"SIM_{uuid.uuid4().hex[:8]}\"\n                        logger.info(f\"[SIMULATION] Sell order {fake_order_id} SIMULATED at {sell_price:.2f}, size={adjusted_size:.6f}, feature={feature}\")\n                        # Create a fake order object for consistency\n                        fake_order = {\n                            \"id\": fake_order_id,\n                            \"status\": \"open\",\n                            \"price\": sell_price,\n                            \"amount\": adjusted_size,\n                            \"feature\": feature\n                        }\n                        if feature_order_id is not None:\n                            fake_order[\"feature_order_id\"] = feature_order_id\n                        return fake_order\n                    \n                    order = exchange.create_limit_sell_order(\n                        config.SYMBOL,\n                        adjusted_size,\n                        sell_price,\n                        params={\"post_only\": True},\n                    )\n                    order = exchange.fetch_order(order[\"id\"])\n                    logger.info(\n                        f\"Sell order placed: {order['id']} at {sell_price:.2f}, Status: {order['status']}, feature={feature}, feature_order_id={feature_order_id}\"\n                    )\n                    buy_prices[order[\"id\"]] = price\n                    order[\"feature\"] = feature\n                    if feature_order_id is not None:\n                        order[\"feature_order_id\"] = feature_order_id\n                    return order\n                except ccxt.InvalidOrder as e:\n                    logger.error(f\"Sell failed: {e}\")\n                    sell_price += 0.01\n                    sell_price = float(exchange.price_to_precision(config.SYMBOL, sell_price))\n                    logger.info(f\"Retrying with adjusted price: {sell_price:.2f}, attempt {attempt + 1}/3\")\n                    time.sleep(1)\n                except ccxt.AuthenticationError as e:\n                    logger.error(f\"Authentication error placing sell order: {e}\")\n                    bot_state[\"paused\"] = True\n                    return None\n                except Exception as e:\n                    logger.error(f\"Sell failed: {e}\")\n                    time.sleep(1)\n            else:\n                logger.warning(f\"Insufficient ETH: {eth:.6f} < {adjusted_size:.6f}, attempt {attempt + 1}/3\")\n                time.sleep(1)\n        logger.error(f\"Failed to place sell after 3 attempts for {order_id}, feature={feature}\")\n        return None\n    except Exception as e:\n        logger.error(f\"Error placing sell order after buy {order_id}: {e}\")\n        return None",
        "performance_issues": [
          "String concatenation in loop - consider join()",
          "Long function - consider refactoring"
        ],
        "optimization_priority": 7,
        "estimated_impact": "high"
      },
      "success": false,
      "original_performance": {
        "execution_time": 0.0,
        "memory_usage": null,
        "cpu_usage": null,
        "function_calls": 0,
        "profile_data": null
      },
      "optimized_performance": null,
      "improvement_ratio": null,
      "applied": false,
      "error": "LLM optimization failed: 'QwenAgentInterface' object has no attribute 'generate_optimization'"
    },
    {
      "candidate": {
        "function_name": "adjust_grid_with_funds_check",
        "file_path": "C:\\Users\\805Sk\\GridBotWorkspace\\automated_debugging_strategy\\GridbotBackup.py",
        "line_start": 3724,
        "line_end": 3957,
        "code_snippet": "def adjust_grid_with_funds_check(ws_manager, exchange):\n    try:\n        logger.debug(\"Starting grid adjustment\")\n        volatility = bot_state.get(\"volatility\", 0.06)\n        config.GRID_SIZE = max(2.0, config.VOLATILITY_WINDOW * volatility * 0.3)\n        position_size = min(0.0012, config.POSITION_SIZE * 1.2)  # Align with Section 10\n        base_buy_lines = 20\n        base_sell_lines = 20\n        feature_buy_lines = 16  # Align with 26 total (10 base + 16 feature)\n        feature_sell_lines = 16\n        base_price = get_current_price()\n        num_features = 8  # MACD, Bollinger Bands, Momentum, Volume Trend, RSI, EMA, ATR, VWAP\n        lines_per_feature = max(8, feature_buy_lines // num_features)\n\n        logger.info(\n            f\"Grid adjustment parameters: grid_size={config.GRID_SIZE:.2f}, position_size={position_size:.6f}, \"\n            f\"base_buy_lines={base_buy_lines}, base_sell_lines={base_sell_lines}, \"\n            f\"feature_buy_lines={feature_buy_lines}, feature_sell_lines={feature_sell_lines}, \"\n            f\"lines_per_feature={lines_per_feature}, base_price={base_price:.2f}\"\n        )\n\n        # Compute feature signals\n        close_prices = ohlcv_df[\"close\"].tail(100)\n        high_prices = ohlcv_df[\"high\"].tail(100)\n        low_prices = ohlcv_df[\"low\"].tail(100)\n        volume = ohlcv_df[\"volume\"].tail(100)\n        feature_data = ohlcv_df.tail(100)\n\n        macd, macd_signal = compute_macd(close_prices)\n        upper_bb, lower_bb = compute_bollinger(close_prices)\n        momentum = compute_momentum(close_prices)\n        volume_trend = compute_volume_trend(volume)\n        rsi = compute_rsi(close_prices)\n        ema = compute_ema(close_prices)\n        atr = compute_atr(high_prices, low_prices, close_prices)\n        vwap = compute_vwap(feature_data)\n\n        feature_names = [\"MACD\", \"Bollinger Bands\", \"Momentum\", \"Volume Trend\", \"RSI\", \"EMA\", \"ATR\", \"VWAP\"]\n        features = [\n            (macd.iloc[-1] - macd_signal.iloc[-1]) / (macd.std() + 1e-6),\n            (close_prices.iloc[-1] - lower_bb.iloc[-1]) / (upper_bb.iloc[-1] - lower_bb.iloc[-1] + 1e-6),\n            momentum.iloc[-1] / (momentum.std() + 1e-6),\n            volume_trend.iloc[-1] / (volume_trend.std() + 1e-6),\n            (rsi.iloc[-1] - 50) / (rsi.std() + 1e-6),\n            (close_prices.iloc[-1] - ema.iloc[-1]) / (ema.std() + 1e-6),\n            atr.iloc[-1] / (atr.std() + 1e-6),\n            (close_prices.iloc[-1] - vwap.iloc[-1]) / (vwap.std() + 1e-6),\n        ]\n        feature_weights = np.array(features) / (np.abs(features).sum() + 1e-6)\n        logger.info(\n            f\"Feature weights: {', '.join([f'{name}={weight:.4f}' for name, weight in zip(feature_names, feature_weights)])}\"\n        )\n\n        # Cancel existing orders\n        cancelled = cancel_orders(exchange, bot_state[\"buy_orders\"] + bot_state[\"sell_orders\"], config.SYMBOL)\n        bot_state[\"buy_orders\"] = []\n        bot_state[\"sell_orders\"] = []\n\n        # Place base buy orders\n        base_buy_count = 0\n        for i in range(base_buy_lines):\n            price = base_price - (i + 1) * config.GRID_SIZE\n            price = float(exchange.price_to_precision(config.SYMBOL, price))\n            if check_funds(\"buy\", price, position_size, exchange):\n                order_id = place_order(\"buy\", price, position_size, ws_manager, exchange)\n                if order_id:\n                    bot_state[\"buy_orders\"].append(\n                        {\n                            \"id\": order_id,\n                            \"side\": \"buy\",\n                            \"price\": price,\n                            \"size\": position_size,\n                            \"status\": \"open\",\n                            \"timestamp\": int(time.time() * 1000),\n                            \"feature\": \"base\",\n                        }\n                    )\n                    base_buy_count += 1\n                    logger.info(f\"Base buy order placed: id={order_id}, price={price:.2f}, feature=base\")\n                else:\n                    logger.warning(f\"Failed to place base buy order at {price:.2f}, feature=base\")\n            else:\n                logger.warning(f\"Skipped base buy order at {price:.2f} due to insufficient funds, feature=base\")\n\n        # Place feature-based buy orders with dynamic cap logic\n        feature_buy_count = 0\n        FEATURE_ORDER_CAP = getattr(config, \"FEATURE_ORDER_CAP\", 84)\n        SOFT_PER_FEATURE_CAP = FEATURE_ORDER_CAP // 2\n        features_list = [fn.lower() for fn in feature_names]\n        def count_open_feature_orders_for_side(bot_state, feature, side):\n            orders = bot_state[\"buy_orders\"] if side == \"buy\" else bot_state[\"sell_orders\"]\n            return sum(1 for o in orders if o.get(\"feature\", \"base\").lower() == feature.lower() and o.get(\"status\", \"open\") == \"open\")\n        def count_total_open_feature_orders_for_side(bot_state, side):\n            orders = bot_state[\"buy_orders\"] if side == \"buy\" else bot_state[\"sell_orders\"]\n            return sum(1 for o in orders if o.get(\"feature\", \"base\").lower() in features_list and o.get(\"status\", \"open\") == \"open\")\n\n        for feature_idx, (weight, feature_name) in enumerate(zip(feature_weights, feature_names)):\n            for line_idx in range(lines_per_feature):\n                open_feature_orders = count_total_open_feature_orders_for_side(bot_state, \"buy\")\n                open_for_this_feature = count_open_feature_orders_for_side(bot_state, feature_name, \"buy\")\n                # Allow if under global cap, and (soft cap not exceeded or others are underutilized)\n                allow = False\n                if open_feature_orders < FEATURE_ORDER_CAP:\n                    if open_for_this_feature < SOFT_PER_FEATURE_CAP:\n                        allow = True\n                    else:\n                        # Allow exceeding soft cap if slots are available\n                        allow = True\n                        logger.info(f\"[DYNAMIC CAP] Feature '{feature_name}' exceeding soft cap ({SOFT_PER_FEATURE_CAP}), but slots available (total open: {open_feature_orders}/{FEATURE_ORDER_CAP})\")\n                if not allow:\n                    logger.info(f\"[DYNAMIC CAP] Feature '{feature_name}' cannot place more buy orders: open={open_for_this_feature}, total open={open_feature_orders}, cap={FEATURE_ORDER_CAP}\")\n                    continue\n                offset = (base_buy_lines + feature_idx * lines_per_feature + line_idx + 1) * config.GRID_SIZE\n                price_adjustment = weight * config.GRID_SIZE * 0.5\n                price = base_price - offset + price_adjustment\n                price = float(exchange.price_to_precision(config.SYMBOL, price))\n                if check_funds(\"buy\", price, position_size, exchange):\n                    order_id = place_order(\"buy\", price, position_size, ws_manager, exchange)\n                    if order_id:\n                        bot_state[\"buy_orders\"].append(\n                            {\n                                \"id\": order_id,\n                                \"side\": \"buy\",\n                                \"price\": price,\n                                \"size\": position_size,\n                                \"status\": \"open\",\n                                \"timestamp\": int(time.time() * 1000),\n                                \"feature\": feature_name,\n                            }\n                        )\n                        feature_buy_count += 1\n                        logger.info(\n                            f\"Feature buy order placed: id={order_id}, price={price:.2f}, feature={feature_name}, weight={weight:.4f}\"\n                        )\n                    else:\n                        logger.warning(f\"Failed to place feature buy order at {price:.2f}, feature={feature_name}\")\n                else:\n                    logger.warning(f\"Skipped feature buy order at {price:.2f} due to insufficient funds, feature={feature_name}\")\n\n        # Log open feature order counts for buy side\n        open_feature_orders = count_total_open_feature_orders_for_side(bot_state, \"buy\")\n        per_feature_counts = {fn: count_open_feature_orders_for_side(bot_state, fn, \"buy\") for fn in features_list}\n        logger.info(f\"[DYNAMIC CAP] Total open feature buy orders: {open_feature_orders}/{FEATURE_ORDER_CAP}, per-feature: {per_feature_counts}\")\n\n        logger.info(f\"[SUMMARY] Base buy orders placed: {base_buy_count}, Feature buy orders placed: {feature_buy_count}\")\n        # --- ENFORCE ORDER SPACING: After buy checks ---\n        logger.info(\"[ORDER SPACING] [AFTER BUY] Enforcing order spacing after buy order checks.\")\n        enforce_order_spacing(bot_state, min_spacing=getattr(config, \"MIN_FEATURE_ORDER_SPACING\", 2.0))\n\n        # Place base sell orders\n        base_sell_count = 0\n        for i in range(base_sell_lines):\n            price = base_price + (i + 1) * config.GRID_SIZE\n            price = float(exchange.price_to_precision(config.SYMBOL, price))\n            if check_funds(\"sell\", price, position_size, exchange):\n                order_id = place_order(\"sell\", price, position_size, ws_manager, exchange)\n                if order_id:\n                    bot_state[\"sell_orders\"].append(\n                        {\n                            \"id\": order_id,\n                            \"side\": \"sell\",\n                            \"price\": price,\n                            \"size\": position_size,\n                            \"status\": \"open\",\n                            \"timestamp\": int(time.time() * 1000),\n                            \"feature\": \"base\",\n                        }\n                    )\n                    base_sell_count += 1\n                    logger.info(f\"Base sell order placed: id={order_id}, price={price:.2f}, feature=base\")\n                else:\n                    logger.warning(f\"Failed to place base sell order at {price:.2f}, feature=base\")\n            else:\n                logger.warning(f\"Skipped base sell order at {price:.2f} due to insufficient funds, feature=base\")\n\n        # Place feature-based sell orders with dynamic cap logic\n        feature_sell_count = 0\n        for feature_idx, (weight, feature_name) in enumerate(zip(feature_weights, feature_names)):\n            for line_idx in range(lines_per_feature):\n                open_feature_orders = count_total_open_feature_orders_for_side(bot_state, \"sell\")\n                open_for_this_feature = count_open_feature_orders_for_side(bot_state, feature_name, \"sell\")\n                allow = False\n                if open_feature_orders < FEATURE_ORDER_CAP:\n                    if open_for_this_feature < SOFT_PER_FEATURE_CAP:\n                        allow = True\n                    else:\n                        allow = True\n                        logger.info(f\"[DYNAMIC CAP] Feature '{feature_name}' exceeding soft cap ({SOFT_PER_FEATURE_CAP}), but slots available (total open: {open_feature_orders}/{FEATURE_ORDER_CAP})\")\n                if not allow:\n                    logger.info(f\"[DYNAMIC CAP] Feature '{feature_name}' cannot place more sell orders: open={open_for_this_feature}, total open={open_feature_orders}, cap={FEATURE_ORDER_CAP}\")\n                    continue\n                offset = (base_sell_lines + feature_idx * lines_per_feature + line_idx + 1) * config.GRID_SIZE\n                price_adjustment = weight * config.GRID_SIZE * 0.5\n                price = base_price + offset + price_adjustment\n                price = float(exchange.price_to_precision(config.SYMBOL, price))\n                if check_funds(\"sell\", price, position_size, exchange):\n                    order_id = place_order(\"sell\", price, position_size, ws_manager, exchange)\n                    if order_id:\n                        bot_state[\"sell_orders\"].append(\n                            {\n                                \"id\": order_id,\n                                \"side\": \"sell\",\n                                \"price\": price,\n                                \"size\": position_size,\n                                \"status\": \"open\",\n                                \"timestamp\": int(time.time() * 1000),\n                                \"feature\": feature_name,\n                            }\n                        )\n                        feature_sell_count += 1\n                        logger.info(\n                            f\"Feature sell order placed: id={order_id}, price={price:.2f}, feature={feature_name}, weight={weight:.4f}\"\n                        )\n                    else:\n                        logger.warning(f\"Failed to place feature sell order at {price:.2f}, feature={feature_name}\")\n                else:\n                    logger.warning(f\"Skipped feature sell order at {price:.2f} due to insufficient funds, feature={feature_name}\")\n\n        # Log open feature order counts for sell side\n        open_feature_orders = count_total_open_feature_orders_for_side(bot_state, \"sell\")\n        per_feature_counts = {fn: count_open_feature_orders_for_side(bot_state, fn, \"sell\") for fn in features_list}\n        logger.info(f\"[DYNAMIC CAP] Total open feature sell orders: {open_feature_orders}/{FEATURE_ORDER_CAP}, per-feature: {per_feature_counts}\")\n\n        logger.info(f\"[SUMMARY] Base sell orders placed: {base_sell_count}, Feature sell orders placed: {feature_sell_count}\")\n        # --- ENFORCE ORDER SPACING: After sell checks ---\n        logger.info(\"[ORDER SPACING] [AFTER SELL] Enforcing order spacing after sell order checks.\")\n        enforce_order_spacing(bot_state, min_spacing=getattr(config, \"MIN_FEATURE_ORDER_SPACING\", 2.0))\n\n        logger.info(\n            f\"Grid adjusted: {len(bot_state['buy_orders'])} buy orders, {len(bot_state['sell_orders'])} sell orders\"\n        )\n        bot_state[\"paused\"] = False\n    except Exception as e:\n        logger.error(f\"Failed to adjust grid: {e}\")",
        "performance_issues": [
          "String concatenation in loop - consider join()",
          "Nested loops detected - consider optimization",
          "String concatenation in loop - consider join()",
          "String concatenation in loop - consider join()",
          "Nested loops detected - consider optimization",
          "String concatenation in loop - consider join()",
          "Complex comprehension - consider breaking down",
          "String concatenation in loop - consider join()",
          "Complex comprehension - consider breaking down",
          "String concatenation in loop - consider join()",
          "Complex comprehension - consider breaking down",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "Complex comprehension - consider breaking down",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "Long function - consider refactoring"
        ],
        "optimization_priority": 7,
        "estimated_impact": "medium"
      },
      "success": false,
      "original_performance": {
        "execution_time": 0.0,
        "memory_usage": null,
        "cpu_usage": null,
        "function_calls": 0,
        "profile_data": null
      },
      "optimized_performance": null,
      "improvement_ratio": null,
      "applied": false,
      "error": "LLM optimization failed: 'QwenAgentInterface' object has no attribute 'generate_targeted_optimization'"
    },
    {
      "candidate": {
        "function_name": "run_bot",
        "file_path": "C:\\Users\\805Sk\\GridBotWorkspace\\automated_debugging_strategy\\GridbotBackup.py",
        "line_start": 4577,
        "line_end": 9783,
        "code_snippet": "def run_bot():\n\n    # Initialize the ML log file for LLM agent monitoring\n    initialize_ml_log()\n\n    # Declare global variables\n    global exchange\n    global bot_state\n    global buy_prices\n    global ohlcv_df\n    global raw_trades_for_ohlcv_df\n    # Ensure last_feature_order_price is initialized\n    if 'last_feature_order_price' not in bot_state:\n        bot_state['last_feature_order_price'] = None\n\n    # Verify global buy_prices is initialized\n    if not isinstance(buy_prices, dict):\n        logger.error(\"Global buy_prices is not initialized as a dictionary, initializing now\")\n        globals()[\"buy_prices\"] = {}\n\n    # Initialize WebSocket manager\n    websocket_manager = WebSocketManager(config.API_KEY, config.SECRET_KEY)\n    coinbase_thread = websocket_manager.start()\n\n    # Configure Coinbase exchange\n    exchange = ccxt.coinbase(\n        {\n            \"apiKey\": config.API_KEY,\n            \"secret\": config.SECRET_KEY,\n            \"enableRateLimit\": True,\n            \"rateLimit\": 200,\n            \"options\": {\"defaultType\": \"spot\"},\n        }\n    )\n    logger.debug(f\"Exchange rate limit configured to {exchange.rateLimit} milliseconds\")\n\n    # Start CLI thread\n    cli_thread = threading.Thread(target=start_cli, daemon=True)\n    cli_thread.start()\n\n    # Fetch initial market data\n    current_price = 0.0\n    try:\n        ticker = exchange.fetch_ticker(config.SYMBOL)\n        current_price = float(ticker[\"last\"])\n        logger.info(f\"Initial market data fetched: Price={current_price:.2f}, GRID_SIZE={config.GRID_SIZE}\")\n        \n        # Log startup activity to ML file for LLM agent monitoring\n        try:\n            timestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n            log_trade_to_ml_file(timestamp, \"STARTUP\", current_price, 0.0, 0.0)\n            logger.info(\"Startup activity logged to ML file\")\n        except Exception as ml_log_error:\n            logger.error(f\"Failed to log startup to ML file: {ml_log_error}\")\n            \n    except Exception as ticker_error:\n        logger.error(f\"Failed to fetch initial ticker data: {ticker_error}\")\n        shutdown_event.set()\n        raise\n\n    # Initialize data caches\n    historical_data = None\n    trade_data = None\n    try:\n        historical_data = fetch_historical_data(exchange, config.SYMBOL, limit=config.LOOKBACK)\n        if historical_data is None or historical_data.empty:\n            logger.error(\"Failed to fetch initial historical data, exiting...\")\n            shutdown_event.set()\n            raise RuntimeError(\"No historical data available\")\n\n        # Compute features for historical_data (restored block)\n        historical_data = historical_data.copy()\n        historical_data[\"trades\"] = 0\n        historical_data[\"rsi\"] = compute_rsi(historical_data[\"close\"])\n        historical_data[\"ema\"] = compute_ema(historical_data[\"close\"])\n        historical_data[\"volatility\"] = compute_volatility(historical_data, periods=config.VOLATILITY_WINDOW)\n        historical_data[\"macd\"], historical_data[\"macd_signal\"] = compute_macd(historical_data[\"close\"])\n        historical_data[\"bollinger_upper\"], historical_data[\"bollinger_lower\"] = compute_bollinger(historical_data[\"close\"])\n        historical_data[\"momentum\"] = compute_momentum(historical_data[\"close\"])\n        historical_data[\"volume_trend\"] = compute_volume_trend(historical_data[\"volume\"])\n        historical_data[\"atr\"] = compute_atr(\n            historical_data[\"high\"],\n            historical_data[\"low\"],\n            historical_data[\"close\"],\n            periods=config.ATR_PERIOD,\n        )\n        historical_data[\"vwap\"] = compute_vwap(historical_data, period=config.VWAP_PERIOD)\n        historical_data[\"predicted_price\"] = historical_data[\"close\"].shift(-1).fillna(historical_data[\"close\"].mean())\n        historical_data[\"grid_level\"] = 0\n        historical_data = (\n            historical_data.bfill()\n            .ffill()\n            .fillna(\n                {\n                    \"rsi\": 50.0,\n                    \"ema\": historical_data[\"close\"].mean(),\n                    \"volatility\": 0.1,\n                    \"macd\": 0.0,\n                    \"macd_signal\": 0.0,\n                    \"bollinger_upper\": historical_data[\"close\"].mean(),\n                    \"bollinger_lower\": historical_data[\"close\"].mean(),\n                    \"momentum\": 0.0,\n                    \"volume_trend\": 0.0,\n                    \"atr\": historical_data[\"close\"].mean() * 0.01,\n                    \"vwap\": historical_data[\"close\"].mean(),\n                    \"predicted_price\": historical_data[\"close\"].mean(),\n                    \"grid_level\": 0,\n                    \"trades\": 0,\n                }\n            )\n        )\n\n        # Ensure historical_data timestamps are datetime\n        if (\n            \"timestamp\" not in historical_data\n            or historical_data[\"timestamp\"].isna().any()\n            or not pd.api.types.is_datetime64_any_dtype(historical_data[\"timestamp\"])\n        ):\n            logger.warning(\"Invalid or missing timestamps in historical_data, converting to datetime\")\n            historical_data[\"timestamp\"] = pd.to_datetime(historical_data[\"timestamp\"], errors=\"coerce\", utc=True).fillna(\n                pd.Timestamp.now(tz=\"UTC\")\n            )\n\n        trade_data = fetch_trade_counts(\n            exchange,\n            config.SYMBOL,\n            historical_data=historical_data,\n            lookback_minutes=config.MIN_TRADE_MINUTES,\n        )\n        if trade_data is None or trade_data.empty:\n            logger.warning(\"Failed to fetch initial trade data, using historical data only\")\n            trade_data = historical_data[[\"timestamp\", \"close\", \"volume\", \"high\", \"low\"]].assign(trades=0)\n    except Exception as data_error:\n        logger.error(f\"Failed to initialize data caches: {data_error}\")\n        shutdown_event.set()\n        raise\n\n    # Verify trade_data features\n    if trade_data is not None and not trade_data.empty:\n        trade_data = trade_data.copy()\n        required_features = [\n            \"timestamp\",\n            \"close\",\n            \"volume\",\n            \"trades\",\n            \"rsi\",\n            \"ema\",\n            \"volatility\",\n            \"macd\",\n            \"macd_signal\",\n            \"bollinger_upper\",\n            \"bollinger_lower\",\n            \"momentum\",\n            \"volume_trend\",\n            \"atr\",\n            \"vwap\",\n            \"predicted_price\",\n            \"grid_level\",\n        ]\n        missing_features = [f for f in required_features if f not in trade_data.columns]\n        if missing_features:\n            logger.warning(f\"Missing features in trade_data: {missing_features}, computing them\")\n            trade_data[\"rsi\"] = compute_rsi(trade_data[\"close\"])\n            trade_data[\"ema\"] = compute_ema(trade_data[\"close\"])\n            trade_data[\"volatility\"] = compute_volatility(trade_data, periods=config.VOLATILITY_WINDOW)\n            trade_data[\"macd\"], trade_data[\"macd_signal\"] = compute_macd(trade_data[\"close\"])\n            trade_data[\"bollinger_upper\"], trade_data[\"bollinger_lower\"] = compute_bollinger(trade_data[\"close\"])\n            trade_data[\"momentum\"] = compute_momentum(trade_data[\"close\"])\n            trade_data[\"volume_trend\"] = compute_volume_trend(trade_data[\"volume\"])\n            trade_data[\"atr\"] = compute_atr(\n                trade_data.get(\"high\", trade_data[\"close\"]),\n                trade_data.get(\"low\", trade_data[\"close\"]),\n                trade_data[\"close\"],\n                periods=config.ATR_PERIOD,\n            )\n            trade_data[\"vwap\"] = compute_vwap(trade_data, period=config.VWAP_PERIOD)\n            trade_data[\"predicted_price\"] = trade_data[\"close\"].shift(-1).fillna(trade_data[\"close\"].mean())\n            trade_data[\"grid_level\"] = 0\n            trade_data = (\n                trade_data.bfill()\n                .ffill()\n                .fillna(\n                    {\n                        \"rsi\": 50.0,\n                        \"ema\": trade_data[\"close\"].mean(),\n                        \"volatility\": 0.1,\n                        \"macd\": 0.0,\n                        \"macd_signal\": 0.0,\n                        \"bollinger_upper\": trade_data[\"close\"].mean(),\n                        \"bollinger_lower\": trade_data[\"close\"].mean(),\n                        \"momentum\": 0.0,\n                        \"volume_trend\": 0.0,\n                        \"atr\": trade_data[\"close\"].mean() * 0.01,\n                        \"vwap\": trade_data[\"close\"].mean(),\n                        \"predicted_price\": trade_data[\"close\"].mean(),\n                        \"grid_level\": 0,\n                        \"trades\": 0,\n                    }\n                )\n            )\n\n    # Ensure trade_data timestamps are datetime\n    if (\n        \"timestamp\" not in trade_data\n        or trade_data[\"timestamp\"].isna().any()\n        or not pd.api.types.is_datetime64_any_dtype(trade_data[\"timestamp\"])\n    ):\n        logger.warning(\"Invalid or missing timestamps in trade_data, converting to datetime\")\n        trade_data[\"timestamp\"] = pd.to_datetime(trade_data[\"timestamp\"], errors=\"coerce\", utc=True).fillna(\n            pd.Timestamp.now(tz=\"UTC\")\n        )\n\n    # Train machine learning models\n    sklearn_rf_model = None\n    sklearn_rf_scaler = None\n    sklearn_sgd_model = None\n    sklearn_sgd_scaler = None\n    sklearn_lookback = config.SKLEARN_LOOKBACK  # e.g., 80\n    pytorch_model = None\n    pytorch_feature_scaler = None\n    pytorch_target_scaler = None\n    pytorch_lookback = config.PYTORCH_LOOKBACK  # e.g., 60\n    xgb_model = None\n    xgb_scaler = None\n    xgb_lookback = config.XGB_LOOKBACK  # e.g., 60\n    meta_model = None\n    meta_scaler = None\n    # Initialize prediction variables to avoid NameError\n    last_sklearn_prediction = current_price\n    last_pytorch_prediction = current_price\n    last_xgb_prediction = current_price\n    logger.debug(\n        f\"Initialized prediction variables: last_sklearn_prediction={last_sklearn_prediction:.2f}, \"\n        f\"last_pytorch_prediction={last_pytorch_prediction:.2f}, last_xgb_prediction={last_xgb_prediction:.2f}\"\n    )\n\n    # Initialize prediction_history\n    prediction_history = pd.DataFrame(\n        columns=[\n            \"sklearn_pred\", \"pytorch_pred\", \"xgb_pred\",\n            \"current_price\", \"volatility\", \"actual_price\"\n        ]\n    )\n    logger.debug(\"Initialized empty prediction_history DataFrame\")\n\n    try:\n        rf_model, rf_scaler, sgd_model, sgd_scaler, lookback = train_sklearn_predictor(historical_data, trade_data)\n        if rf_model is not None and sgd_model is not None:\n            sklearn_rf_model = rf_model\n            sklearn_rf_scaler = rf_scaler\n            sklearn_sgd_model = sgd_model\n            sklearn_sgd_scaler = sgd_scaler\n            sklearn_lookback = lookback\n            bot_state[\"sklearn_rf_model\"] = sklearn_rf_model\n            bot_state[\"scaler_sklearn_rf\"] = sklearn_rf_scaler\n            bot_state[\"sklearn_sgd_model\"] = sklearn_sgd_model\n            bot_state[\"scaler_sklearn_sgd\"] = sklearn_sgd_scaler\n            bot_state[\"sklearn_lookback\"] = sklearn_lookback\n            logger.info(\"Sklearn RF and SGD models trained successfully\")\n            logger.debug(f\"bot_state keys after sklearn training: {list(bot_state.keys())}\")\n            # --- SGD MSE Check ---\n            if hasattr(sgd_model, 'mse_'):\n                sgd_mse = sgd_model.mse_\n            elif hasattr(sgd_model, 'loss_'):\n                sgd_mse = sgd_model.loss_\n            else:\n                sgd_mse = None\n            check_sgd_mse(sgd_mse)\n        else:\n            logger.error(\"Sklearn model training failed: RF or SGD model is None\")\n            logger.debug(\"Debug prompt: Check data quality - verify trade_data and historical_data are not empty\")\n            logger.debug(\"Debug prompt: Verify feature engineering - ensure sufficient features for model training\")\n            logger.debug(\"Optimization prompt: Review sklearn training parameters in train_sklearn_predictor()\")\n    except Exception as sklearn_error:\n        logger.error(f\"Failed to train Sklearn model: {sklearn_error}\")\n        logger.debug(f\"Debug prompt: Sklearn exception details - {type(sklearn_error).__name__}: {str(sklearn_error)}\")\n        logger.debug(\"Debug prompt: Check data preprocessing pipeline and feature scaling\")\n        logger.debug(\"Optimization prompt: Verify sklearn version compatibility and parameter settings\")\n\n    try:\n        pytorch_model, pytorch_feature_scaler, pytorch_target_scaler = train_pytorch_predictor(trade_data, historical_data)\n        if pytorch_model is not None:\n            bot_state[\"pytorch_model\"] = pytorch_model\n            bot_state[\"pytorch_scaler\"] = pytorch_feature_scaler\n            bot_state[\"pytorch_target_scaler\"] = pytorch_target_scaler\n            bot_state[\"pytorch_lookback\"] = pytorch_lookback\n            logger.info(\"PyTorch model trained successfully\")\n        else:\n            logger.error(\"PyTorch model training failed\")\n            logger.debug(\"Debug prompt: Check PyTorch environment - verify CUDA availability if using GPU\")\n            logger.debug(\"Debug prompt: Validate data shapes and tensor conversions in train_pytorch_predictor()\")\n            logger.debug(\"Optimization prompt: Review learning rate, batch size, and network architecture\")\n    except Exception as pytorch_error:\n        logger.error(f\"Failed to train PyTorch model: {pytorch_error}\")\n        logger.debug(f\"Debug prompt: PyTorch exception details - {type(pytorch_error).__name__}: {str(pytorch_error)}\")\n        logger.debug(\"Debug prompt: Check tensor shapes, device placement, and memory usage\")\n        logger.debug(\"Optimization prompt: Consider gradient clipping, learning rate scheduling, or model architecture changes\")\n\n    try:\n        xgb_model, xgb_scaler, xgb_lookback = train_xgboost_predictor(historical_data, trade_data)\n        if xgb_model is not None:\n            bot_state[\"xgb_model\"] = xgb_model\n            bot_state[\"xgb_scaler\"] = xgb_scaler\n            bot_state[\"xgb_lookback\"] = xgb_lookback\n            logger.info(\"XGBoost model trained successfully\")\n        else:\n            logger.error(\"XGBoost model training failed\")\n    except Exception as xgb_error:\n        logger.error(f\"Failed to train XGBoost model: {xgb_error}\")\n\n    # Populate prediction_history\n    if trade_data is not None and not trade_data.empty:\n        close_value = trade_data[\"close\"].iloc[-1]\n        volatility_value = (\n            trade_data[\"volatility\"].iloc[-1]\n            if \"volatility\" in trade_data and not pd.isna(trade_data[\"volatility\"].iloc[-1])\n            else config.LOG_DEFAULT_VOLATILITY\n        )\n        actual_price = (\n            trade_data[\"close\"].iloc[-1]\n            if \"close\" in trade_data and not pd.isna(trade_data[\"close\"].iloc[-1])\n            else close_value\n        )\n        prediction_history = pd.DataFrame(\n            {\n                \"sklearn_pred\": [last_sklearn_prediction],\n                \"pytorch_pred\": [last_pytorch_prediction],\n                \"xgb_pred\": [last_xgb_prediction],\n                \"current_price\": [close_value],\n                \"volatility\": [volatility_value],\n                \"actual_price\": [actual_price],\n            }\n        )\n        logger.debug(f\"Initialized prediction_history with trade_data: {prediction_history.iloc[-1].to_dict()}\")\n    else:\n        logger.warning(\"trade_data empty, initializing prediction_history with current_price\")\n        prediction_history = pd.DataFrame(\n            {\n                \"sklearn_pred\": [current_price],\n                \"pytorch_pred\": [current_price],\n                \"xgb_pred\": [current_price],\n                \"current_price\": [current_price],\n                \"volatility\": [config.LOG_DEFAULT_VOLATILITY],\n                \"actual_price\": [current_price],\n            }\n        )\n        logger.debug(f\"Initialized prediction_history with fallback: {prediction_history.iloc[-1].to_dict()}\")\n\n    # Train meta-model\n    try:\n        meta_model, meta_scaler = train_meta_model(prediction_history, min_samples=1)\n        if meta_model is not None:\n            bot_state[\"meta_model\"] = meta_model\n            bot_state[\"meta_scaler\"] = meta_scaler\n            logger.info(\"Meta-model trained successfully\")\n            joblib.dump(meta_model, \"client_meta_model.pkl\")\n            logger.info(\"Saved initial meta-model to client_meta_model.pkl\")\n            joblib.dump(meta_scaler, \"client_meta_scaler.pkl\")\n            logger.info(\"Saved initial meta-model scaler to client_meta_scaler.pkl\")\n            # --- Meta-model Overfit Check ---\n            train_mse = getattr(meta_model, 'mse_', None)\n            test_mse = getattr(meta_model, 'test_mse_', None)\n            check_meta_model_overfit(train_mse, test_mse)\n        else:\n            logger.error(\"Meta-model training failed\")\n    except Exception as meta_error:\n        logger.error(f\"Failed to train meta-model: {meta_error}\")\n        meta_model = None\n        meta_scaler = None\n\n    # Store prediction_history in bot_state\n    bot_state[\"prediction_history\"] = prediction_history\n    logger.debug(\"Stored prediction_history in bot_state\")\n\n    # Require at least two models to proceed (including meta-model)\n    valid_models = sum(1 for model in [sklearn_rf_model, sklearn_sgd_model, pytorch_model, xgb_model, meta_model] if model is not None)\n    if valid_models < 2:\n        logger.error(f\"Only {valid_models} model(s) trained successfully, at least two required, exiting...\")\n        shutdown_event.set()\n        raise RuntimeError(\"Insufficient valid ML models\")\n\n    logger.info(f\"Trained {valid_models} ML models successfully\")\n\n    # Log training data\n    if not historical_data.empty:\n        last_timestamp = (\n            historical_data[\"timestamp\"].iloc[-1]\n            if \"timestamp\" in historical_data and pd.notna(historical_data[\"timestamp\"].iloc[-1])\n            else pd.Timestamp.now(tz=\"UTC\")\n        )\n        last_close = historical_data[\"close\"].iloc[-1]\n        last_volume = historical_data[\"volume\"].iloc[-1]\n        last_volatility = historical_data[\"volatility\"].iloc[-1]\n        last_rsi = historical_data[\"rsi\"].iloc[-1]\n        last_ema = historical_data[\"ema\"].iloc[-1]\n        last_atr = historical_data[\"atr\"].iloc[-1]\n        last_vwap = historical_data[\"vwap\"].iloc[-1]\n        logger.info(\n            f\"Initial Sklearn Training: timestamp={last_timestamp}, \"\n            f\"close={last_close:.2f}, volume={last_volume:.2f}, \"\n            f\"volatility={last_volatility:.2f}, rsi={last_rsi:.2f}, \"\n            f\"ema={last_ema:.2f}, atr={last_atr:.2f}, vwap={last_vwap:.2f}\"\n        )\n    if trade_data is not None and not trade_data.empty:\n        last_timestamp = (\n            trade_data[\"timestamp\"].iloc[-1]\n            if \"timestamp\" in trade_data and pd.notna(trade_data[\"timestamp\"].iloc[-1])\n            else pd.Timestamp.now(tz=\"UTC\")\n        )\n        last_close = trade_data[\"close\"].iloc[-1]\n        last_trades = trade_data[\"trades\"].iloc[-1]\n        logger.info(\n            f\"Initial PyTorch Training: timestamp={last_timestamp}, \"\n            f\"close={last_close:.2f}, trades={last_trades:.0f}\"\n        )\n\n    # Set lookback period\n    lookback = max(sklearn_lookback, pytorch_lookback, xgb_lookback)\n    logger.debug(f\"Lookback values: sklearn={sklearn_lookback}, pytorch={pytorch_lookback}, xgb={xgb_lookback}, max={lookback}\")\n    sklearn_features = [\n        \"timestamp\",\n        \"close\",\n        \"volume\",\n        \"trades\",\n        \"rsi\",\n        \"ema\",\n        \"volatility\",\n        \"macd\",\n        \"macd_signal\",\n        \"bollinger_upper\",\n        \"bollinger_lower\",\n        \"momentum\",\n        \"volume_trend\",\n        \"high\",\n        \"low\",\n        \"atr\",\n        \"vwap\",\n        \"predicted_price\",\n        \"grid_level\",\n    ]\n    other_features = [\n        \"timestamp\",\n        \"close\",\n        \"volume\",\n        \"trades\",\n        \"rsi\",\n        \"ema\",\n        \"volatility\",\n        \"macd\",\n        \"macd_signal\",\n        \"bollinger_upper\",\n        \"bollinger_lower\",\n        \"momentum\",\n        \"volume_trend\",\n        \"high\",\n        \"low\",\n        \"atr\",\n        \"vwap\",\n        \"predicted_price\",\n        \"grid_level\",\n    ]\n\n    # Initialize recent_data and perform initial WebSocket update\n    try:\n        ohlcv_df, raw_trades_for_ohlcv_df, updated = _update_live_data_from_websocket(\n            websocket_manager, ohlcv_df, raw_trades_for_ohlcv_df\n        )\n        if updated and not ohlcv_df.empty:\n            logger.info(f\"Initial WebSocket update successful, using ohlcv_df for recent_data, rows={len(ohlcv_df)}\")\n            if \"timestamp\" in ohlcv_df:\n                logger.debug(f\"Raw ohlcv_df timestamps before conversion: {ohlcv_df['timestamp'].head().to_list()}\")\n                ohlcv_df[\"timestamp\"] = pd.to_datetime(ohlcv_df[\"timestamp\"], errors=\"coerce\", utc=True)\n                if ohlcv_df[\"timestamp\"].isna().any():\n                    logger.warning(\"Some timestamps in ohlcv_df are invalid, filling with current time\")\n                    ohlcv_df[\"timestamp\"] = ohlcv_df[\"timestamp\"].fillna(pd.Timestamp.now(tz=\"UTC\"))\n            else:\n                logger.warning(\"No timestamp column in ohlcv_df, creating with current time\")\n                ohlcv_df[\"timestamp\"] = pd.Timestamp.now(tz=\"UTC\")\n            logger.debug(\n                f\"ohlcv_df after timestamp fix: first_timestamp={ohlcv_df['timestamp'].iloc[0] if not ohlcv_df.empty else 'N/A'}, \"\n                f\"last_timestamp={ohlcv_df['timestamp'].iloc[-1] if not ohlcv_df.empty else 'N/A'}, \"\n                f\"last_close={ohlcv_df['close'].iloc[-1] if not ohlcv_df.empty else 'N/A'}\"\n            )\n            if len(ohlcv_df) < lookback:\n                logger.debug(f\"Padding recent_data: ohlcv_df has {len(ohlcv_df)} rows, need {lookback}\")\n                historical_subset = historical_data[sklearn_features].tail(lookback - len(ohlcv_df)).copy()\n                historical_subset[\"timestamp\"] = pd.to_datetime(\n                    historical_subset[\"timestamp\"], errors=\"coerce\", utc=True\n                ).fillna(pd.Timestamp.now(tz=\"UTC\"))\n                recent_data = pd.concat([historical_subset, ohlcv_df[sklearn_features]], ignore_index=True).tail(\n                    lookback\n                )\n                recent_trade_data = pd.concat(\n                    [\n                        historical_data[other_features].tail(lookback - len(ohlcv_df)),\n                        ohlcv_df[other_features],\n                    ],\n                    ignore_index=True,\n                ).tail(lookback)\n            else:\n                recent_data = ohlcv_df[sklearn_features].tail(lookback).copy()\n                recent_trade_data = ohlcv_df[other_features].tail(lookback).copy()\n            if \"timestamp\" in recent_data:\n                recent_data[\"timestamp\"] = pd.to_datetime(recent_data[\"timestamp\"], errors=\"coerce\", utc=True)\n                if recent_data[\"timestamp\"].isna().any():\n                    logger.warning(\"Invalid timestamps in recent_data after construction, filling with current time\")\n                    recent_data[\"timestamp\"] = recent_data[\"timestamp\"].fillna(pd.Timestamp.now(tz=\"UTC\"))\n            else:\n                logger.warning(\"No timestamp column in recent_data after construction, setting to current time\")\n                recent_data[\"timestamp\"] = pd.Timestamp.now(tz=\"UTC\")\n            if \"timestamp\" in recent_trade_data:\n                recent_trade_data[\"timestamp\"] = pd.to_datetime(\n                    recent_trade_data[\"timestamp\"], errors=\"coerce\", utc=True\n                )\n                if recent_trade_data[\"timestamp\"].isna().any():\n                    logger.warning(\n                        \"Invalid timestamps in recent_trade_data after construction, filling with current time\"\n                    )\n                    recent_trade_data[\"timestamp\"] = recent_trade_data[\"timestamp\"].fillna(pd.Timestamp.now(tz=\"UTC\"))\n            else:\n                logger.warning(\"No timestamp column in recent_trade_data after construction, setting to current time\")\n                recent_trade_data[\"timestamp\"] = pd.Timestamp.now(tz=\"UTC\")\n        else:\n            logger.warning(\"Initial WebSocket update failed or no data, using historical_data\")\n            recent_data = historical_data[sklearn_features].tail(lookback).copy()\n            recent_trade_data = (\n                trade_data[other_features].tail(lookback).copy()\n                if trade_data is not None\n                else recent_data[other_features].copy()\n            )\n            recent_data[\"timestamp\"] = pd.to_datetime(recent_data[\"timestamp\"], errors=\"coerce\", utc=True).fillna(\n                pd.Timestamp.now(tz=\"UTC\")\n            )\n            recent_trade_data[\"timestamp\"] = pd.to_datetime(\n                recent_trade_data[\"timestamp\"], errors=\"coerce\", utc=True\n            ).fillna(pd.Timestamp.now(tz=\"UTC\"))\n    except Exception as ws_error:\n        logger.error(f\"Error in initial WebSocket update: {ws_error}, using historical_data\")\n        recent_data = historical_data[sklearn_features].tail(lookback).copy()\n        recent_trade_data = (\n            trade_data[other_features].tail(lookback).copy()\n            if trade_data is not None\n            else recent_data[other_features].copy()\n        )\n        recent_data[\"timestamp\"] = pd.to_datetime(recent_data[\"timestamp\"], errors=\"coerce\", utc=True).fillna(\n            pd.Timestamp.now(tz=\"UTC\")\n        )\n        recent_trade_data[\"timestamp\"] = pd.to_datetime(\n            recent_trade_data[\"timestamp\"], errors=\"coerce\", utc=True\n        ).fillna(pd.Timestamp.now(tz=\"UTC\"))\n\n    # Initialize bot state\n    bot_state[\"pytorch_model\"] = LSTMPricePredictor(\n        input_size=18,\n        hidden_size=config.PYTORCH_HIDDEN_SIZE,\n        num_layers=config.PYTORCH_NUM_LAYERS,\n        dropout=config.PYTORCH_DROPOUT\n    ).to(config.DEVICE)\n    bot_state[\"buy_orders\"] = []\n    bot_state[\"sell_orders\"] = []\n    closed_orders = []\n    last_trade_time = time.time()\n    last_reset_time = time.time()\n    last_retrain_time = time.time()\n    last_retrain_check = time.time()\n    last_sklearn_prediction = current_price\n    last_pytorch_prediction = current_price\n    last_xgb_prediction = current_price\n    trade_counts = {}\n    grid_base_price = current_price\n    initial_grid_size = config.GRID_SIZE\n    initial_position_size = config.POSITION_SIZE\n    trade_data_lookback_minutes = config.MIN_TRADE_MINUTES\n    eth_balance = 0.0\n    usd_balance = 0.0\n    eth_balance, usd_balance = sync_balances(exchange)\n    bot_state[\"initial_eth\"] = eth_balance\n    bot_state[\"initial_usd\"] = usd_balance\n    bot_state[\"initial_buy_price\"] = current_price\n    prediction_accuracy = {\"sklearn\": [], \"pytorch\": [], \"xgboost\": []}\n\n    # Store initial grid parameters for rebalancing\n    initial_num_buy_grid_lines = config.NUM_BUY_GRID_LINES  # Save initial buy grid lines (20) for rebalancing reference\n    initial_num_sell_grid_lines = config.NUM_SELL_GRID_LINES  # Save initial sell grid lines (20) for rebalancing reference\n\n    # Perform initial ETH purchase\n    target_eth = config.POSITION_SIZE * config.NUM_SELL_GRID_LINES * config.TARGET_ETH_BUFFER  # Calculate target ETH needed\n    eth_balance = exchange.fetch_balance().get('ETH', {}).get('free', 0.0)  # Fetch available ETH balance\n    logger.info(f\"Checking ETH balance: {eth_balance:.6f} ETH, target: {target_eth:.6f} ETH\")  # Log balance check\n    initial_buy_order = None  # Initialize to avoid undefined variable error\n\n    if eth_balance >= target_eth:\n        logger.info(f\"Sufficient ETH balance ({eth_balance:.6f} >= {target_eth:.6f}), skipping initial buy\")  # Log sufficient balance\n        grid_base_price = current_price  # Set grid base price to current market price\n        bot_state[\"initial_buy_price\"] = grid_base_price  # Store initial buy price for reference\n        logger.info(f\"Grid base price set to {grid_base_price:.2f}\")  # Log grid base price\n    else:\n        total_usd_needed = usd_balance * config.INITIAL_ETH_PERCENTAGE  # Calculate USD needed for ETH purchase\n        total_cost_usd = min(total_usd_needed, target_eth * current_price)  # Limit cost to available USD or target ETH\n        logger.info(\n            f\"Submitting initial market buy for {total_cost_usd:.2f} USD (~{total_cost_usd / current_price:.6f} ETH)\"\n        )  # Log buy order submission\n        try:\n            if total_cost_usd <= 0:\n                logger.error(f\"Invalid total_cost_usd: {total_cost_usd}, skipping initial buy order\")  # Log invalid cost error\n                grid_base_price = current_price  # Fallback to current price\n            else:\n                initial_buy_order = exchange.create_market_buy_order(\n                    config.SYMBOL,\n                    total_cost_usd,\n                    params={\"createMarketBuyOrderRequiresPrice\": False},\n                )  # Place market buy order\n                initial_buy_order = exchange.fetch_order(initial_buy_order[\"id\"])  # Fetch order details\n                filled_amount = float(initial_buy_order[\"filled\"]) if initial_buy_order[\"filled\"] else 0.0  # Get filled amount\n                logger.info(f\"Initial buy filled: {filled_amount:.6f} ETH, ID={initial_buy_order['id']}\")  # Log buy order success\n                grid_base_price = float(initial_buy_order[\"average\"]) if initial_buy_order[\"average\"] else current_price  # Use average price\n                bot_state[\"initial_buy_price\"] = grid_base_price  # Store initial buy price\n                logger.info(f\"Grid base price set to {grid_base_price:.2f}\")  # Log grid base price\n        except Exception as buy_error:\n            logger.error(f\"Initial buy order failed: {buy_error}, using current price as grid base\")  # Log buy order failure\n            grid_base_price = current_price  # Fallback to current price\n\n    # Initialize orders to send\n    initial_orders_to_send = [\n        {\n            \"type\": \"order\",\n            \"id\": initial_buy_order[\"id\"] if initial_buy_order else \"initial_buy\",\n            \"status\": initial_buy_order[\"status\"] if initial_buy_order else \"failed\",\n            \"side\": \"buy\",\n            \"price\": float(grid_base_price),\n            \"timestamp\": int(time.time() * 1000),\n        }\n    ]  # Initialize WebSocket message list with initial buy order (if any)\n    current_max_order_range = config.MAX_ORDER_RANGE * (config.GRID_SIZE / config.MIN_GRID_SIZE)  # Adjust range based on grid size\n    current_stagnation_timeout = config.STAGNATION_TIMEOUT * (config.MIN_GRID_SIZE / config.GRID_SIZE)  # Adjust timeout based on grid size\n    logger.info(\n        f\"Initial setup: MAX_ORDER_RANGE={current_max_order_range:.2f}, STAGNATION_TIMEOUT={current_stagnation_timeout:.0f}s, \"\n        f\"NUM_BUY_GRID_LINES={initial_num_buy_grid_lines}, NUM_SELL_GRID_LINES={initial_num_sell_grid_lines}\"\n    )  # Enhanced: Log setup parameters for troubleshooting\n    logger.info(\"Placing initial base grid orders and scanning for feature-based orders (RSI, Bollinger Bands, MACD, EMA, ATR, Volatility, VWAP) during initial order placement. LIVE ORDER PLACEMENT ENABLED.\")\n\n    eth_balance, usd_balance = sync_balances(exchange)  # Sync balances after potential initial buy\n    logger.info(f\"Initial balances for grid setup: ETH={eth_balance:.6f}, USD={usd_balance:.2f}\")  # Log updated balances\n\n    # Initialize feature_trade_state if not present\n    if 'feature_trade_state' not in bot_state:\n        bot_state['feature_trade_state'] = {\n            'rsi': {'last_side': None, 'last_price': None},\n            'bollinger': {'last_side': None, 'last_price': None},\n            'macd': {'last_side': None, 'last_price': None},\n        }\n        logger.info(\"Initialized feature_trade_state for DCA tracking\")\n\n    # DCA logic to enforce buy/sell sequence\n    def can_place_feature_order(feature, side, current_price):\n        state = bot_state['feature_trade_state'][feature]\n        if state['last_side'] is None:\n            if side == 'buy':\n                logger.info(f\"[DCA {feature.upper()}] No previous trade, allowing buy order\")\n                return True\n            else:\n                logger.info(f\"[DCA {feature.upper()}] No previous trade, sell order blocked (requires buy first)\")\n                return False\n        if side == 'sell' and state['last_side'] == 'buy' and state['last_price']:\n            can_sell = current_price >= state['last_price'] * 1.015  # 1.5% profit threshold\n            logger.info(f\"[DCA {feature.upper()}] Sell check: current_price={current_price:.2f}, \"\n                        f\"last_buy_price={state['last_price']:.2f}, threshold={state['last_price'] * 1.015:.2f}, \"\n                        f\"can_sell={can_sell}\")\n            return can_sell\n        if side == 'buy' and state['last_side'] == 'sell' and state['last_price']:\n            can_buy = current_price <= state['last_price'] * 0.98  # 2% lower threshold\n            logger.info(f\"[DCA {feature.upper()}] Buy check: current_price={current_price:.2f}, \"\n                        f\"last_sell_price={state['last_price']:.2f}, threshold={state['last_price'] * 0.98:.2f}, \"\n                        f\"can_buy={can_buy}\")\n            return can_buy\n        logger.info(f\"[DCA {feature.upper()}] Cannot place {side} order: last_side={state['last_side']}, \"\n                    f\"last_price={state['last_price']}\")\n        return False\n\n    # --- Place initial base grid orders (buy/sell) ---\n    initial_orders_to_send = []\n    for grid_index in range(config.NUM_BUY_GRID_LINES):\n        if count_total_open_base_orders(bot_state) >= (config.NUM_BUY_GRID_LINES + config.NUM_SELL_GRID_LINES):\n            logger.info(f\"[BASE GRID] Skipping buy order placement: global base order cap reached ({config.NUM_BUY_GRID_LINES + config.NUM_SELL_GRID_LINES})\")\n            break\n        price = grid_base_price - (config.GRID_SIZE * (grid_index + 1))\n        price = float(exchange.price_to_precision(config.SYMBOL, price))\n        if (grid_base_price - price) <= current_max_order_range:\n            amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n            cost = float(amount) * price\n            if usd_balance >= cost:\n                try:\n                    order = exchange.create_limit_buy_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                    order = exchange.fetch_order(order[\"id\"])\n                    order_price = float(order[\"price\"]) if order[\"price\"] else price\n                    if order[\"status\"] == \"open\":\n                        bot_state[\"buy_orders\"].append({**order, \"feature\": \"base\"})\n                        initial_orders_to_send.append({\n                            \"type\": \"order\",\n                            \"id\": order[\"id\"],\n                            \"status\": order[\"status\"],\n                            \"side\": order[\"side\"],\n                            \"price\": float(order_price),\n                            \"timestamp\": int(time.time() * 1000),\n                            \"feature\": \"base\"\n                        })\n                    logger.info(f\"[BASE] Buy order {order['id']} placed at {price:.2f}, size={amount}, feature=base [LIVE]\")\n                except Exception as buy_order_error:\n                    logger.error(f\"[BASE] Failed to place buy order at {price:.2f}: {buy_order_error}\")\n            else:\n                logger.warning(f\"[BASE] Insufficient USD {usd_balance:.2f} for buy order at {price:.2f} (cost {cost:.2f})\")\n        time.sleep(exchange.rateLimit / 1000)\n    logger.info(f\"[BASE] Placed {len([o for o in bot_state['buy_orders'] if o['feature'] == 'base'])}/{config.NUM_BUY_GRID_LINES} base buy orders [LIVE]\")\n\n    eth_balance, _ = sync_balances(exchange)\n    logger.info(f\"[BASE] ETH balance before sell orders: {eth_balance:.6f}\")\n    for grid_index in range(config.NUM_SELL_GRID_LINES):\n        if count_total_open_base_orders(bot_state) >= (config.NUM_BUY_GRID_LINES + config.NUM_SELL_GRID_LINES):\n            logger.info(f\"[BASE GRID] Skipping sell order placement: global base order cap reached ({config.NUM_BUY_GRID_LINES + config.NUM_SELL_GRID_LINES})\")\n            break\n        price = grid_base_price + (config.GRID_SIZE * (grid_index + 1))\n        price = float(exchange.price_to_precision(config.SYMBOL, price))\n        if (price - grid_base_price) <= current_max_order_range:\n            amount = min(\n                eth_balance / max(1, config.NUM_SELL_GRID_LINES - grid_index),\n                config.POSITION_SIZE,\n         \n   )\n            amount = float(exchange.amount_to_precision(config.SYMBOL, amount))\n            if eth_balance >= amount and amount >= config.MIN_POSITION_SIZE:\n                try:\n                    order = exchange.create_limit_sell_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                    order = exchange.fetch_order(order[\"id\"])\n                    order_price = float(order[\"price\"]) if order[\"price\"] else price\n                    if order[\"status\"] == \"open\":\n                        bot_state[\"sell_orders\"].append({**order, \"feature\": \"base\"})\n                        initial_orders_to_send.append({\n                            \"type\": \"order\",\n                            \"id\": order[\"id\"],\n                            \"status\": order[\"status\"],\n                            \"side\": order[\"side\"],\n                            \"price\": float(order_price),\n                            \"timestamp\": int(time.time() * 1000),\n                            \"feature\": \"base\"\n                        })\n                    eth_balance -= amount\n                    buy_prices[order[\"id\"]] = grid_base_price\n                    logger.info(f\"[BASE] Sell order {order['id']} placed at {price:.2f}, size={amount}, feature=base\")\n                except Exception as sell_order_error:\n                    logger.error(f\"[BASE] Failed to place sell order at {price:.2f}: {sell_order_error}\")\n            else:\n                logger.warning(f\"[BASE] Insufficient ETH {eth_balance:.6f} for sell order at {price:.2f} (required {amount:.6f})\")\n        time.sleep(exchange.rateLimit / 1000)\n    logger.info(f\"[BASE] Placed {len([o for o in bot_state['sell_orders'] if o['feature'] == 'base'])}/{config.NUM_SELL_GRID_LINES} base sell orders\")\n    logger.info(f\"[BASE] Placed {len([o for o in bot_state['sell_orders'] if o['feature'] == 'base'])}/{config.NUM_SELL_GRID_LINES} base sell orders [LIVE]\")\n\n    # --- Place initial feature-based orders (RSI, Bollinger Bands, MACD) ---\n    # --- Place initial feature-based orders (RSI, Bollinger Bands, MACD) ---\n    # LIVE ORDER PLACEMENT ENABLED\n    latest = historical_data.iloc[-1]\n    try:\n        orderbook = exchange.fetch_order_book(config.SYMBOL)\n        best_bid = float(orderbook['bids'][0][0]) if orderbook['bids'] else None\n        best_ask = float(orderbook['asks'][0][0]) if orderbook['asks'] else None\n        min_tick = getattr(exchange, 'markets', {}).get(config.SYMBOL, {}).get('precision', {}).get('price', 0.01)\n        min_tick = float(min_tick) if min_tick else 0.01\n    except Exception as ob_err:\n        logger.warning(f\"[FEATURE] Could not fetch order book for post-only compliance: {ob_err}\")\n        best_bid = best_ask = None\n        min_tick = 0.01\n\n    feature_order_cap = getattr(config, \"FEATURE_ORDER_CAP\", 100)\n    soft_feature_order_cap = getattr(config, \"SOFT_FEATURE_ORDER_CAP\", 50)\n\n    # RSI\n    logger.info(f\"[RSI] Current RSI: {latest['rsi']:.2f}, Buy if < 30\")\n    min_feature_spacing = getattr(config, \"MIN_FEATURE_ORDER_SPACING\", 0.005)\n    if (\n        latest[\"rsi\"] < 30\n        and best_ask\n        and count_total_open_feature_orders(bot_state) < feature_order_cap\n        and can_place_feature_order(\"rsi\", \"buy\", latest[\"close\"])\n        and can_place_feature_order_with_spacing(bot_state, latest[\"close\"], min_feature_spacing)\n    ):\n        if soft_feature_order_cap is not None:\n            feature_count = sum(1 for o in bot_state[\"buy_orders\"] if o.get(\"feature\") == \"rsi\" and o.get(\"status\", \"open\") == \"open\")\n            if feature_count >= soft_feature_order_cap:\n                logger.info(f\"[INIT] Soft cap reached for feature rsi ({soft_feature_order_cap}), but not strictly enforced.\")\n        retry_count = 0\n        max_retries = 5\n        price = float(exchange.price_to_precision(config.SYMBOL, min(latest[\"close\"], best_ask - min_tick)))\n        while retry_count < max_retries and price < best_ask:\n            try:\n                amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                cost = float(amount) * price\n                if usd_balance >= cost:\n                    order = exchange.create_limit_buy_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                    order = exchange.fetch_order(order[\"id\"])\n                    order_price = float(order[\"price\"]) if order.get(\"price\") is not None else price\n                    bot_state[\"buy_orders\"].append({**order, \"feature\": \"rsi\", \"price\": order_price})\n                    initial_orders_to_send.append({\n                        \"type\": \"order\",\n                        \"id\": order[\"id\"],\n                        \"status\": order[\"status\"],\n                        \"side\": order[\"side\"],\n                        \"price\": order_price,\n                        \"timestamp\": int(time.time() * 1000),\n                        \"feature\": \"rsi\"\n                    })\n                    bot_state['feature_trade_state']['rsi']['last_side'] = 'buy'\n                    bot_state['feature_trade_state']['rsi']['last_price'] = order_price\n                    logger.info(f\"[RSI] Buy order {order['id']} placed at {order_price:.2f}, size={amount}, feature=rsi, DCA updated\")\n                    break\n                else:\n                    logger.warning(f\"[RSI] Insufficient USD {usd_balance:.2f} for buy order at {price:.2f} (cost {cost:.2f})\")\n                    break\n            except Exception as e:\n                if \"INVALID_LIMIT_PRICE_POST_ONLY\" in str(e):\n                    retry_count += 1\n                    price = float(exchange.price_to_precision(config.SYMBOL, price - min_tick))\n                    logger.warning(f\"[RSI] Buy order post-only error, retrying with lower price: {price:.2f} (attempt {retry_count}/{max_retries})\")\n                else:\n                    logger.error(f\"[RSI] Failed to place buy order: {e}\")\n                    break\n        else:\n            logger.warning(f\"[RSI] Skipped buy: could not place post-only order after {max_retries} retries or price {price:.2f} >= best_ask {best_ask}\")\n\n    # Bollinger Bands\n    logger.info(f\"[BOLLINGER] Current Price: {latest['close']:.2f}, Lower Band: {latest['bollinger_lower']:.2f}, Upper Band: {latest['bollinger_upper']:.2f}\")\n    if (\n        latest[\"close\"] <= latest[\"bollinger_lower\"]\n        and best_ask\n        and count_total_open_feature_orders(bot_state) < feature_order_cap\n        and can_place_feature_order(\"bollinger\", \"buy\", latest[\"close\"])\n        and can_place_feature_order_with_spacing(bot_state, latest[\"close\"], min_feature_spacing)\n    ):\n        if soft_feature_order_cap is not None:\n            feature_count = sum(1 for o in bot_state[\"buy_orders\"] if o.get(\"feature\") == \"bollinger\" and o.get(\"status\", \"open\") == \"open\")\n            if feature_count >= soft_feature_order_cap:\n                logger.info(f\"[INIT] Soft cap reached for feature bollinger ({soft_feature_order_cap}), but not strictly enforced.\")\n        retry_count = 0\n        max_retries = 5\n        price = float(exchange.price_to_precision(config.SYMBOL, min(latest[\"close\"], best_ask - min_tick)))\n        while retry_count < max_retries and price < best_ask:\n            try:\n                amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                cost = float(amount) * price\n                if usd_balance >= cost:\n                    order = exchange.create_limit_buy_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                    order = exchange.fetch_order(order[\"id\"])\n                    order_price = float(order[\"price\"]) if order.get(\"price\") is not None else price\n                    bot_state[\"buy_orders\"].append({**order, \"feature\": \"bollinger\", \"price\": order_price})\n                    initial_orders_to_send.append({\n                        \"type\": \"order\",\n                        \"id\": order[\"id\"],\n                        \"status\": order[\"status\"],\n                        \"side\": order[\"side\"],\n                        \"price\": order_price,\n                        \"timestamp\": int(time.time() * 1000),\n                        \"feature\": \"bollinger\"\n                    })\n                    bot_state['feature_trade_state']['bollinger']['last_side'] = 'buy'\n                    bot_state['feature_trade_state']['bollinger']['last_price'] = order_price\n                    logger.info(f\"[BOLLINGER] Buy order {order['id']} placed at {order_price:.2f}, size={amount}, feature=bollinger, DCA updated\")\n                    break\n                else:\n                    logger.warning(f\"[BOLLINGER] Insufficient USD {usd_balance:.2f} for buy order at {price:.2f} (cost {cost:.2f})\")\n                    break\n            except Exception as e:\n                if \"INVALID_LIMIT_PRICE_POST_ONLY\" in str(e):\n                    retry_count += 1\n                    price = float(exchange.price_to_precision(config.SYMBOL, price - min_tick))\n                    logger.warning(f\"[BOLLINGER] Buy order post-only error, retrying with lower price: {price:.2f} (attempt {retry_count}/{max_retries})\")\n                else:\n                    logger.error(f\"[BOLLINGER] Failed to place buy order: {e}\")\n                    break\n        else:\n            logger.warning(f\"[BOLLINGER] Skipped buy: could not place post-only order after {max_retries} retries or price {price:.2f} >= best_ask {best_ask}\")\n\n    # MACD\n    logger.info(f\"[MACD] Current MACD: {latest['macd']:.4f}, Signal: {latest['macd_signal']:.4f}, Buy if MACD > Signal\")\n    if (\n        latest[\"macd\"] > latest[\"macd_signal\"]\n        and best_ask\n        and count_total_open_feature_orders(bot_state) < feature_order_cap\n        and can_place_feature_order(\"macd\", \"buy\", latest[\"close\"])\n        and can_place_feature_order_with_spacing(bot_state, latest[\"close\"], min_feature_spacing)\n    ):\n        if soft_feature_order_cap is not None:\n            feature_count = sum(1 for o in bot_state[\"buy_orders\"] if o.get(\"feature\") == \"macd\" and o.get(\"status\", \"open\") == \"open\")\n            if feature_count >= soft_feature_order_cap:\n                logger.info(f\"[INIT] Soft cap reached for feature macd ({soft_feature_order_cap}), but not strictly enforced.\")\n        retry_count = 0\n        max_retries = 5\n        price = float(exchange.price_to_precision(config.SYMBOL, min(latest[\"close\"], best_ask - min_tick)))\n        while retry_count < max_retries and price < best_ask:\n            try:\n                amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                cost = float(amount) * price\n                if usd_balance >= cost:\n                    order = exchange.create_limit_buy_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                    order = exchange.fetch_order(order[\"id\"])\n                    order_price = float(order[\"price\"]) if order.get(\"price\") is not None else price\n                    bot_state[\"buy_orders\"].append({**order, \"feature\": \"macd\", \"price\": order_price})\n                    initial_orders_to_send.append({\n                        \"type\": \"order\",\n                        \"id\": order[\"id\"],\n                        \"status\": order[\"status\"],\n                        \"side\": order[\"side\"],\n                        \"price\": order_price,\n                        \"timestamp\": int(time.time() * 1000),\n                        \"feature\": \"macd\"\n                    })\n                    bot_state['feature_trade_state']['macd']['last_side'] = 'buy'\n                    bot_state['feature_trade_state']['macd']['last_price'] = order_price\n                    logger.info(f\"[MACD] Buy order {order['id']} placed at {order_price:.2f}, size={amount}, feature=macd, DCA updated\")\n                    break\n                else:\n                    logger.warning(f\"[MACD] Insufficient USD {usd_balance:.2f} for buy order at {price:.2f} (cost {cost:.2f})\")\n                    break\n            except Exception as e:\n                if \"INVALID_LIMIT_PRICE_POST_ONLY\" in str(e):\n                    retry_count += 1\n                    price = float(exchange.price_to_precision(config.SYMBOL, price - min_tick))\n                    logger.warning(f\"[MACD] Buy order post-only error, retrying with lower price: {price:.2f} (attempt {retry_count}/{max_retries})\")\n                else:\n                    logger.error(f\"[MACD] Failed to place buy order: {e}\")\n                    break\n        else:\n            logger.warning(f\"[MACD] Skipped buy: could not place post-only order after {max_retries} retries or price {price:.2f} >= best_ask {best_ask}\")\n\n    # Send initial orders via WebSocket\n    try:\n        # Remove any cancelled/closed orders from initial_orders_to_send before sending\n        filtered_orders_to_send = [o for o in initial_orders_to_send if o.get('status', 'open') == 'open']\n        websocket_manager.send(json.dumps(filtered_orders_to_send))\n        logger.info(f\"[WEBSOCKET] Sent {len(filtered_orders_to_send)} initial orders (base and feature-based)\")\n    except Exception as websocket_error:\n        logger.error(f\"[WEBSOCKET] Error sending initial WebSocket orders: {websocket_error}\")\n\n    # Initialize main loop variables\n    iteration_count = 0  # Initialize iteration counter\n    previous_price = current_price  # Store current price for tracking\n    last_heartbeat = time.time()  # Initialize heartbeat timestamp\n    last_data_refresh = time.time()  # Initialize data refresh timestamp\n\n    # Initialize ML scalers\n    scaler_sklearn_rf = StandardScaler()  # For RandomForestRegressor\n    scaler_pytorch = MinMaxScaler()\n    scaler_xgb = StandardScaler()\n    scaler_meta = StandardScaler()\n    bot_state[\"sklearn_rf_scaler\"] = scaler_sklearn_rf\n    bot_state[\"pytorch_scaler\"] = scaler_pytorch\n    bot_state[\"xgb_scaler\"] = scaler_xgb\n    bot_state[\"meta_scaler\"] = scaler_meta\n\n    # Main loop\n    last_trade_time = time.time()\n    last_heartbeat = time.time()\n    last_reset_time = time.time()\n    iteration_count = 0\n    previous_price = bot_state[\"current_price\"]\n    grid_base_price = 0\n    initial_position_size = config.POSITION_SIZE\n    initial_grid_size = config.GRID_SIZE\n    last_sklearn_prediction = 0\n    last_pytorch_prediction = 0\n    last_xgb_prediction = 0\n    trade_counts = collections.defaultdict(int)\n    prediction_accuracy = {\"sklearn\": [], \"pytorch\": [], \"xgboost\": []}\n\n    # Fit scalers and initialize models\n    if not bot_state[\"feature_cache\"].empty:\n        features = [\n            \"close\", \"volume\", \"trades\", \"rsi\", \"ema\", \"volatility\", \"macd\", \"macd_signal\",\n            \"bollinger_upper\", \"bollinger_lower\", \"momentum\", \"volume_trend\", \"atr\", \"vwap\",\n            \"price_spread\", \"returns\", \"volume_change\", \"trade_intensity\"\n        ]\n        # Fit scalers with DataFrame to preserve feature names\n        X = bot_state[\"feature_cache\"][features]\n        scaler_sklearn_rf.fit(X)\n        scaler_pytorch.fit(X)\n        scaler_xgb.fit(X)\n        logger.info(\"Scalers fitted with initial feature cache data\")\n\n        # Force initial retraining\n        models = retrain_ml_models(\n            bot_state[\"feature_cache\"], scaler_sklearn_rf, scaler_pytorch, scaler_xgb, scaler_meta\n        )\n        if all(models):\n            (bot_state[\"sklearn_rf_model\"], bot_state[\"sklearn_sgd_model\"]), \\\n            bot_state[\"pytorch_model\"], bot_state[\"xgb_model\"], bot_state[\"meta_model\"] = models\n            bot_state[\"last_retrain_time\"] = time.time()\n            logger.info(\"Initial model retraining completed\")\n\n    try:\n        # Main loop for continuous trading\n        while not shutdown_event.is_set():\n            try:\n                # Check if bot is paused\n                if bot_state[\"paused\"]:\n                    logger.info(\"Bot is paused, skipping iteration\")\n                    time.sleep(config.CHECK_ORDER_FREQUENCY)\n                    continue\n\n                # Log periodic heartbeat to ML file for LLM agent monitoring\n                current_time = time.time()\n                if current_time - last_heartbeat >= 30:  # Every 30 seconds\n                    try:\n                        timestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n                        current_price = bot_state.get(\"current_price\", 0)\n                        log_trade_to_ml_file(timestamp, f\"HEARTBEAT_{iteration_count}\", current_price, 0.0, 0.0)\n                        last_heartbeat = current_time\n                    except Exception as heartbeat_error:\n                        logger.error(f\"Failed to log heartbeat to ML file: {heartbeat_error}\")\n\n                \"\"\" # --- ADDED: Breakout Logic ---\n                # If a breakout position is active, manage it and skip the rest of the grid logic.\n                if bot_state.get(\"breakout_position\", {}).get(\"active\"):\n                    logger.info(\"[BREAKOUT] Active breakout position detected. Managing position...\")\n                    manage_breakout_position(exchange, websocket_manager)\n                    time.sleep(config.CHECK_ORDER_FREQUENCY) # Wait before the next check\n                    continue # Skip the rest of the main loop to focus on the breakout\n\n                # If not in a breakout, check if conditions are right for a new one.\n                check_for_breakout(exchange, websocket_manager)\n\n                # If a breakout was just initiated, loop again to let manage_breakout_position take over.\n                if bot_state.get(\"breakout_position\", {}).get(\"active\"):\n                    logger.info(\"[BREAKOUT] New breakout trade initiated. Skipping grid logic for this cycle.\")\n                    time.sleep(config.CHECK_ORDER_FREQUENCY)\n                    continue\n\n                # If grid is paused (due to breakout), skip grid logic\n                if bot_state.get(\"grid_paused\"):\n                    logger.info(\"[GRID PAUSED] Grid logic is paused due to an active breakout trade. Waiting for breakout to complete.\")\n                    time.sleep(config.CHECK_ORDER_FREQUENCY)\n                    continue\n                \n                # --- ADDED: Grid Repositioning Logic ---\n                if bot_state.get(\"needs_grid_reposition\"):\n                    reposition_grid_after_breakout(exchange, websocket_manager)\n                    # The grid is now repositioned, continue to the next loop to start normal checks\n                    continue\n                # --- END: Grid Repositioning Logic ---\n                # --- END: Breakout Logic ---\n\n                # === BEGIN: Active Feature Calls and Logging === \"\"\"\n                try:\n                    logger.info(\"[PROTECTION] Running uptrend protection and feature order spacing.\")\n                    if 'apply_uptrend_protection' in globals():\n                        apply_uptrend_protection(ohlcv_df, config, bot_state)\n                    if 'apply_feature_order_spacing' in globals():\n                        apply_feature_order_spacing(bot_state, config)\n                except Exception as e:\n                    logger.error(f\"[PROTECTION] Error in protection features: {e}\")\n\n                try:\n                    logger.info(\"[LOGGING] Logging protection and feature trade events.\")\n                    if 'log_protection_event' in globals():\n                        log_protection_event(bot_state, config)\n                    if 'log_feature_trade' in globals():\n                        log_feature_trade(time.time(), 'mainloop', 'mainloop', 'mainloop', bot_state.get('current_price', 0), 0, 'mainloop', 0)\n                except Exception as e:\n                    logger.error(f\"[LOGGING] Error in logging features: {e}\")\n\n                try:\n                    logger.info(\"[OPTIMIZATION] Running auto parameter optimization.\")\n                    if 'auto_optimize_params_bi' in globals() and 'apply_param_changes_bi' in globals():\n                        perf_hist = bot_state.get('performance_history', [])\n                        if perf_hist and len(perf_hist) >= 10:\n                            changes = auto_optimize_params_bi(perf_hist[-20:], config)\n                            if changes:\n                                logger.info(f\"[OPTIMIZATION] Proposed parameter changes: {changes}\")\n                                apply_param_changes_bi(config, changes)\n                except Exception as e:\n                    logger.error(f\"[OPTIMIZATION] Error in auto parameter optimization: {e}\")\n                # === END: Active Feature Calls and Logging ===\n\n                current_time = time.time()\n                current_volume = ohlcv_df[\"volume\"].iloc[-1] if not ohlcv_df.empty else 0.0\n\n                # Update live data\n                ohlcv_df, raw_trades_for_ohlcv_df, data_updated = _update_live_data_from_websocket(\n                    websocket_manager, ohlcv_df, raw_trades_for_ohlcv_df\n                )\n\n                # Online Updates\n                if len(recent_trade_data) >= config.PYTORCH_LOOKBACK:\n                    try:\n                        # Ensure all features\n                        required_features = [\n                            \"close\", \"volume\", \"trades\", \"rsi\", \"ema\", \"volatility\", \"macd\", \"macd_signal\",\n                            \"bollinger_upper\", \"bollinger_lower\", \"momentum\", \"volume_trend\", \"atr\", \"vwap\",\n                            \"price_spread\", \"returns\", \"volume_change\", \"trade_intensity\"\n                        ]\n                        if not all(f in recent_trade_data.columns for f in required_features):\n                            logger.warning(\"Computing additional features for recent_trade_data\")\n                            recent_trade_data = compute_additional_features(recent_trade_data)\n                            recent_trade_data = recent_trade_data.bfill().ffill().fillna({\n                                \"price_spread\": 0.0, \"returns\": 0.0, \"volume_change\": 0.0, \"trade_intensity\": 0.0\n                            })\n\n                        log_ref_timestamp = recent_trade_data['timestamp'].iloc[-1] if not recent_trade_data.empty else pd.Timestamp.now(tz=\"UTC\")\n                        log_ref_current_close = recent_trade_data['close'].iloc[-1] if not recent_trade_data.empty else current_price\n\n                        # Sklearn RF prediction\n                        sklearn_predicted = last_sklearn_prediction\n                        if bot_state.get(\"sklearn_rf_model\"):\n                            try:\n                                sklearn_predicted = predict_sklearn_price(\n                                    bot_state[\"sklearn_rf_model\"], bot_state[\"scaler_sklearn_rf\"],\n                                    config.SKLEARN_LOOKBACK, recent_trade_data, current_price, last_sklearn_prediction\n                                )\n                                logger.info(f\"Sklearn Prediction: timestamp={log_ref_timestamp}, predicted_price={sklearn_predicted:.2f}, current_close={log_ref_current_close:.2f}\")\n                            except Exception as e:\n                                logger.error(f\"Sklearn prediction failed: {e}\")\n                                sklearn_predicted = last_sklearn_prediction or current_price\n\n                        # PyTorch prediction\n                        pytorch_predicted = last_pytorch_prediction\n                        if bot_state.get(\"pytorch_model\"):\n                            try:\n                                pytorch_predicted = predict_pytorch_price(\n                                    bot_state[\"pytorch_model\"], bot_state[\"pytorch_scaler\"], bot_state[\"pytorch_target_scaler\"],\n                                    config.PYTORCH_LOOKBACK, recent_trade_data, current_price, last_pytorch_prediction\n                                )\n                                logger.info(f\"Pytorch Prediction: timestamp={log_ref_timestamp}, predicted_price={pytorch_predicted:.2f}, current_close={log_ref_current_close:.2f}\")\n                            except Exception as e:\n                                logger.error(f\"Pytorch prediction failed: {e}\")\n                                pytorch_predicted = last_pytorch_prediction or current_price\n\n                        # XGBoost prediction\n                        xgb_predicted = last_xgb_prediction\n                        if bot_state.get(\"xgb_model\"):\n                            try:\n                                xgb_predicted = predict_xgboost_price(\n                                    bot_state[\"xgb_model\"], bot_state[\"xgb_scaler\"],\n                                    60, recent_trade_data, current_price, last_xgb_prediction  # Fixed lookback=60\n                                )\n                                logger.info(f\"XGBoost Prediction: timestamp={log_ref_timestamp}, predicted_price={xgb_predicted:.2f}, current_close={log_ref_current_close:.2f}\")\n                            except Exception as e:\n                                logger.error(f\"XGBoost prediction failed: {e}\")\n                                xgb_predicted = last_xgb_prediction or current_price\n\n                        # Meta-model prediction\n                        meta_predicted = log_ref_current_close\n                        if bot_state.get(\"meta_model\") and bot_state.get(\"meta_scaler\") and all(np.isfinite([sklearn_predicted, pytorch_predicted, xgb_predicted])):\n                            volatility = recent_trade_data[\"volatility\"].iloc[-1] if not recent_trade_data.empty else 0.1\n                            try:\n                                meta_predicted = predict_meta_model(\n                                    bot_state[\"meta_model\"], bot_state[\"meta_scaler\"],\n                                    sklearn_predicted, pytorch_predicted, xgb_predicted, volatility, log_ref_current_close\n                                )\n                                logger.info(f\"Meta-Model Prediction: timestamp={log_ref_timestamp}, predicted_price={meta_predicted:.2f}, current_close={log_ref_current_close:.2f}\")\n                            except Exception as e:\n                                logger.error(f\"Meta-model prediction failed: {e}\")\n                                valid_preds = [p for p in [sklearn_predicted, pytorch_predicted, xgb_predicted] if np.isfinite(p)]\n                                meta_predicted = np.mean(valid_preds) if valid_preds else log_ref_current_close\n                                logger.info(f\"Meta-Model Fallback (mean of base predictions): timestamp={log_ref_timestamp}, predicted_price={meta_predicted:.2f}, current_close={log_ref_current_close:.2f}\")\n\n                        # Validate predictions\n                        valid_predictions = [\n                            p for p in [sklearn_predicted, pytorch_predicted, xgb_predicted, meta_predicted]\n                            if np.isfinite(p) and 1000 < p < 10000\n                        ]\n                        if not valid_predictions:\n                            logger.warning(\"No valid ML predictions, using current price\")\n                            sklearn_predicted = pytorch_predicted = xgb_predicted = meta_predicted = current_price\n                        else:\n                            avg_prediction = sum(valid_predictions) / len(valid_predictions)\n                            sklearn_predicted = sklearn_predicted if np.isfinite(sklearn_predicted) and 1000 < sklearn_predicted < 10000 else avg_prediction\n                            pytorch_predicted = pytorch_predicted if np.isfinite(pytorch_predicted) and 1000 < pytorch_predicted < 10000 else avg_prediction\n                            xgb_predicted = xgb_predicted if np.isfinite(xgb_predicted) and 1000 < xgb_predicted < 10000 else avg_prediction\n                            meta_predicted = meta_predicted if np.isfinite(meta_predicted) and 1000 < meta_predicted < 10000 else avg_prediction\n\n                        last_sklearn_prediction = sklearn_predicted\n                        last_pytorch_prediction = pytorch_predicted\n                        last_xgb_prediction = xgb_predicted\n\n                        # Online updates\n                        if len(recent_trade_data) >= config.PYTORCH_LOOKBACK:\n                            # Sklearn SGD update\n                            X_sgd = recent_trade_data.tail(config.SKLEARN_LOOKBACK)[required_features]\n                            y_sgd = recent_trade_data[\"close\"].tail(config.SKLEARN_LOOKBACK).values\n                            logger.debug(f\"Sklearn SGD update: X shape={X_sgd.shape}, y shape={y_sgd.shape}\")\n                            if bot_state.get(\"sklearn_sgd_model\"):\n                                bot_state[\"sklearn_sgd_model\"] = online_update_sklearn(\n                                    bot_state[\"sklearn_sgd_model\"], bot_state[\"scaler_sklearn_sgd\"], X_sgd, y_sgd\n                                )\n                                logger.info(\"Sklearn SGD model updated online\")\n                            else:\n                                logger.error(\"SGDRegressor model not initialized\")\n\n                            # PyTorch update\n                            X_pytorch = recent_trade_data.tail(config.PYTORCH_LOOKBACK)[required_features]\n                            y_pytorch = recent_trade_data[\"close\"].tail(config.PYTORCH_LOOKBACK)\n                            logger.debug(f\"PyTorch update: X shape={X_pytorch.shape}, y shape={y_pytorch.shape}\")\n\n                            if bot_state.get(\"pytorch_model\"):\n                                if bot_state.get(\"pytorch_scaler\") is not None and bot_state.get(\"pytorch_target_scaler\") is not None:\n                                    bot_state[\"pytorch_model\"] = online_update_pytorch(\n                                        bot_state[\"pytorch_model\"], bot_state[\"pytorch_scaler\"], bot_state[\"pytorch_target_scaler\"],\n                                        X_pytorch, y_pytorch, config.DEVICE\n                                    )\n                                    logger.info(\"PyTorch model updated online\")\n                                else:\n                                    logger.error(\"PyTorch scaler or target scaler is None, skipping PyTorch online update\")\n                            else:\n                                logger.error(\"PyTorch model not initialized\")\n\n                            logger.info(\"Performed online model updates\")\n                    except Exception as ml_error:\n                        logger.error(f\"Error in ML predictions or updates: {ml_error}\")\n\n                # 1. Fetch Market Data\n                current_volume = 0.0\n                try:\n                    ticker = exchange.fetch_ticker(config.SYMBOL)\n                    if not ticker or \"last\" not in ticker:\n                        logger.error(\"Failed to fetch ticker data, skipping iteration\")\n                        time.sleep(config.CHECK_ORDER_FREQUENCY)\n                        continue\n                    current_price = float(ticker[\"last\"])\n                    current_volume = float(ticker[\"baseVolume\"]) if ticker.get(\"baseVolume\") else 0\n                    minute_key = pd.Timestamp.now(tz=\"UTC\").floor(\"1min\")\n                    trade_counts[minute_key] = trade_counts.get(minute_key, 0) + 1\n                    logger.debug(f\"Fetched market data: price={current_price:.2f}, volume={current_volume:.2f}\")\n                except Exception as market_error:\n                    logger.error(f\"Error fetching market data: {market_error}\")\n                    time.sleep(config.CHECK_ORDER_FREQUENCY)\n                    continue\n\n                # 2. Update Balances\n                for attempt in range(3):\n                    try:\n                        eth_balance, usd_balance = sync_balances(exchange)\n                        logger.debug(\n                            f\"Balance updated (attempt {attempt + 1}/3): ETH={eth_balance:.6f}, USD={usd_balance:.2f}\"\n                        )\n                        break\n                    except ccxt.RateLimitExceeded as rate_error:\n                        logger.warning(f\"Rate limit exceeded on balance sync attempt {attempt + 1}/3: {rate_error}\")\n                        time.sleep(1)\n                    except Exception as balance_error:\n                        logger.error(f\"Balance sync attempt {attempt + 1}/3 failed: {balance_error}\")\n                        time.sleep(1)\n                else:\n                    logger.error(\"Failed to sync balances after 3 attempts, pausing bot\")\n                    bot_state[\"paused\"] = True\n                    time.sleep(config.CHECK_ORDER_FREQUENCY)\n                    continue\n                \n                # 3. Refresh Data for ML Predictions\n                try:\n                    logger.info(\"Checking for data refresh: ohlcv_df_rows=%d, last_timestamp=%s\",\n                                len(ohlcv_df), ohlcv_df['timestamp'].iloc[-1] if not ohlcv_df.empty else 'None')\n\n                    if not hasattr(_update_live_data_from_websocket, \"last_ohlcv_update_log_time\"):\n                        _update_live_data_from_websocket.last_ohlcv_update_log_time = 0\n                        _update_live_data_from_websocket.ohlcv_log_interval = 300  # 5 minutes\n                        logger.info(\"Initialized WebSocket update logging: interval=%ds\", _update_live_data_from_websocket.ohlcv_log_interval)\n\n                    if current_time - last_data_refresh > 60:  # Refresh every 60 seconds\n                        logger.info(\"Starting data refresh: current_time=%s\", pd.Timestamp.now(tz=\"UTC\"))\n                        try:\n                            # Prevent duplicate WebSocket updates\n                            if hasattr(_update_live_data_from_websocket, \"lock\"):\n                                if not _update_live_data_from_websocket.lock.acquire(blocking=False):\n                                    logger.debug(\"Skipping WebSocket update due to active lock\")\n                                    return\n                            else:\n                                _update_live_data_from_websocket.lock = threading.Lock()\n                                _update_live_data_from_websocket.lock.acquire()\n                            logger.info(\"Acquired WebSocket update lock\")\n\n                            try:\n                                if (current_time - getattr(_update_live_data_from_websocket, \"last_update\", 0) <\n                                        config.WEBSOCKET_MIN_UPTIME):\n                                    logger.debug(\"Skipping redundant WebSocket update, last_update=%.2fs ago\",\n                                                current_time - _update_live_data_from_websocket.last_update)\n                                    return\n                                _update_live_data_from_websocket.last_update = current_time\n                                logger.info(\"Proceeding with WebSocket data update\")\n\n                                try:\n                                    ohlcv_df, raw_trades_for_ohlcv_df, updated = _update_live_data_from_websocket(\n                                        websocket_manager, ohlcv_df, raw_trades_for_ohlcv_df)\n                                except Exception as ws_update_error:\n                                    logger.error(\"Failed to update WebSocket data: %s\", str(ws_update_error))\n                                    raise\n\n                                if updated and not ohlcv_df.empty:\n                                    num_new_candles = len(ohlcv_df) - len(ohlcv_df.drop_duplicates())\n                                    total_rows = len(ohlcv_df)\n                                    if num_new_candles > 0:\n                                        current_time_epoch = time.time()\n                                        if (current_time_epoch - _update_live_data_from_websocket.last_ohlcv_update_log_time >=\n                                                _update_live_data_from_websocket.ohlcv_log_interval):\n                                            logger.info(\"Updated OHLCV data with %d new candle(s) from WebSocket. Total rows=%d, last_close=%.2f\",\n                                                        num_new_candles, total_rows, ohlcv_df['close'].iloc[-1])\n                                            _update_live_data_from_websocket.last_ohlcv_update_log_time = current_time_epoch\n                                        else:\n                                            logger.debug(\"Added %d new candle(s) via WebSocket. Total rows=%d (INFO log throttled)\",\n                                                        num_new_candles, total_rows)\n                                    else:\n                                        logger.debug(\"Processed WebSocket data, 0 new candles added. Total rows=%d\", total_rows)\n\n                                    # Define dynamic defaults using WebSocket data\n                                    close_mean = ohlcv_df[\"close\"].mean() if not ohlcv_df.empty else current_price\n                                    defaults = {\n                                        \"rsi\": ohlcv_df[\"rsi\"].mean() if not ohlcv_df.empty and \"rsi\" in ohlcv_df else config.LOG_DEFAULT_RSI,\n                                        \"ema\": close_mean,\n                                        \"volatility\": ohlcv_df[\"volatility\"].mean() if not ohlcv_df.empty and \"volatility\" in ohlcv_df else config.LOG_DEFAULT_VOLATILITY,\n                                        \"macd\": config.LOG_DEFAULT_MACD,\n                                        \"macd_signal\": config.LOG_DEFAULT_MACD_SIGNAL,\n                                        \"bollinger_upper\": close_mean,\n                                        \"bollinger_lower\": close_mean,\n                                        \"momentum\": config.LOG_DEFAULT_MOMENTUM,\n                                        \"volume_trend\": config.LOG_DEFAULT_VOLUME_TREND,\n                                        \"atr\": close_mean * config.LOG_DEFAULT_ATR,\n                                        \"vwap\": close_mean,\n                                        \"predicted_price\": ohlcv_df[\"close\"].iloc[-1] if not ohlcv_df.empty else current_price,\n                                        \"grid_level\": 0,\n                                        \"trades\": int(ohlcv_df[\"trades\"].mean()) if not ohlcv_df.empty and \"trades\" in ohlcv_df else 0,\n                                        \"close\": close_mean,\n                                        \"high\": ohlcv_df[\"high\"].mean() if not ohlcv_df.empty and \"high\" in ohlcv_df else close_mean * 1.001,\n                                        \"low\": ohlcv_df[\"low\"].mean() if not ohlcv_df.empty and \"low\" in ohlcv_df else close_mean * 0.999,\n                                        \"open\": close_mean,\n                                        \"volume\": ohlcv_df[\"volume\"].mean() if not ohlcv_df.empty and \"volume\" in ohlcv_df else 0.0,\n                                        \"price_spread\": ohlcv_df[\"price_spread\"].mean() if not ohlcv_df.empty and \"price_spread\" in ohlcv_df else 0.0,\n                                        \"returns\": ohlcv_df[\"returns\"].mean() if not ohlcv_df.empty and \"returns\" in ohlcv_df else 0.0,\n                                        \"volume_change\": ohlcv_df[\"volume_change\"].mean() if not ohlcv_df.empty and \"volume_change\" in ohlcv_df else 0.0,\n                                        \"trade_intensity\": ohlcv_df[\"trade_intensity\"].mean() if not ohlcv_df.empty and \"trade_intensity\" in ohlcv_df else 0.0\n                                    }\n                                    logger.info(\"Defined dynamic defaults: rsi=%.2f, volatility=%.4f, atr=%.2f, price_spread=%.2f\",\n                                                defaults[\"rsi\"], defaults[\"volatility\"], defaults[\"atr\"], defaults[\"price_spread\"])\n\n                                    # Ensure ohlcv_df has all required columns\n                                    required_columns = [\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n                                    missing_columns = [c for c in required_columns if c not in ohlcv_df.columns]\n                                    if missing_columns:\n                                        logger.info(\"Missing columns in ohlcv_df: %s, adding with defaults\", missing_columns)\n                                        for col in missing_columns:\n                                            if col == \"timestamp\":\n                                                ohlcv_df[\"timestamp\"] = pd.Timestamp.now(tz=\"UTC\")\n                                            elif col in [\"open\", \"high\", \"low\", \"close\"]:\n                                                ohlcv_df[col] = close_mean\n                                            elif col == \"volume\":\n                                                ohlcv_df[col] = 0.0\n\n                                    # Validate and fix timestamps\n                                    if \"timestamp\" in ohlcv_df:\n                                        logger.debug(\"Raw ohlcv_df timestamps before conversion: %s\", ohlcv_df['timestamp'].head().to_list())\n                                        ohlcv_df[\"timestamp\"] = pd.to_datetime(ohlcv_df[\"timestamp\"], errors=\"coerce\", utc=True)\n                                        if ohlcv_df[\"timestamp\"].isna().any():\n                                            logger.info(\"Found %d invalid timestamps in ohlcv_df, filling with current time\",\n                                                        ohlcv_df['timestamp'].isna().sum())\n                                            ohlcv_df[\"timestamp\"] = ohlcv_df[\"timestamp\"].fillna(pd.Timestamp.now(tz=\"UTC\"))\n                                    else:\n                                        logger.info(\"No timestamp column in ohlcv_df, setting to current time\")\n                                        ohlcv_df[\"timestamp\"] = pd.Timestamp.now(tz=\"UTC\")\n\n                                    # Fill NaN values in OHLCV columns with forward/backward fill\n                                    for col in [\"open\", \"high\", \"low\", \"close\", \"volume\"]:\n                                        if ohlcv_df[col].isna().any():\n                                            logger.info(\"Filling %d NaN values in ohlcv_df[%s] with forward/backward fill\",\n                                                        ohlcv_df[col].isna().sum(), col)\n                                            ohlcv_df[col] = ohlcv_df[col].ffill().bfill()\n                                            if ohlcv_df[col].isna().any():\n                                                logger.info(\"Persisting %d NaNs in ohlcv_df[%s], filling with %s\",\n                                                            ohlcv_df[col].isna().sum(), col, defaults.get(col, 0.0))\n                                                ohlcv_df[col] = ohlcv_df[col].fillna(defaults.get(col, 0.0))\n\n                                    # Ensure ohlcv_df has all required features\n                                    required_features = [\n                                        \"close\", \"volume\", \"trades\", \"rsi\", \"ema\", \"macd\", \"macd_signal\",\n                                        \"bollinger_upper\", \"bollinger_lower\", \"momentum\", \"volume_trend\",\n                                        \"atr\", \"vwap\", \"predicted_price\", \"grid_level\", \"volatility\",\n                                        \"high\", \"low\", \"price_spread\", \"returns\", \"volume_change\", \"trade_intensity\"\n                                    ]\n                                    missing_features = [f for f in required_features if f not in ohlcv_df.columns]\n                                    if missing_features:\n                                        logger.info(\"Missing features in ohlcv_df: %s, adding with defaults\", missing_features)\n                                        for feature in missing_features:\n                                            ohlcv_df[feature] = defaults.get(feature, 0.0)\n\n                                    # Compute technical indicators with validation\n                                    try:\n                                        logger.info(\"Computing technical indicators for ohlcv_df\")\n                                        ohlcv_df[\"rsi\"] = compute_rsi(ohlcv_df[\"close\"], periods=config.RSI_PERIOD)\n                                        ohlcv_df[\"ema\"] = compute_ema(ohlcv_df[\"close\"], span=config.EMA_SPAN)\n                                        ohlcv_df[\"volatility\"] = compute_volatility(ohlcv_df, periods=config.VOLATILITY_WINDOW)\n                                        ohlcv_df[\"macd\"], ohlcv_df[\"macd_signal\"] = compute_macd(\n                                            ohlcv_df[\"close\"],\n                                            fast=config.MACD_FAST,\n                                            slow=config.MACD_SLOW,\n                                            signal=config.MACD_SIGNAL,\n                                        )\n                                        ohlcv_df[\"bollinger_upper\"], ohlcv_df[\"bollinger_lower\"] = compute_bollinger(\n                                            ohlcv_df[\"close\"],\n                                            window=config.BOLLINGER_WINDOW,\n                                            num_std=config.BOLLINGER_NUM_STD,\n                                        )\n                                        ohlcv_df[\"momentum\"] = compute_momentum(ohlcv_df[\"close\"], periods=config.MOMENTUM_PERIOD)\n                                        ohlcv_df[\"volume_trend\"] = compute_volume_trend(ohlcv_df[\"volume\"], window=5)\n                                        ohlcv_df[\"atr\"] = compute_atr(\n                                            ohlcv_df[\"high\"],\n                                            ohlcv_df[\"low\"],\n                                            ohlcv_df[\"close\"],\n                                            periods=config.ATR_PERIOD,\n                                        )\n                                        ohlcv_df[\"vwap\"] = compute_vwap(ohlcv_df, period=config.VWAP_PERIOD)\n                                        ohlcv_df[\"predicted_price\"] = ohlcv_df[\"close\"].shift(-1).fillna(ohlcv_df[\"close\"].iloc[-1])\n                                        ohlcv_df[\"grid_level\"] = 0\n                                        logger.info(\"Computed indicators: atr=%.2f, vwap=%.2f, rsi=%.2f, volatility=%.4f, price_spread=%.2f\",\n                                                    ohlcv_df['atr'].iloc[-1], ohlcv_df['vwap'].iloc[-1],\n                                                    ohlcv_df['rsi'].iloc[-1], ohlcv_df['volatility'].iloc[-1],\n                                                    ohlcv_df['price_spread'].iloc[-1])\n                                    except Exception as e:\n                                        logger.error(\"Error computing indicators for ohlcv_df: %s, using defaults\", str(e))\n                                        for feature in required_features:\n                                            ohlcv_df[feature] = defaults.get(feature, 0.0)\n\n                                    # Fill NaN values in computed features with forward/backward fill\n                                    for feature in required_features:\n                                        if feature in ohlcv_df and ohlcv_df[feature].isna().any():\n                                            logger.info(\"Filling %d NaN values in ohlcv_df[%s] with forward/backward fill\",\n                                                        ohlcv_df[feature].isna().sum(), feature)\n                                            ohlcv_df[feature] = ohlcv_df[feature].ffill().bfill()\n                                            if ohlcv_df[feature].isna().any():\n                                                logger.info(\"Persisting %d NaNs in ohlcv_df[%s], filling with %s\",\n                                                            ohlcv_df[feature].isna().sum(), feature, defaults.get(feature, 0.0))\n                                                ohlcv_df[feature] = ohlcv_df[feature].fillna(defaults.get(feature, 0.0))\n                                        elif feature in ohlcv_df:\n                                            logger.debug(\"No NaN values in ohlcv_df[%s]: min=%.2f, max=%.2f\",\n                                                        feature, ohlcv_df[feature].min(), ohlcv_df[feature].max())\n\n                                    # Assign to recent_data and recent_trade_data\n                                    logger.info(\"Assigning data to recent_data and recent_trade_data: lookback=%d\", lookback)\n                                    if len(ohlcv_df) < lookback:\n                                        logger.info(\"Padding recent_data: ohlcv_df_rows=%d, needed=%d\", len(ohlcv_df), lookback)\n                                        for feature in required_features:\n                                            if feature not in historical_data.columns:\n                                                close_mean_hist = historical_data[\"close\"].mean() if \"close\" in historical_data else current_price\n                                                historical_data[feature] = defaults.get(\n                                                    feature,\n                                                    close_mean_hist if feature in [\"ema\", \"vwap\", \"bollinger_upper\",\n                                                                                \"bollinger_lower\", \"high\", \"low\"] else 0.0)\n                                        historical_subset = historical_data[sklearn_features].tail(lookback - len(ohlcv_df)).copy()\n                                        historical_subset[\"timestamp\"] = pd.to_datetime(\n                                            historical_subset[\"timestamp\"], errors=\"coerce\", utc=True).fillna(pd.Timestamp.now(tz=\"UTC\"))\n                                        other_features = [\n                                            \"timestamp\", \"close\", \"volume\", \"trades\", \"rsi\", \"ema\", \"volatility\", \"macd\",\n                                            \"macd_signal\", \"bollinger_upper\", \"bollinger_lower\", \"momentum\", \"volume_trend\",\n                                            \"high\", \"low\", \"atr\", \"vwap\", \"predicted_price\", \"grid_level\",\n                                            \"price_spread\", \"returns\", \"volume_change\", \"trade_intensity\"\n                                        ]\n                                        recent_data = pd.concat([historical_subset, ohlcv_df[sklearn_features]], ignore_index=True).tail(lookback)\n                                        recent_trade_data = pd.concat(\n                                            [historical_data[other_features].tail(lookback - len(ohlcv_df)), ohlcv_df[other_features]],\n                                            ignore_index=True).tail(lookback)\n                                    else:\n                                        other_features = [\n                                            \"timestamp\", \"close\", \"volume\", \"trades\", \"rsi\", \"ema\", \"volatility\", \"macd\",\n                                            \"macd_signal\", \"bollinger_upper\", \"bollinger_lower\", \"momentum\", \"volume_trend\",\n                                            \"high\", \"low\", \"atr\", \"vwap\", \"predicted_price\", \"grid_level\",\n                                            \"price_spread\", \"returns\", \"volume_change\", \"trade_intensity\"\n                                        ]\n                                        recent_data = ohlcv_df[sklearn_features].tail(lookback).copy()\n                                        recent_trade_data = ohlcv_df[other_features].tail(lookback).copy()\n                                        logger.info(\"Assigned recent_trade_data: rows=%d, last_timestamp=%s, last_close=%.2f, last_atr=%.2f, last_price_spread=%.2f\",\n                                                    len(recent_trade_data), recent_trade_data[\"timestamp\"].iloc[-1],\n                                                    recent_trade_data[\"close\"].iloc[-1], recent_trade_data[\"atr\"].iloc[-1],\n                                                    recent_trade_data[\"price_spread\"].iloc[-1])\n\n                                    # Validate timestamps\n                                    logger.info(\"Validating timestamps for recent_data and recent_trade_data\")\n                                    for dataset, name in [(recent_data, \"recent_data\"), (recent_trade_data, \"recent_trade_data\")]:\n                                        if (\"timestamp\" not in dataset or dataset[\"timestamp\"].isna().all() or\n                                                not pd.api.types.is_datetime64_any_dtype(dataset[\"timestamp\"])):\n                                            logger.info(\"Invalid timestamps in %s, setting to current time\", name)\n                                            dataset[\"timestamp\"] = pd.Series([pd.Timestamp.now(tz=\"UTC\")] * len(dataset), index=dataset.index)\n                                        dataset[\"timestamp\"] = pd.to_datetime(dataset[\"timestamp\"], errors=\"coerce\", utc=True)\n                                        if dataset[\"timestamp\"].isna().any():\n                                            logger.info(\"Found %d invalid timestamps in %s, filling with current time\",\n                                                        dataset[\"timestamp\"].isna().sum(), name)\n                                            dataset[\"timestamp\"] = dataset[\"timestamp\"].fillna(pd.Timestamp.now(tz=\"UTC\"))\n\n                                    # Initialize prediction_history if empty\n                                    if \"prediction_history\" not in bot_state or bot_state[\"prediction_history\"].empty:\n                                        logger.info(\"Initializing prediction_history\")\n                                        close_value = recent_trade_data[\"close\"].iloc[-1] if not recent_trade_data.empty and \"close\" in recent_trade_data else current_price\n                                        volatility_value = recent_trade_data[\"volatility\"].iloc[-1] if not recent_trade_data.empty and \"volatility\" in recent_trade_data else defaults[\"volatility\"]\n                                        actual_price = recent_trade_data[\"predicted_price\"].iloc[-1] if not recent_trade_data.empty and \"predicted_price\" in recent_trade_data else current_price\n                                        bot_state[\"prediction_history\"] = pd.DataFrame({\n                                            \"sklearn_pred\": [last_sklearn_prediction or close_value],\n                                            \"pytorch_pred\": [last_pytorch_prediction or close_value],\n                                            \"xgb_pred\": [last_xgb_prediction or close_value],\n                                            \"current_price\": [close_value],\n                                            \"volatility\": [volatility_value],\n                                            \"actual_price\": [actual_price]\n                                        })\n                                        logger.info(\"Initialized prediction_history: rows=1, close=%.2f, volatility=%.4f\",\n                                                    close_value, volatility_value)\n                                        logger.debug(\"Prediction_history details: %s\", bot_state['prediction_history'].iloc[-1].to_dict())\n\n                                    logger.debug(\"Recent_data columns: %s\", recent_data.columns.tolist())\n\n                            finally:\n                                _update_live_data_from_websocket.lock.release()\n                                logger.info(\"Released WebSocket update lock\")\n\n                        except Exception as ws_error:\n                                logger.error(\"Error updating WebSocket data: %s, falling back to historical data\", str(ws_error))\n                                try:\n                                    for feature in required_features:\n                                        if feature not in historical_data.columns:\n                                            close_mean = historical_data[\"close\"].mean() if \"close\" in historical_data else current_price\n                                            historical_data[feature] = defaults.get(\n                                                feature,\n                                                close_mean if feature in [\"ema\", \"vwap\", \"bollinger_upper\", \"bollinger_lower\", \"high\", \"low\"] else 0.0)\n                                    recent_data = historical_data[sklearn_features].tail(lookback).copy()\n                                    recent_trade_data = trade_data[other_features].tail(lookback).copy() if trade_data is not None else recent_data[other_features].copy()\n                                    recent_data[\"timestamp\"] = pd.to_datetime(recent_data[\"timestamp\"], errors=\"coerce\", utc=True).fillna(pd.Timestamp.now(tz=\"UTC\"))\n                                    recent_trade_data[\"timestamp\"] = pd.to_datetime(recent_trade_data[\"timestamp\"], errors=\"coerce\", utc=True).fillna(pd.Timestamp.now(tz=\"UTC\"))\n                                    logger.info(\"Assigned fallback data: recent_data_rows=%d, recent_trade_data_rows=%d\",\n                                                len(recent_data), len(recent_trade_data))\n                                    logger.debug(\"Recent_data columns (fallback): %s\", recent_data.columns.tolist())\n                                    logger.debug(\"Recent_trade_data columns (fallback): %s\", recent_trade_data.columns.tolist())\n\n                                    # Initialize prediction_history in error case\n                                    if \"prediction_history\" not in bot_state or bot_state[\"prediction_history\"].empty:\n                                        logger.info(\"Initializing prediction_history (fallback)\")\n                                        close_value = recent_trade_data[\"close\"].iloc[-1] if not recent_trade_data.empty and \"close\" in recent_trade_data else current_price\n                                        volatility_value = recent_trade_data[\"volatility\"].iloc[-1] if not recent_trade_data.empty and \"volatility\" in recent_trade_data else defaults[\"volatility\"]\n                                        actual_price = recent_trade_data[\"predicted_price\"].iloc[-1] if not recent_trade_data.empty and \"predicted_price\" in recent_trade_data else current_price\n                                        bot_state[\"prediction_history\"] = pd.DataFrame({\n                                            \"sklearn_pred\": [last_sklearn_prediction or close_value],\n                                            \"pytorch_pred\": [last_pytorch_prediction or close_value],\n                                            \"xgb_pred\": [last_xgb_prediction or close_value],\n                                            \"current_price\": [close_value],\n                                            \"volatility\": [volatility_value],\n                                            \"actual_price\": [actual_price]\n                                        })\n                                        logger.info(\"Initialized prediction_history (fallback): rows=1, close=%.2f, volatility=%.4f\",\n                                                    close_value, volatility_value)\n                                        logger.debug(\"Prediction_history details (fallback): %s\", bot_state['prediction_history'].iloc[-1].to_dict())\n                                except Exception as fallback_error:\n                                    logger.error(\"Error assigning fallback data: %s\", str(fallback_error))\n\n                        except Exception as ws_error:\n                            logger.error(\"Error in WebSocket update process: %s\", str(ws_error))\n\n                        last_data_refresh = current_time\n                        logger.info(\"Refreshed historical and trade data for ML predictions: duration=%.2fs\",\n                                    time.time() - current_time)\n                except Exception as refresh_error:\n                    logger.error(\"Error refreshing data for ML predictions: %s\", str(refresh_error))\n\n                # 4. Retraining\n                try:\n                    logger.info(\"Checking ML model retraining conditions: current_time=%s\", pd.Timestamp.now(tz=\"UTC\"))\n                    if current_time - last_retrain_check > config.RETRAIN_INTERVAL:  # Check every 1200 seconds\n                        logger.info(\"RETRAIN_INTERVAL met: time_since_last_check=%.2fs, interval=%ds\", \n                                    current_time - last_retrain_check, config.RETRAIN_INTERVAL)\n                        time_since_last_retrain = current_time - last_retrain_time\n                        min_data_rows = max(1, config.LOOKBACK // 600 + 80)  # ~80 rows\n                        should_retrain = time_since_last_retrain >= config.MAX_RETRAIN_INTERVAL or (\n                            time_since_last_retrain >= config.MIN_RETRAIN_INTERVAL and len(recent_data) >= min_data_rows\n                        )\n\n                        if should_retrain:\n                            logger.info(\"Retraining triggered: time_since_last_retrain=%.2fs, recent_data_rows=%d, min_data_rows=%d\",\n                                        time_since_last_retrain, len(recent_data), min_data_rows)\n                            # Use WebSocket ohlcv_df if sufficient, else fetch additional data\n                            if len(recent_data) < 61 or len(recent_trade_data) < 61:\n                                logger.info(\"Insufficient data for retraining: recent_data=%d, recent_trade_data=%d, needed=61\",\n                                            len(recent_data), len(recent_trade_data))\n                                try:\n                                    logger.info(\"Attempting WebSocket data update: ohlcv_df_rows=%d\", len(ohlcv_df))\n                                    # Ensure ohlcv_df has enough rows\n                                    if len(ohlcv_df) < 2 * config.LOOKBACK:\n                                        logger.info(\"Forcing WebSocket data update: ohlcv_df_rows=%d < needed=%d\",\n                                                    len(ohlcv_df), 2 * config.LOOKBACK)\n                                        ohlcv_df, raw_trades_for_ohlcv_df, updated = _update_live_data_from_websocket(\n                                            websocket_manager,\n                                            ohlcv_df,\n                                            raw_trades_for_ohlcv_df,\n                                        )\n                                        if updated and not ohlcv_df.empty:\n                                            logger.info(\"Updated ohlcv_df via WebSocket: new_rows=%d, last_close=%.2f\",\n                                                        len(ohlcv_df), ohlcv_df['close'].iloc[-1])\n\n                                    logger.info(\"Defining dynamic defaults for retraining\")\n                                    # Define dynamic defaults using WebSocket data\n                                    close_mean = ohlcv_df[\"close\"].mean() if not ohlcv_df.empty else current_price\n                                    defaults = {\n                                        \"rsi\": ohlcv_df[\"rsi\"].mean() if not ohlcv_df.empty and \"rsi\" in ohlcv_df else 50.0,\n                                        \"ema\": close_mean,\n                                        \"volatility\": ohlcv_df[\"volatility\"].mean() if not ohlcv_df.empty and \"volatility\" in ohlcv_df else 0.1,\n                                        \"macd\": 0.0,\n                                        \"macd_signal\": 0.0,\n                                        \"bollinger_upper\": close_mean,\n                                        \"bollinger_lower\": close_mean,\n                                        \"momentum\": 0.0,\n                                        \"volume_trend\": 0.0,\n                                        \"atr\": close_mean * 0.01,\n                                        \"vwap\": close_mean,\n                                        \"predicted_price\": ohlcv_df[\"close\"].iloc[-1] if not ohlcv_df.empty else current_price,\n                                        \"grid_level\": 0,\n                                        \"trades\": int(ohlcv_df[\"trades\"].mean()) if not ohlcv_df.empty and \"trades\" in ohlcv_df else 0,\n                                        \"close\": close_mean,\n                                        \"high\": ohlcv_df[\"high\"].mean() if not ohlcv_df.empty and \"high\" in ohlcv_df else close_mean * 1.001,\n                                        \"low\": ohlcv_df[\"low\"].mean() if not ohlcv_df.empty and \"low\" in ohlcv_df else close_mean * 0.999,\n                                        \"open\": close_mean,\n                                        \"volume\": ohlcv_df[\"volume\"].mean() if not ohlcv_df.empty and \"volume\" in ohlcv_df else 0.0,\n                                        \"price_spread\": ohlcv_df[\"price_spread\"].mean() if not ohlcv_df.empty and \"price_spread\" in ohlcv_df else 0.0,\n                                        \"returns\": ohlcv_df[\"returns\"].mean() if not ohlcv_df.empty and \"returns\" in ohlcv_df else 0.0,\n                                        \"volume_change\": ohlcv_df[\"volume_change\"].mean() if not ohlcv_df.empty and \"volume_change\" in ohlcv_df else 0.0,\n                                        \"trade_intensity\": ohlcv_df[\"trade_intensity\"].mean() if not ohlcv_df.empty and \"trade_intensity\" in ohlcv_df else 0.0\n                                    }\n                                    logger.info(\"Defined dynamic defaults: rsi=%.2f, volatility=%.4f, atr=%.2f, price_spread=%.2f\",\n                                                defaults[\"rsi\"], defaults[\"volatility\"], defaults[\"atr\"], defaults[\"price_spread\"])\n\n                                    # Use WebSocket data if sufficient\n                                    if len(ohlcv_df) >= 2 * config.LOOKBACK:\n                                        logger.info(\"Using WebSocket ohlcv_df for retraining: ohlcv_df_rows=%d\", len(ohlcv_df))\n                                        recent_data = ohlcv_df[sklearn_features].tail(2 * config.LOOKBACK).copy()\n                                        recent_trade_data = ohlcv_df[\n                                            [\n                                                \"timestamp\", \"close\", \"volume\", \"trades\", \"rsi\", \"ema\",\n                                                \"volatility\", \"macd\", \"macd_signal\", \"bollinger_upper\",\n                                                \"bollinger_lower\", \"momentum\", \"volume_trend\", \"high\",\n                                                \"low\", \"atr\", \"vwap\", \"predicted_price\", \"grid_level\",\n                                                \"price_spread\", \"returns\", \"volume_change\", \"trade_intensity\"\n                                            ]\n                                        ].tail(2 * config.LOOKBACK).copy()\n                                        logger.info(\"Assigned WebSocket data: recent_data_rows=%d, recent_trade_data_rows=%d\",\n                                                    len(recent_data), len(recent_trade_data))\n                                    else:\n                                        logger.info(\"Fetching additional trade data via API: ohlcv_df_rows=%d < needed=%d\",\n                                                    len(ohlcv_df), 2 * config.LOOKBACK)\n                                        trade_counts_total = pd.DataFrame()\n                                        try:\n                                            for attempt in range(7):\n                                                since = int(\n                                                    (current_time - (2 * config.LOOKBACK + attempt * 600) * 60) * 1000\n                                                )\n                                                until = int(current_time * 1000)\n                                                logger.info(\"Fetching trades: attempt=%d, since=%s, until=%s\",\n                                                            attempt + 1, pd.Timestamp(since, unit=\"ms\", tz=\"UTC\"), pd.Timestamp(until, unit=\"ms\", tz=\"UTC\"))\n                                                trades = exchange.fetch_trades(\n                                                    config.SYMBOL,\n                                                    limit=1000,\n                                                    since=since,\n                                                    params={\"until\": until},\n                                                )\n                                                if trades:\n                                                    trade_data = pd.DataFrame(trades)\n                                                    if \"timestamp\" in trade_data:\n                                                        trade_data[\"timestamp\"] = pd.to_datetime(\n                                                            trade_data[\"timestamp\"],\n                                                            unit=\"ms\",\n                                                            utc=True,\n                                                            errors=\"coerce\",\n                                                        )\n                                                        trade_data[\"timestamp\"] = trade_data[\"timestamp\"].fillna(\n                                                            pd.Timestamp.now(tz=\"UTC\")\n                                                        )\n                                                        trade_data[\"price\"] = trade_data[\"price\"].astype(float)\n                                                        trade_data[\"amount\"] = trade_data[\"amount\"].astype(float)\n                                                        trade_counts = (\n                                                            trade_data.groupby(pd.Grouper(key=\"timestamp\", freq=\"1min\"))\n                                                            .agg(\n                                                                {\n                                                                    \"price\": \"mean\",\n                                                                    \"amount\": \"sum\",\n                                                                    \"id\": \"count\",\n                                                                }\n                                                            )\n                                                            .reset_index()\n                                                        )\n                                                        trade_counts = trade_counts.rename(\n                                                            columns={\n                                                                \"id\": \"trades\",\n                                                                \"amount\": \"volume\",\n                                                                \"price\": \"close\",\n                                                            }\n                                                        )\n                                                        trade_counts_total = pd.concat(\n                                                            [trade_counts_total, trade_counts],\n                                                            ignore_index=True,\n                                                        )\n                                                        logger.info(\"Fetched %d trade records in attempt %d, total_records=%d\",\n                                                                    len(trade_counts), attempt + 1, len(trade_counts_total))\n                                                        if len(trade_counts_total) >= 122:\n                                                            break\n                                                time.sleep(exchange.rateLimit / 1000)\n                                        except Exception as trade_error:\n                                            logger.error(\"Failed to fetch trades: %s\", str(trade_error))\n\n                                        if not trade_counts_total.empty:\n                                            logger.info(\"Processing fetched trade data: total_records=%d\", len(trade_counts_total))\n                                            trade_counts_total = trade_counts_total.drop_duplicates(\n                                                subset=[\"timestamp\"], keep=\"last\"\n                                            ).sort_values(\"timestamp\")\n                                            if not recent_trade_data.empty:\n                                                recent_trade_data = pd.concat(\n                                                    [recent_trade_data, trade_counts_total],\n                                                    ignore_index=True,\n                                                )\n                                                recent_trade_data = (\n                                                    recent_trade_data.drop_duplicates(subset=[\"timestamp\"], keep=\"last\")\n                                                    .sort_values(\"timestamp\")\n                                                    .tail(2 * config.LOOKBACK)\n                                                )\n                                            else:\n                                                recent_trade_data = trade_counts_total.tail(2 * config.LOOKBACK)\n                                            logger.info(\"Updated recent_trade_data with trade data: rows=%d\", len(recent_trade_data))\n                                        else:\n                                            logger.warning(\"No trades fetched, using OHLCV-derived trade counts\")\n                                            if not ohlcv_df.empty:\n                                                recent_trade_data = (\n                                                    ohlcv_df[\n                                                        [\n                                                            \"timestamp\",\n                                                            \"close\",\n                                                            \"volume\",\n                                                            \"trades\",\n                                                        ]\n                                                    ]\n                                                    .tail(2 * config.LOOKBACK)\n                                                    .copy()\n                                                )\n                                                recent_trade_data[\"trades\"] = recent_trade_data[\"trades\"].fillna(\n                                                    defaults[\"trades\"]\n                                                )\n                                                logger.info(\"Updated recent_trade_data with OHLCV trades: rows=%d\", len(recent_trade_data))\n\n                                        logger.info(\"Fetching additional OHLCV data via API\")\n                                        try:\n                                            timeframe = \"1m\"\n                                            since = int(\n                                                (current_time - (2 * config.LOOKBACK + 40) * 60) * 1000\n                                            )\n                                            logger.info(\"Fetching OHLCV: timeframe=%s, since=%s, limit=%d\",\n                                                        timeframe, pd.Timestamp(since, unit=\"ms\", tz=\"UTC\"), 2 * config.LOOKBACK)\n                                            ohlcv = exchange.fetch_ohlcv(\n                                                config.SYMBOL,\n                                                timeframe,\n                                                since=since,\n                                                limit=2 * config.LOOKBACK,\n                                            )\n                                            if ohlcv:\n                                                ohlcv_df_new = pd.DataFrame(\n                                                    ohlcv,\n                                                    columns=[\n                                                        \"timestamp\",\n                                                        \"open\",\n                                                        \"high\",\n                                                        \"low\",\n                                                        \"close\",\n                                                        \"volume\",\n                                                    ],\n                                                )\n                                                ohlcv_df_new[\"timestamp\"] = pd.to_datetime(\n                                                    ohlcv_df_new[\"timestamp\"],\n                                                    unit=\"ms\",\n                                                    utc=True,\n                                                    errors=\"coerce\",\n                                                )\n                                                ohlcv_df_new[\"timestamp\"] = ohlcv_df_new[\"timestamp\"].fillna(\n                                                    pd.Timestamp.now(tz=\"UTC\")\n                                                )\n                                                logger.info(\"Fetched %d OHLCV records, computing indicators\", len(ohlcv_df_new))\n                                                if len(ohlcv_df_new) < config.BOLLINGER_WINDOW:\n                                                    logger.warning(\n                                                        \"Insufficient OHLCV data: rows=%d, need=%d\", len(ohlcv_df_new), config.BOLLINGER_WINDOW\n                                                    )\n                                                for col in [\"open\", \"high\", \"low\", \"close\", \"volume\"]:\n                                                    ohlcv_df_new[col] = ohlcv_df_new[col].ffill().bfill()\n                                                    if ohlcv_df_new[col].isna().any():\n                                                        ohlcv_df_new[col] = ohlcv_df_new[col].fillna(defaults.get(col, 0.0))\n                                                ohlcv_df_new[\"rsi\"] = compute_rsi(\n                                                    ohlcv_df_new[\"close\"],\n                                                    periods=config.RSI_PERIOD,\n                                                ).fillna(defaults[\"rsi\"])\n                                                ohlcv_df_new[\"ema\"] = compute_ema(\n                                                    ohlcv_df_new[\"close\"], span=config.EMA_SPAN\n                                                ).fillna(defaults[\"ema\"])\n                                                ohlcv_df_new[\"volatility\"] = compute_volatility(\n                                                    ohlcv_df_new, periods=config.VOLATILITY_WINDOW\n                                                ).fillna(defaults[\"volatility\"])\n                                                (\n                                                    ohlcv_df_new[\"macd\"],\n                                                    ohlcv_df_new[\"macd_signal\"],\n                                                ) = compute_macd(\n                                                    ohlcv_df_new[\"close\"],\n                                                    fast=config.MACD_FAST,\n                                                    slow=config.MACD_SLOW,\n                                                    signal=config.MACD_SIGNAL,\n                                                )\n                                                ohlcv_df_new[\"macd\"] = ohlcv_df_new[\"macd\"].fillna(defaults[\"macd\"])\n                                                ohlcv_df_new[\"macd_signal\"] = ohlcv_df_new[\"macd_signal\"].fillna(\n                                                    defaults[\"macd_signal\"]\n                                                )\n                                                (\n                                                    ohlcv_df_new[\"bollinger_upper\"],\n                                                    ohlcv_df_new[\"bollinger_lower\"],\n                                                ) = compute_bollinger(\n                                                    ohlcv_df_new[\"close\"],\n                                                    window=config.BOLLINGER_WINDOW,\n                                                    num_std=config.BOLLINGER_NUM_STD,\n                                                )\n                                                ohlcv_df_new[\"bollinger_upper\"] = ohlcv_df_new[\"bollinger_upper\"].fillna(\n                                                    defaults[\"bollinger_upper\"]\n                                                )\n                                                ohlcv_df_new[\"bollinger_lower\"] = ohlcv_df_new[\"bollinger_lower\"].fillna(\n                                                    defaults[\"bollinger_lower\"]\n                                                )\n                                                ohlcv_df_new[\"momentum\"] = compute_momentum(\n                                                    ohlcv_df_new[\"close\"],\n                                                    periods=config.MOMENTUM_PERIOD,\n                                                ).fillna(defaults[\"momentum\"])\n                                                ohlcv_df_new[\"volume_trend\"] = compute_volume_trend(\n                                                    ohlcv_df_new[\"volume\"], window=5\n                                                ).fillna(defaults[\"volume_trend\"])\n                                                ohlcv_df_new[\"atr\"] = compute_atr(\n                                                    ohlcv_df_new[\"high\"],\n                                                    ohlcv_df_new[\"low\"],\n                                                    ohlcv_df_new[\"close\"],\n                                                    periods=config.ATR_PERIOD,\n                                                ).fillna(defaults[\"atr\"])\n                                                ohlcv_df_new[\"vwap\"] = compute_vwap(\n                                                    ohlcv_df_new, period=config.VWAP_PERIOD\n                                                ).fillna(defaults[\"vwap\"])\n                                                ohlcv_df_new[\"predicted_price\"] = (\n                                                    ohlcv_df_new[\"close\"].shift(-1).fillna(defaults[\"predicted_price\"])\n                                                )\n                                                ohlcv_df_new[\"grid_level\"] = defaults[\"grid_level\"]\n                                                ohlcv_df_new[\"trades\"] = (\n                                                    recent_trade_data[\"trades\"]\n                                                    .iloc[-len(ohlcv_df_new) :]\n                                                    .reindex(ohlcv_df_new.index)\n                                                    .fillna(defaults[\"trades\"])\n                                                    if \"trades\" in recent_trade_data\n                                                    else defaults[\"trades\"]\n                                                )\n                                                ohlcv_df_new[\"price_spread\"] = (ohlcv_df_new[\"high\"] - ohlcv_df_new[\"low\"]).fillna(defaults[\"price_spread\"])\n                                                ohlcv_df_new[\"returns\"] = ohlcv_df_new[\"close\"].pct_change().fillna(defaults[\"returns\"])\n                                                ohlcv_df_new[\"volume_change\"] = ohlcv_df_new[\"volume\"].diff().fillna(defaults[\"volume_change\"])\n                                                ohlcv_df_new[\"trade_intensity\"] = (ohlcv_df_new[\"trades\"] / ohlcv_df_new[\"volume\"].replace(0, 1)).fillna(defaults[\"trade_intensity\"])\n                                                nan_counts = {f: ohlcv_df_new[f].isna().sum() for f in required_features}\n                                                if any(nan_counts.values()):\n                                                    logger.warning(\"NaN values in ohlcv_df_new: %s\", nan_counts)\n                                                    for feature in required_features:\n                                                        ohlcv_df_new[feature] = ohlcv_df_new[feature].fillna(defaults.get(feature, 0.0))\n                                                if not ohlcv_df.empty:\n                                                    ohlcv_df = pd.concat(\n                                                        [ohlcv_df, ohlcv_df_new],\n                                                        ignore_index=True,\n                                                    )\n                                                    ohlcv_df = (\n                                                        ohlcv_df.drop_duplicates(subset=[\"timestamp\"], keep=\"last\")\n                                                        .sort_values(\"timestamp\")\n                                                        .tail(2 * config.LOOKBACK)\n                                                    )\n                                                else:\n                                                    ohlcv_df = ohlcv_df_new.tail(2 * config.LOOKBACK)\n                                                recent_data = ohlcv_df[sklearn_features].tail(2 * config.LOOKBACK).copy()\n                                                recent_trade_data = ohlcv_df[\n                                                    [\n                                                        \"timestamp\", \"close\", \"volume\", \"trades\", \"rsi\", \"ema\",\n                                                        \"volatility\", \"macd\", \"macd_signal\", \"bollinger_upper\",\n                                                        \"bollinger_lower\", \"momentum\", \"volume_trend\", \"high\",\n                                                        \"low\", \"atr\", \"vwap\", \"predicted_price\", \"grid_level\",\n                                                        \"price_spread\", \"returns\", \"volume_change\", \"trade_intensity\"\n                                                    ]\n                                                ].tail(2 * config.LOOKBACK).copy()\n                                                logger.info(\"Updated data with OHLCV: ohlcv_df_rows=%d, recent_data_rows=%d, recent_trade_data_rows=%d\",\n                                                            len(ohlcv_df), len(recent_data), len(recent_trade_data))\n                                            else:\n                                                logger.warning(\"No OHLCV data fetched, proceeding with existing ohlcv_df\")\n                                            time.sleep(exchange.rateLimit / 1000)\n                                        except Exception as ohlcv_error:\n                                            logger.error(\"Error fetching/updating OHLCV data: %s\", str(ohlcv_error))\n                                            time.sleep(exchange.rateLimit / 1000)\n                                finally:\n                                    if hasattr(_update_live_data_from_websocket, \"lock\") and _update_live_data_from_websocket.lock.locked():\n                                        logger.info(\"Releasing WebSocket update lock\")\n                                        _update_live_data_from_websocket.lock.release()\n\n                            # Verify data after preparation\n                            logger.info(\"Verifying data for retraining: recent_data_rows=%d, recent_trade_data_rows=%d, needed=61\",\n                                        len(recent_data), len(recent_trade_data))\n                            if len(recent_data) < 61 or len(recent_trade_data) < 61:\n                                logger.warning(\"Insufficient data after preparation: recent_data=%d, recent_trade_data=%d\",\n                                            len(recent_data), len(recent_trade_data))\n                                last_retrain_check = current_time\n                                return\n\n                            logger.info(\"Starting ML model retraining: data_rows=%d, lookback=%d\",\n                                        len(recent_data), config.LOOKBACK // 100)\n                            try:\n                                start_time = time.time()\n                                sklearn_model_new, sklearn_scaler_new = None, None\n                                pytorch_model_new, pytorch_scaler_new = None, None\n                                xgb_model_new, xgb_scaler_new = None, None\n                                meta_model_new, meta_scaler_new = None, None\n\n                                # Prepare features for MSE computation\n                                features = [\n                                    \"close\", \"volume\", \"trades\", \"rsi\", \"ema\", \"volatility\", \"macd\", \"macd_signal\",\n                                    \"bollinger_upper\", \"bollinger_lower\", \"momentum\", \"volume_trend\", \"atr\", \"vwap\",\n                                    \"price_spread\", \"returns\", \"volume_change\", \"trade_intensity\"\n                                ]\n                                lookback = config.LOOKBACK // 100\n                                pytorch_lookback = min(lookback, 32)  # Smaller lookback for PyTorch\n                                logger.info(\"Prepared features for retraining: feature_count=%d, lookback=%d, pytorch_lookback=%d\",\n                                            len(features), lookback, pytorch_lookback)\n\n                                # Load or initialize models and scalers\n                                logger.info(\"Loading Sklearn model and scaler\")\n                                try:\n                                    if (\n                                        bot_state.get(\"sklearn_model\")\n                                        and os.path.exists(\"client_sklearn_model.pkl\")\n                                        and os.path.exists(\"client_sklearn_scaler.pkl\")\n                                    ):\n                                        sklearn_model_new = joblib.load(\"client_sklearn_model.pkl\")\n                                        sklearn_scaler_new = joblib.load(\"client_sklearn_scaler.pkl\")\n                                        logger.info(\"Loaded saved Sklearn model and scaler\")\n                                    else:\n                                        logger.info(\"No saved Sklearn model/scaler found\")\n                                except Exception as e:\n                                    logger.error(\"Failed to load Sklearn model/scaler: %s\", str(e))\n                                    sklearn_model_new, sklearn_scaler_new = None, None\n\n                                logger.info(\"Training Sklearn RF and SGD models\")\n                                try:\n                                    # Load scalers if available\n                                    if os.path.exists(\"client_sklearn_rf_scaler.pkl\"):\n                                        bot_state[\"scaler_sklearn_rf\"] = joblib.load(\"client_sklearn_rf_scaler.pkl\")\n                                        logger.info(\"Loaded RF scaler from client_sklearn_rf_scaler.pkl\")\n                                    else:\n                                        bot_state[\"scaler_sklearn_rf\"] = StandardScaler()\n                                        logger.info(\"Initialized new RF scaler\")\n                                    if os.path.exists(\"client_sklearn_sgd_scaler.pkl\"):\n                                        bot_state[\"scaler_sklearn_sgd\"] = joblib.load(\"client_sklearn_sgd_scaler.pkl\")\n                                        logger.info(\"Loaded SGD scaler from client_sklearn_sgd_scaler.pkl\")\n                                    else:\n                                        bot_state[\"scaler_sklearn_sgd\"] = StandardScaler()\n                                        logger.info(\"Initialized new SGD scaler\")\n\n                                    # Train sklearn models\n                                    rf_model, rf_scaler, sgd_model, sgd_scaler, sklearn_lookback = train_sklearn_predictor(historical_data, trade_data)\n                                    if rf_model is not None and sgd_model is not None:\n                                        bot_state[\"sklearn_rf_model\"] = rf_model\n                                        bot_state[\"scaler_sklearn_rf\"] = rf_scaler\n                                        bot_state[\"sklearn_sgd_model\"] = sgd_model\n                                        bot_state[\"scaler_sklearn_sgd\"] = sgd_scaler\n                                        bot_state[\"sklearn_lookback\"] = sklearn_lookback\n                                        logger.info(\"Sklearn RF and SGD models trained successfully: lookback=%d\", sklearn_lookback)\n                                    else:\n                                        logger.error(\"Sklearn model training failed: RF or SGD model is None\")\n                                except Exception as sklearn_error:\n                                    logger.error(\"Failed to train Sklearn model: %s\", str(sklearn_error))\n\n                                logger.info(\"Loading PyTorch model and scaler\")\n                                try:\n                                    if bot_state.get(\"pytorch_model\"):\n                                        bot_state[\"pytorch_model\"] = LSTMPricePredictor(input_size=len(features))\n                                        if os.path.exists(\"client_pytorch_model.pth\") and os.path.exists(\n                                            \"client_pytorch_scaler.pkl\"\n                                        ):\n                                            bot_state[\"pytorch_model\"].load_state_dict(\n                                                torch.load(\"client_pytorch_model.pth\")\n                                            )\n                                            pytorch_scaler_new = joblib.load(\"client_pytorch_scaler.pkl\")\n                                            pytorch_model_new = bot_state[\"pytorch_model\"]\n                                            logger.info(\"Loaded saved PyTorch model and scaler\")\n                                        else:\n                                            pytorch_model_new = bot_state[\"pytorch_model\"]\n                                            pytorch_scaler_new = None\n                                            logger.info(\"No saved PyTorch model/scaler found\")\n                                except Exception as e:\n                                    logger.error(\"Failed to load PyTorch model/scaler: %s\", str(e))\n                                    pytorch_model_new, pytorch_scaler_new = None, None\n\n                                logger.info(\"Training XGBoost model\")\n                                try:\n                                    # Load XGBoost scaler if available\n                                    if os.path.exists(\"client_xgb_scaler.pkl\"):\n                                        bot_state[\"xgb_scaler\"] = joblib.load(\"client_xgb_scaler.pkl\")\n                                        logger.info(\"Loaded XGBoost scaler from client_xgb_scaler.pkl\")\n                                    else:\n                                        bot_state[\"xgb_scaler\"] = StandardScaler()\n                                        logger.info(\"Initialized new XGBoost scaler\")\n\n                                    # Train XGBoost model\n                                    xgb_model, xgb_scaler, xgb_lookback = train_xgboost_predictor(historical_data, trade_data)\n                                    if xgb_model is not None:\n                                        bot_state[\"xgb_model\"] = xgb_model\n                                        bot_state[\"xgb_scaler\"] = xgb_scaler\n                                        logger.info(\"XGBoost model trained successfully: lookback=%d\", xgb_lookback)\n                                    else:\n                                        logger.error(\"XGBoost model training failed\")\n                                except Exception as xgb_error:\n                                    logger.error(\"Failed to train XGBoost model: %s\", str(xgb_error))\n\n                                logger.info(\"Loading Meta-Model and scaler\")\n                                try:\n                                    if (\n                                        bot_state.get(\"meta_model\")\n                                        and os.path.exists(\"client_meta_model.pkl\")\n                                        and os.path.exists(\"client_meta_scaler.pkl\")\n                                    ):\n                                        meta_model_new = joblib.load(\"client_meta_model.pkl\")\n                                        meta_scaler_new = joblib.load(\"client_meta_scaler.pkl\")\n                                        logger.info(\"Loaded saved Meta-Model and scaler\")\n                                    else:\n                                        logger.info(\"No saved Meta-Model/scaler found\")\n                                except Exception as e:\n                                    logger.error(\"Failed to load Meta-Model/scaler: %s\", str(e))\n                                    meta_model_new, meta_scaler_new = None, None\n\n                                if bot_state.get(\"sklearn_model\") and (\n                                    sklearn_model_new is None or sklearn_scaler_new is None\n                                ):\n                                    logger.info(\"Retraining Sklearn model: recent_data_rows=%d\", len(recent_data))\n                                    try:\n                                        (\n                                            sklearn_model_new,\n                                            sklearn_scaler_new,\n                                            sklearn_lookback,\n                                        ) = train_sklearn_predictor(\n                                            recent_data,\n                                            recent_trade_data,\n                                            lookback=lookback,\n                                        )\n                                        if sklearn_model_new and sklearn_scaler_new:\n                                            scaled_features = sklearn_scaler_new.transform(recent_data[features])\n                                            X, y = [], []\n                                            for i in range(lookback, len(scaled_features)):\n                                                X.append(scaled_features[i - lookback : i].flatten())\n                                                y.append(scaled_features[i, features.index(\"close\")])\n                                            X = np.array(X)\n                                            y = np.array(y)\n                                            train_size = int(len(X) * 0.8)\n                                            if train_size >= 5 and len(X) - train_size >= 2:\n                                                X_train, X_test = X[:train_size], X[train_size:]\n                                                y_train, y_test = y[:train_size], y[train_size:]\n                                                y_train_pred = sklearn_model_new.predict(X_train)\n                                                y_test_pred = sklearn_model_new.predict(X_test)\n                                                train_mse = mean_squared_error(y_train, y_train_pred)\n                                                test_mse = mean_squared_error(y_test, y_test_pred)\n                                                sklearn_model_new.mse_train = train_mse\n                                                sklearn_model_new.mse_test = test_mse\n                                                logger.info(\"Sklearn model retrained: train_samples=%d, test_samples=%d, train_mse=%.6f, test_mse=%.6f\",\n                                                            len(X_train), len(X_test), train_mse, test_mse)\n                                            else:\n                                                train_mse = \"N/A\"\n                                                test_mse = \"N/A\"\n                                                logger.warning(\"Insufficient Sklearn split: train=%d, test=%d\", train_size, len(X) - train_size)\n                                            joblib.dump(sklearn_scaler_new, \"client_sklearn_scaler.pkl\")\n                                            joblib.dump(sklearn_model_new, \"client_sklearn_model.pkl\")\n                                            logger.info(\"Saved Sklearn scaler and model to client_sklearn_scaler.pkl and client_sklearn_model.pkl\")\n                                        else:\n                                            logger.warning(\"Sklearn retraining returned None\")\n                                    except Exception as sklearn_error:\n                                        logger.error(\"Sklearn retraining failed: %s\", str(sklearn_error))\n\n                                if bot_state.get(\"pytorch_model\") and (\n                                    pytorch_model_new is None or pytorch_scaler_new is None or pytorch_target_scaler_new is None\n                                ):\n                                    logger.info(\"Retraining PyTorch model: recent_trade_data_rows=%d, lookback=%d\",\n                                                len(recent_trade_data), pytorch_lookback)\n                                    try:\n                                        if len(recent_trade_data) < 10:\n                                            raise ValueError(\n                                                \"Insufficient data for PyTorch: rows=%d, need=10\" % len(recent_trade_data)\n                                            )\n                                        num_epochs = getattr(config, \"MIN_PYTORCH_NUM_EPOCHS\", 200)\n                                        if not isinstance(num_epochs, int) or num_epochs <= 0:\n                                            logger.warning(\"Invalid MIN_PYTORCH_NUM_EPOCHS=%s, using default=200\", num_epochs)\n                                            num_epochs = 200\n                                        logger.info(\"Training PyTorch model: epochs=%d\", num_epochs)\n                                        (\n                                            pytorch_model_new,\n                                            pytorch_scaler_new,\n                                            pytorch_target_scaler_new\n                                        ) = train_pytorch_predictor(recent_trade_data, recent_data, lookback_minutes=pytorch_lookback)\n                                        if not (pytorch_model_new and pytorch_scaler_new and pytorch_target_scaler_new):\n                                            logger.warning(\"PyTorch retraining returned None, falling back to initial training function\")\n                                            pytorch_model_new, pytorch_scaler_new, pytorch_target_scaler_new = train_pytorch_predictor(historical_data, historical_data, lookback_minutes=pytorch_lookback, num_epochs=num_epochs)\n                                            if pytorch_model_new and pytorch_scaler_new and pytorch_target_scaler_new:\n                                                logger.info(\"Fallback initial PyTorch training succeeded after retrain failure\")\n                                            else:\n                                                logger.error(\"Fallback initial PyTorch training also failed\")\n                                        if pytorch_model_new and pytorch_scaler_new and pytorch_target_scaler_new:\n                                            scaled_features = pytorch_scaler_new.transform(recent_trade_data[features])\n                                            X, y = [], []\n                                            for i in range(pytorch_lookback, len(scaled_features)):\n                                                X.append(scaled_features[i - pytorch_lookback : i])\n                                                y.append(scaled_features[i, features.index(\"close\")])\n                                            X = np.array(X)\n                                            y = np.array(y)\n                                            train_size = int(len(X) * 0.8)\n                                            if train_size >= 8 and len(X) - train_size >= 2:\n                                                X_train, X_test = X[:train_size], X[train_size:]\n                                                y_train, y_test = y[:train_size], y[train_size:]\n                                                X_train = torch.FloatTensor(X_train).to(config.DEVICE)\n                                                y_train = torch.FloatTensor(y_train).view(-1, 1).to(config.DEVICE)\n                                                X_test = torch.FloatTensor(X_test).to(config.DEVICE)\n                                                y_test = torch.FloatTensor(y_test).view(-1, 1).to(config.DEVICE)\n                                                pytorch_model_new.eval()\n                                                with torch.no_grad():\n                                                    train_outputs = pytorch_model_new(X_train)\n                                                    test_outputs = pytorch_model_new(X_test)\n                                                    criterion = nn.MSELoss()\n                                                    train_loss = criterion(train_outputs, y_train).item()\n                                                    test_loss = criterion(test_outputs, y_test).item()\n                                                pytorch_model_new.train_loss = train_loss\n                                                pytorch_model_new.test_loss = test_loss\n                                                logger.info(\"PyTorch model retrained: train_samples=%d, test_samples=%d, train_loss=%.6f, test_loss=%.6f\",\n                                                            len(X_train), len(X_test), train_loss, test_loss)\n                                            else:\n                                                logger.warning(\"Insufficient PyTorch split: train=%d, test=%d\", train_size, len(X) - train_size)\n                                                train_loss = \"N/A\"\n                                                test_loss = \"N/A\"\n                                            joblib.dump(pytorch_scaler_new, \"client_pytorch_scaler.pkl\")\n                                            joblib.dump(pytorch_target_scaler_new, \"client_pytorch_target_scaler.pkl\")\n                                            torch.save(pytorch_model_new.state_dict(), \"client_pytorch_model.pth\")\n                                            logger.info(\"Saved PyTorch scaler, target scaler, and model to client_pytorch_scaler.pkl, client_pytorch_target_scaler.pkl, client_pytorch_model.pth\")\n                                        else:\n                                            logger.error(\"PyTorch retraining and fallback both failed; scalers/models not updated\")\n                                    except Exception as pytorch_error:\n                                        logger.error(\"PyTorch retraining failed: %s\", str(pytorch_error))\n\n                                logger.info(\"Optimizing config parameters\")\n                                try:\n                                    current_params = {\n                                        \"ML_TREND_WEIGHT\": config.ML_TREND_WEIGHT,\n                                        \"ML_CONFIDENCE_THRESHOLD\": config.ML_CONFIDENCE_THRESHOLD,\n                                    }\n                                    bounds = {\n                                        \"ML_TREND_WEIGHT\": (0.3, 1.5),\n                                        \"ML_CONFIDENCE_THRESHOLD\": (0.5, 0.95),\n                                    }\n                                    ensemble_pred = (\n                                        prediction_history[[\"sklearn_pred\", \"pytorch_pred\", \"xgb_pred\"]].mean(axis=1).values\n                                    )\n                                    y_meta = prediction_history[\"actual_price\"].values\n                                    new_params = optimize_config_parameters(\n                                        ensemble_pred, y_meta, current_params, bounds\n                                    )\n                                    config.ML_TREND_WEIGHT = new_params[\"ML_TREND_WEIGHT\"]\n                                    config.ML_CONFIDENCE_THRESHOLD = new_params[\"ML_CONFIDENCE_THRESHOLD\"]\n                                    logger.info(\"Updated config parameters: ML_TREND_WEIGHT=%.2f, ML_CONFIDENCE_THRESHOLD=%.2f\",\n                                                config.ML_TREND_WEIGHT, config.ML_CONFIDENCE_THRESHOLD)\n                                except Exception as opt_error:\n                                    logger.error(\"Parameter optimization failed: %s, retaining current parameters\", str(opt_error))\n\n                                logger.info(\"Updating prediction history: current_rows=%d\", len(prediction_history))\n                                try:\n                                    new_entry = pd.DataFrame(\n                                        {\n                                            \"sklearn_pred\": [last_sklearn_prediction or current_price],\n                                            \"pytorch_pred\": [last_pytorch_prediction or current_price],\n                                            \"xgb_pred\": [last_xgb_prediction or current_price],\n                                            \"current_price\": [current_price],\n                                            \"volatility\": [\n                                                recent_trade_data[\"volatility\"].iloc[-1]\n                                                if \"volatility\" in recent_trade_data\n                                                and not pd.isna(recent_trade_data[\"volatility\"].iloc[-1])\n                                                else defaults[\"volatility\"]\n                                            ],\n                                            \"actual_price\": [\n                                                recent_trade_data[\"predicted_price\"].iloc[-1]\n                                                if \"predicted_price\" in recent_trade_data\n                                                and not pd.isna(recent_trade_data[\"predicted_price\"].iloc[-1])\n                                                else current_price\n                                            ],\n                                        }\n                                    )\n                                    prediction_history = pd.concat([prediction_history, new_entry], ignore_index=True).tail(\n                                        1000\n                                    )\n                                    bot_state[\"prediction_history\"] = prediction_history\n                                    logger.info(\"Updated prediction_history: new_rows=%d, last_price=%.2f\",\n                                                len(prediction_history), prediction_history[\"current_price\"].iloc[-1])\n                                except Exception as history_error:\n                                    logger.error(\"Failed to update prediction history: %s\", str(history_error))\n\n                                logger.info(\"Updating bot_state with retrained models\")\n                                try:\n                                    if sklearn_model_new or pytorch_model_new or xgb_model_new or meta_model_new:\n                                        if sklearn_model_new:\n                                            bot_state[\"sklearn_model\"] = sklearn_model_new\n                                            bot_state[\"sklearn_scaler\"] = sklearn_scaler_new\n                                            logger.info(\"Updated bot_state with Sklearn model\")\n                                        if pytorch_model_new:\n                                            bot_state[\"pytorch_model\"] = pytorch_model_new\n                                            bot_state[\"pytorch_scaler\"] = pytorch_scaler_new\n                                            logger.info(\"Updated bot_state with PyTorch model\")\n                                        if xgb_model_new:\n                                            bot_state[\"xgb_model\"] = xgb_model_new\n                                            bot_state[\"xgb_scaler\"] = xgb_scaler_new\n                                            logger.info(\"Updated bot_state with XGBoost model\")\n                                        if meta_model_new:\n                                            bot_state[\"meta_model\"] = meta_model_new\n                                            bot_state[\"meta_scaler\"] = meta_scaler_new\n                                            logger.info(\"Updated bot_state with Meta-Model\")\n                                        last_retrain_time = current_time\n                                        lookback = max(\n                                            sklearn_lookback or 0,\n                                            pytorch_lookback or 0,\n                                            xgb_lookback or 0,\n                                        )\n                                        logger.info(\"Retraining completed successfully: duration=%.2fs, final_lookback=%d\",\n                                                    time.time() - start_time, lookback)\n                                    else:\n                                        logger.error(\"Retraining failed: no models could be trained\")\n                                except Exception as state_error:\n                                    logger.error(\"Failed to update bot_state: %s\", str(state_error))\n                            except Exception as retrain_error:\n                                logger.error(\"Error during ML retraining: %s, continuing with existing models\", str(retrain_error))\n                            last_retrain_check = current_time\n                        else:\n                            logger.info(\"Skipping retraining: time_since_last_retrain=%.2fs, recent_data_rows=%d, min_data_rows=%d\",\n                                        time_since_last_retrain, len(recent_data), min_data_rows)\n                except Exception as check_error:\n                    logger.error(\"Error checking retraining conditions: %s\", str(check_error))\n                    last_retrain_check = current_time\n\n                # 5. Check Orders\n                # --- Ensure volatility_val and price_val are always defined ---\n                volatility_val = None\n                price_val = None\n                # Try to extract from recent data if available\n                try:\n                    if 'recent_trade_data' in locals() and not recent_trade_data.empty:\n                        if 'volatility' in recent_trade_data.columns:\n                            volatility_val = recent_trade_data['volatility'].iloc[-1]\n                        if 'close' in recent_trade_data.columns:\n                            price_val = recent_trade_data['close'].iloc[-1]\n                except Exception as e:\n                    logger.warning(f\"[PARAM RECOMMEND] Could not extract volatility_val or price_val: {e}\")\n\n                # --- Call dynamic parameter recommendation at the start of Section #5 ---\n                meta_conf = None\n                # Try classifier-style confidence first\n                if 'meta_model' in bot_state and hasattr(bot_state['meta_model'], 'predict_proba') and len(recent_data) > 0:\n                    try:\n                        meta_conf = float(bot_state['meta_model'].predict_proba([recent_data.iloc[-1][[f for f in recent_data.columns if f != 'timestamp']]])[0][1])\n                        logger.info(f\"[PARAM RECOMMEND] meta_conf from meta_model.predict_proba: {meta_conf}\")\n                    except Exception as e:\n                        logger.warning(f\"[PARAM RECOMMEND] Could not compute meta-model confidence (predict_proba): {e}\")\n                # Fallback: use regression confidence (inverse error or prediction variance)\n                if meta_conf is None:\n                    try:\n                        # Use recent prediction errors if available\n                        if 'prediction_history' in bot_state and len(bot_state['prediction_history']) > 5:\n                            preds = bot_state['prediction_history']['meta_pred'].tail(20) if 'meta_pred' in bot_state['prediction_history'] else None\n                            actuals = bot_state['prediction_history']['actual_price'].tail(20)\n                            if preds is not None and len(preds) == len(actuals):\n                                errors = abs(preds.values - actuals.values) / (actuals.values + 1e-9)\n                                mean_error = float(errors.mean())\n                                meta_conf = 1.0 - mean_error\n                                logger.info(f\"[PARAM RECOMMEND] meta_conf from meta-model inverse error: {meta_conf}\")\n                        # If not, use prediction variance as a proxy\n                        elif 'prediction_history' in bot_state and 'meta_pred' in bot_state['prediction_history']:\n                            preds = bot_state['prediction_history']['meta_pred'].tail(20)\n                            if len(preds) > 1:\n                                pred_var = float(preds.var())\n                                meta_conf = 1.0 / (1.0 + pred_var)\n                                logger.info(f\"[PARAM RECOMMEND] meta_conf from meta-model prediction variance: {meta_conf}\")\n                    except Exception as e:\n                        logger.warning(f\"[PARAM RECOMMEND] Could not compute meta-model regression confidence: {e}\")\n                # Fallback: use PyTorch model confidence if available and more accurate\n                if meta_conf is None or (meta_conf is not None and meta_conf < 0.5):\n                    try:\n                        if 'prediction_history' in bot_state and 'pytorch_pred' in bot_state['prediction_history'] and len(bot_state['prediction_history']) > 5:\n                            preds = bot_state['prediction_history']['pytorch_pred'].tail(20)\n                            actuals = bot_state['prediction_history']['actual_price'].tail(20)\n                            if len(preds) == len(actuals):\n                                errors = abs(preds.values - actuals.values) / (actuals.values + 1e-9)\n                                mean_error = float(errors.mean())\n                                pytorch_conf = 1.0 - mean_error\n                                logger.info(f\"[PARAM RECOMMEND] pytorch_conf from PyTorch inverse error: {pytorch_conf}\")\n                                if meta_conf is None or pytorch_conf > meta_conf:\n                                    meta_conf = pytorch_conf\n                    except Exception as e:\n                        logger.warning(f\"[PARAM RECOMMEND] Could not compute PyTorch regression confidence: {e}\")\n                if meta_conf is None:\n                    logger.info(f\"[PARAM RECOMMEND] meta_conf could not be determined (no classifier, no recent predictions)\")\n                # Optionally, compute recent accuracy (e.g., last 20 predictions)\n                recent_accuracy = None\n                if 'prediction_history' in bot_state and len(bot_state['prediction_history']) > 20:\n                    try:\n                        preds = bot_state['prediction_history']['sklearn_pred'].tail(20)\n                        actuals = bot_state['prediction_history']['actual_price'].tail(20)\n                        if len(preds) == len(actuals):\n                            errors = abs(preds.values - actuals.values) / (actuals.values + 1e-9)\n                            recent_accuracy = float((1 - errors).mean())\n                    except Exception as e:\n                        logger.warning(f\"[PARAM RECOMMEND] Could not compute recent accuracy: {e}\")\n                # Get balances for recommendation (always use latest from bot_state if available)\n                if 'get_balances' in globals():\n                    eth_balance, usd_balance = get_balances()\n                elif 'eth_balance' in bot_state and 'usd_balance' in bot_state:\n                    eth_balance = bot_state['eth_balance']\n                    usd_balance = bot_state['usd_balance']\n                else:\n                    eth_balance, usd_balance = 0, 0\n                logger.info(f\"[PARAM RECOMMEND] Using balances for recommendation: USD={usd_balance:.2f}, ETH={eth_balance:.6f}\")\n                # Warn if balances are zero but open orders or recent updates show otherwise\n                if (usd_balance == 0 or eth_balance == 0) and (len(bot_state.get('buy_orders', [])) > 0 or len(bot_state.get('sell_orders', [])) > 0):\n                    logger.warning(f\"[PARAM RECOMMEND] WARNING: Zero balances detected but open orders exist. Check balance update logic.\")\n                recs = recommend_dynamic_params(usd_balance, eth_balance, volatility_val, meta_conf, recent_accuracy, price_val=price_val)\n\n                # --- Dynamically update all actionable parameters (including SHORT_* overrides) ---\n                param_map = {\n                    \"EMA_SPAN\": \"SHORT_EMA_SPAN\",\n                    \"ATR_PERIOD\": \"SHORT_ATR_PERIOD\",\n                    \"VOLATILITY_WINDOW\": \"SHORT_VOLATILITY_WINDOW\",\n                    \"VWAP_PERIOD\": \"SHORT_VWAP_PERIOD\",\n                    \"BOLLINGER_WINDOW\": \"SHORT_BOLLINGER_WINDOW\",\n                    \"MACD_FAST\": \"SHORT_MACD_FAST\",\n                    \"MACD_SLOW\": \"SHORT_MACD_SLOW\",\n                    \"MACD_SIGNAL\": \"SHORT_MACD_SIGNAL\",\n                    \"VOLATILITY_THRESHOLD\": \"LOWER_VOLATILITY_THRESHOLD\"\n                }\n                for param, short_var in param_map.items():\n                    if param in recs:\n                        globals()[short_var] = recs[param]\n                        logger.info(f\"[PARAM AUTO-ADJUST] {short_var} set to {recs[param]} (from {param}) for this run (not persistent)\")\n                # Also update original config values if present\n                for param in [\"EMA_SPAN\", \"ATR_PERIOD\", \"VWAP_PERIOD\", \"BOLLINGER_WINDOW\", \"VOLATILITY_THRESHOLD\"]:\n                    if param in recs and hasattr(config, param):\n                        setattr(config, param, recs[param])\n                        logger.info(f\"[PARAM AUTO-ADJUST] config.{param} set to {recs[param]} for this run (not persistent)\")\n\n                # --- Dynamic Feature Order Triggering in Active Markets ---\n                # If market is highly active (high volatility or volume), allow more aggressive feature order placement within caps\n                market_is_active = False\n                active_volatility_threshold = recs.get(\"VOLATILITY_THRESHOLD\", 0.1) * 2\n                active_volume_threshold = 2 * (recent_trade_data[\"volume\"].rolling(10).mean().iloc[-1] if \"volume\" in recent_trade_data and len(recent_trade_data[\"volume\"]) >= 10 else 0)\n                current_volume = recent_trade_data[\"volume\"].iloc[-1] if \"volume\" in recent_trade_data else 0\n                if volatility_val is not None and volatility_val > active_volatility_threshold:\n                    market_is_active = True\n                if current_volume > active_volume_threshold and active_volume_threshold > 0:\n                    market_is_active = True\n                if market_is_active:\n                    logger.info(f\"[DYNAMIC TRIGGER] Market is ACTIVE (volatility={volatility_val}, volume={current_volume}), relaxing feature order logic within caps.\")\n                    # Lower DCA min spacing and allow more frequent feature orders, but never exceed caps\n                    DCA_min_spacing = min(DCA_min_spacing, 0.002) if 'DCA_min_spacing' in locals() else 0.002\n                    # Optionally, increase soft_feature_order_cap if not at hard cap\n                    if 'soft_feature_order_cap' in locals() and 'feature_order_cap' in locals():\n                        soft_feature_order_cap = min(feature_order_cap, int(soft_feature_order_cap * 1.5) + 1)\n                        logger.info(f\"[DYNAMIC TRIGGER] Increased soft_feature_order_cap to {soft_feature_order_cap} due to active market.\")\n                else:\n                    logger.info(f\"[DYNAMIC TRIGGER] Market is not highly active (volatility={volatility_val}, volume={current_volume}), using default feature order logic.\")\n\n                # --- Simple Risk Management: Gradual, Trend-Based Order Adjustments (3% over 5min) ---\n                # Only cancel relevant side's orders, no cancel-all, and log actions. Gradual, 1-min increments, ready for reversals.\n                try:\n                    trend_window = 5  # 5 minutes (assuming 1min candles)\n                    trend_threshold = 0.03  # 3% move up or down\n                    if \"close\" in recent_trade_data and len(recent_trade_data[\"close\"]) > trend_window:\n                        closes = recent_trade_data[\"close\"].tail(trend_window)\n                        pct_change = (closes.iloc[-1] - closes.iloc[0]) / closes.iloc[0]\n                        # Only act if there are open orders and sufficient balance\n                        if pct_change > trend_threshold and len(bot_state.get(\"sell_orders\", [])) > 0 and eth_balance > 0:\n                            logger.info(f\"[RISK MGMT] Uptrend detected (+{pct_change*100:.2f}% over {trend_window}min). Gradually cancelling sell orders to protect ETH.\")\n                            # Cancel one sell order per minute in uptrend\n                            sell_orders = list(bot_state.get(\"sell_orders\", []))\n                            if sell_orders:\n                                order = sell_orders[0]\n                                try:\n                                    exchange.cancel_order(order[\"id\"], config.SYMBOL)\n                                    logger.info(f\"[RISK MGMT] Gradually canceled sell order {order['id']} due to uptrend.\")\n                                except Exception as e:\n                                    logger.warning(f\"[RISK MGMT] Failed to cancel sell order {order.get('id', '?')}: {e}\")\n                        elif pct_change < -trend_threshold and len(bot_state.get(\"buy_orders\", [])) > 0 and usd_balance > 0:\n                            logger.info(f\"[RISK MGMT] Downtrend detected ({pct_change*100:.2f}% over {trend_window}min). Gradually cancelling buy orders to protect USD.\")\n                            # Cancel one buy order per minute in downtrend\n                            buy_orders = list(bot_state.get(\"buy_orders\", []))\n                            if buy_orders:\n                                order = buy_orders[0]\n                                try:\n                                    exchange.cancel_order(order[\"id\"], config.SYMBOL)\n                                    logger.info(f\"[RISK MGMT] Gradually canceled buy order {order['id']} due to downtrend.\")\n                                except Exception as e:\n                                    logger.warning(f\"[RISK MGMT] Failed to cancel buy order {order.get('id', '?')}: {e}\")\n                        else:\n                            logger.info(f\"[RISK MGMT] No significant trend or no open orders to adjust. pct_change={pct_change*100:.2f}% over {trend_window}min.\")\n                except Exception as risk_error:\n                    logger.error(f\"[RISK MGMT] Error in risk management logic: {risk_error}\")\n\n                # === Section #5: Enhanced Feature-Based Order Logic Enhancements ===\n                # --- SUMMARY TABLE & ACTIONABLE STEPS ---\n                # | Feature    | Trigger Logic                | Threshold/Period | Logging | Would-be Trigger | Actionable Steps |\n                # |------------|------------------------------|------------------|---------|------------------|-----------------|\n                # | EMA        | Price cross EMA              | Lower period     | Yes     | Yes              | Tune period     |\n                # | ATR        | Price move > ATR             | Lower period     | Yes     | Yes              | Tune period     |\n                # | Volatility | Vol > threshold              | Lower threshold  | Yes     | Yes              | Tune threshold  |\n                # | VWAP       | Price cross VWAP             | Lower period     | Yes     | Yes              | Tune period     |\n                # | RSI        | RSI < 30 (buy), > 70 (sell)  | 30/70            | Yes     | Yes              | Tune levels     |\n                # | Bollinger  | Price cross bands            | std=2, window=10 | Yes     | Yes              | Tune window     |\n                # | MACD       | MACD cross signal            | fast/slow=6/13   | Yes     | Yes              | Tune params     |\n                #\n                # Actionable Steps:\n                # 1. All feature triggers log actual values, reasons for not firing, and would-be triggers.\n                # 2. Lowered thresholds/periods for ATR, Volatility, EMA, VWAP (see config overrides below).\n                # 3. DCA/order cap logic relaxed: allow more frequent alternation, lower min_spacing.\n                # 4. Would-be triggers are logged for parameter tuning/backtesting.\n                # 5. All logic is maintainable and parameterized for future tuning.\n\n                # --- Config overrides for shorter periods/lower thresholds ---\n                SHORT_EMA_SPAN = 6\n                SHORT_ATR_PERIOD = 7\n                SHORT_VOLATILITY_WINDOW = 7\n                SHORT_VWAP_PERIOD = 7\n                SHORT_BOLLINGER_WINDOW = 10\n                SHORT_MACD_FAST = 6\n                SHORT_MACD_SLOW = 13\n                SHORT_MACD_SIGNAL = 5\n                LOWER_VOLATILITY_THRESHOLD = 0.12\n\n                # --- Logging all feature triggers and would-be triggers ---\n                would_be_triggers = {}\n                # EMA\n                if 'price_val' in locals() and 'ema_val' in locals() and price_val is not None and ema_val is not None:\n                    would_be_triggers['ema_buy'] = price_val > ema_val\n                    would_be_triggers['ema_sell'] = price_val < ema_val\n                    logger.info(f\"[EMA] Would-be BUY: {would_be_triggers['ema_buy']} (price {price_val:.2f} > ema {ema_val:.2f}), Would-be SELL: {would_be_triggers['ema_sell']} (price {price_val:.2f} < ema {ema_val:.2f})\")\n                # ATR\n                if 'price_val' in locals() and 'atr_val' in locals() and price_val is not None and atr_val is not None:\n                    last_close = None\n                    if \"close\" in recent_trade_data and len(recent_trade_data[\"close\"]) > 1:\n                        last_close = recent_trade_data[\"close\"].iloc[-2]\n                    if last_close is not None:\n                        would_be_triggers['atr_buy'] = price_val < last_close - atr_val\n                        would_be_triggers['atr_sell'] = price_val > last_close + atr_val\n                        logger.info(f\"[ATR] Would-be BUY: {would_be_triggers['atr_buy']} (price {price_val:.2f} < last_close - atr {last_close - atr_val:.2f}), Would-be SELL: {would_be_triggers['atr_sell']} (price {price_val:.2f} > last_close + atr {last_close + atr_val:.2f})\")\n                # Volatility\n                if 'volatility_val' in locals() and volatility_val is not None:\n                    would_be_triggers['volatility_buy'] = volatility_val > LOWER_VOLATILITY_THRESHOLD\n                    would_be_triggers['volatility_sell'] = volatility_val < LOWER_VOLATILITY_THRESHOLD\n                    logger.info(f\"[VOLATILITY] Would-be BUY: {would_be_triggers['volatility_buy']} (vol {volatility_val:.4f} > threshold {LOWER_VOLATILITY_THRESHOLD}), Would-be SELL: {would_be_triggers['volatility_sell']} (vol {volatility_val:.4f} < threshold {LOWER_VOLATILITY_THRESHOLD})\")\n                # VWAP\n                if 'price_val' in locals() and 'vwap_val' in locals() and price_val is not None and vwap_val is not None:\n                    would_be_triggers['vwap_buy'] = price_val > vwap_val\n                    would_be_triggers['vwap_sell'] = price_val < vwap_val\n                    logger.info(f\"[VWAP] Would-be BUY: {would_be_triggers['vwap_buy']} (price {price_val:.2f} > vwap {vwap_val:.2f}), Would-be SELL: {would_be_triggers['vwap_sell']} (price {price_val:.2f} < vwap {vwap_val:.2f})\")\n                # RSI\n                if 'rsi_val' in locals() and rsi_val is not None:\n                    would_be_triggers['rsi_buy'] = rsi_val < 30\n                    would_be_triggers['rsi_sell'] = rsi_val > 70\n                    logger.info(f\"[RSI] Would-be BUY: {would_be_triggers['rsi_buy']} (rsi {rsi_val:.2f} < 30), Would-be SELL: {would_be_triggers['rsi_sell']} (rsi {rsi_val:.2f} > 70)\")\n                # Bollinger\n                if 'price_val' in locals() and 'lower_val' in locals() and 'upper_val' in locals() and price_val is not None and lower_val is not None and upper_val is not None:\n                    would_be_triggers['bollinger_buy'] = price_val <= lower_val\n                    would_be_triggers['bollinger_sell'] = price_val >= upper_val\n                    logger.info(f\"[BOLLINGER] Would-be BUY: {would_be_triggers['bollinger_buy']} (price {price_val:.2f} <= lower {lower_val:.2f}), Would-be SELL: {would_be_triggers['bollinger_sell']} (price {price_val:.2f} >= upper {upper_val:.2f})\")\n                # MACD\n                if 'macd_val' in locals() and 'macd_signal_val' in locals() and macd_val is not None and macd_signal_val is not None:\n                    would_be_triggers['macd_buy'] = macd_val > macd_signal_val\n                    would_be_triggers['macd_sell'] = macd_val < macd_signal_val\n                    logger.info(f\"[MACD] Would-be BUY: {would_be_triggers['macd_buy']} (macd {macd_val:.4f} > signal {macd_signal_val:.4f}), Would-be SELL: {would_be_triggers['macd_sell']} (macd {macd_val:.4f} < signal {macd_signal_val:.4f})\")\n\n                # --- Relaxed DCA/order cap logic: lower min_spacing for DCA alternation ---\n                # (If you want to relax DCA further, set min_spacing in can_place_feature_order to 0.003 or lower)\n\n                # --- END ENHANCEMENTS ---\n\n                # --- Enforce $2 order spacing for buys and sells ---\n                # Example: use ATR as dynamic grid spacing if available, else fallback to $2\n                enforce_order_spacing(bot_state, min_spacing=2.0, feature_name='atr', recent_trade_data=recent_trade_data)\n\n                try:\n                    check_orders_start_time = time.time()\n                    logger.info(\"Starting order checking process\")\n\n                    orders_to_send = []\n                    closed_order_ids = []\n                    current_price = get_current_price()\n                    logger.info(f\"Retrieved current price: {current_price:.2f}\")\n                    max_order_range = config.MAX_ORDER_RANGE  # 2500 above/below current price\n                    logger.info(f\"Max order range set to: {max_order_range:.2f}\")\n\n                    for order_list, is_buy in [\n                        (bot_state[\"buy_orders\"], True),\n                        (bot_state[\"sell_orders\"], False),\n                    ]:\n                        order_type = \"buy\" if is_buy else \"sell\"\n                        logger.info(f\"Checking {order_type} orders: {len(order_list)} orders in list\")\n\n                        # --- Feature-based order scan and logging ---\n                        # Get latest feature values\n                        rsi_val = recent_trade_data[\"rsi\"].iloc[-1] if \"rsi\" in recent_trade_data else None\n                        price_val = recent_trade_data[\"close\"].iloc[-1] if \"close\" in recent_trade_data else None\n                        lower_val = recent_trade_data[\"bollinger_lower\"].iloc[-1] if \"bollinger_lower\" in recent_trade_data else None\n                        upper_val = recent_trade_data[\"bollinger_upper\"].iloc[-1] if \"bollinger_upper\" in recent_trade_data else None\n                        macd_val = recent_trade_data[\"macd\"].iloc[-1] if \"macd\" in recent_trade_data else None\n                        macd_signal_val = recent_trade_data[\"macd_signal\"].iloc[-1] if \"macd_signal\" in recent_trade_data else None\n                        ema_val = recent_trade_data[\"ema\"].iloc[-1] if \"ema\" in recent_trade_data else None\n                        atr_val = recent_trade_data[\"atr\"].iloc[-1] if \"atr\" in recent_trade_data else None\n                        volatility_val = recent_trade_data[\"volatility\"].iloc[-1] if \"volatility\" in recent_trade_data else None\n                        vwap_val = recent_trade_data[\"vwap\"].iloc[-1] if \"vwap\" in recent_trade_data else None\n                        logger.info(\n                            f\"Feature values for {order_type} - \"\n                            f\"RSI: {rsi_val if rsi_val is not None else 'N/A'}, \"\n                            f\"Price: {price_val if price_val is not None else 'N/A'}, \"\n                            f\"Bollinger Lower: {lower_val if lower_val is not None else 'N/A'}, \"\n                            f\"Bollinger Upper: {upper_val if upper_val is not None else 'N/A'}, \"\n                            f\"MACD: {macd_val if macd_val is not None else 'N/A'}, \"\n                            f\"MACD Signal: {macd_signal_val if macd_signal_val is not None else 'N/A'}, \"\n                            f\"EMA: {ema_val if ema_val is not None else 'N/A'}, \"\n                            f\"ATR: {atr_val if atr_val is not None else 'N/A'}, \"\n                            f\"Volatility: {volatility_val if volatility_val is not None else 'N/A'}, \"\n                            f\"VWAP: {vwap_val if vwap_val is not None else 'N/A'}\"\n                        )\n\n                        # --- Automated feature-based order placement (max 8 per feature) ---\n                        # --- Dynamic Feature Order Cap Logic ---\n                        expanded_feature_list = [\"rsi\", \"bollinger\", \"macd\", \"ema\", \"atr\", \"volatility\", \"vwap\"]\n                        max_total_orders = getattr(config, \"MAX_TOTAL_ORDERS\", 240)\n                        num_base_orders = getattr(config, \"NUM_BUY_GRID_LINES\", 20) + getattr(config, \"NUM_SELL_GRID_LINES\", 20)\n                        feature_order_cap = getattr(config, \"FEATURE_ORDER_CAP\", max_total_orders - num_base_orders)\n                        soft_feature_order_cap = getattr(config, \"SOFT_FEATURE_ORDER_CAP\", max(2, feature_order_cap // len(expanded_feature_list)))\n                        total_open_orders = len(bot_state['buy_orders']) + len(bot_state['sell_orders'])\n                        base_order_count = sum(1 for o in order_list if o.get(\"feature\", \"base\") == \"base\")\n                        feature_order_counts = {f: sum(1 for o in order_list if isinstance(o, dict) and o.get(\"feature\") == f) for f in expanded_feature_list}\n                        total_open_feature_orders = sum(feature_order_counts.values())\n                        available_feature_slots = max(0, feature_order_cap - total_open_feature_orders)\n                        logger.info(f\"[ORDER MGMT] Dynamic feature cap: {feature_order_cap}, soft per-feature cap: {soft_feature_order_cap}\")\n                        logger.info(f\"[ORDER MGMT] {order_type.upper()} base orders: {base_order_count}, feature order counts: {feature_order_counts}\")\n                        logger.info(f\"[ORDER MGMT] Total open orders: {total_open_orders} (Buy: {len(bot_state['buy_orders'])}, Sell: {len(bot_state['sell_orders'])}), available feature slots: {available_feature_slots}\")\n\n                        def can_place_feature_order_dynamic(feature):\n                            if total_open_feature_orders < feature_order_cap:\n                                if feature_order_counts[feature] < soft_feature_order_cap:\n                                    return True\n                                # Allow exceeding soft cap if slots are available\n                                logger.info(f\"[DYNAMIC CAP] Feature '{feature}' exceeding soft cap ({soft_feature_order_cap}), but slots available (total open: {total_open_feature_orders}/{feature_order_cap})\")\n                                return True\n                            logger.info(f\"[DYNAMIC CAP] Feature '{feature}' cannot place more orders: open={feature_order_counts[feature]}, total open={total_open_feature_orders}, cap={feature_order_cap}\")\n                            return False\n\n                        # Helper: check if we can place more orders (single robust implementation, always in scope)\n                        def can_place_more_orders():\n                            total_orders = len(bot_state[\"buy_orders\"]) + len(bot_state[\"sell_orders\"])\n                            if total_orders >= max_total_orders:\n                                logger.info(f\"[ORDER MGMT] Total order cap reached: {total_orders} >= {max_total_orders}\")\n                                return False\n                            # Also check if there are available slots for feature orders\n                            if (max_total_orders - total_orders) <= 0:\n                                logger.info(f\"[ORDER MGMT] No available slots for new feature orders (total_open_orders={total_orders}, max_total_orders={max_total_orders})\")\n                                return False\n                            return True\n\n                        # --- DCA-style feature-based trade logic ---\n                        if 'feature_trade_state' not in bot_state:\n                            bot_state['feature_trade_state'] = {f: {'last_side': None, 'last_price': None} for f in expanded_feature_list}\n                            logger.info(\"[ORDER MGMT] Initialized feature_trade_state in bot_state for all features\")\n                        # --- EMA ---\n                        ema_val = recent_trade_data[\"ema\"].iloc[-1] if \"ema\" in recent_trade_data else None\n                        if ema_val is not None:\n                            if 'get_balances' in globals():\n                                eth_balance, usd_balance = get_balances()\n                            else:\n                                eth_balance, usd_balance = 0, 0\n                            position_size = getattr(config, \"POSITION_SIZE\", 0.0018)\n                            # Buy: price crosses above EMA\n                            if is_buy and price_val is not None and price_val > ema_val and can_place_feature_order_dynamic(\"ema\") and can_place_more_orders() and usd_balance > price_val * position_size:\n                                if can_place_feature_order('ema', 'buy', price_val):\n                                    logger.info(f\"[EMA] Buy condition MET: price={price_val:.2f} > EMA={ema_val:.2f}\")\n                                    # Place order (copy MACD logic)\n                                    try:\n                                        amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                        price = float(exchange.price_to_precision(config.SYMBOL, price_val))\n                                        order = exchange.create_limit_buy_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                                        order = exchange.fetch_order(order[\"id\"])\n                                        bot_state[\"buy_orders\"].append({**order, \"feature\": \"ema\"})\n                                        log_feature_trade(\n                                            timestamp=datetime.now(timezone.utc).isoformat(),\n                                            feature=\"ema\",\n                                            order_type=\"buy\",\n                                            order_id=order[\"id\"],\n                                            price=price,\n                                            size=amount,\n                                            status=\"open\",\n                                            profit=\"\"\n                                        )\n                                        logger.info(f\"[EMA] Logged feature trade for BUY order: id={order['id']}\")\n                                    except Exception as e:\n                                        logger.error(f\"[EMA] Failed to place automated BUY order: {e}\")\n                                else:\n                                    logger.info(f\"[EMA] Buy condition MET but DCA logic does NOT allow. Waiting for sell.\")\n                            # Sell: price crosses below EMA\n                            elif not is_buy and price_val is not None and price_val < ema_val and can_place_feature_order_dynamic(\"ema\") and can_place_more_orders() and eth_balance > position_size:\n                                if can_place_feature_order('ema', 'sell', price_val):\n                                    logger.info(f\"[EMA] Sell condition MET: price={price_val:.2f} < EMA={ema_val:.2f}\")\n                                    try:\n                                        amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                        price = float(exchange.price_to_precision(config.SYMBOL, price_val))\n                                        order = exchange.create_limit_sell_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                                        order = exchange.fetch_order(order[\"id\"])\n                                        bot_state[\"sell_orders\"].append({**order, \"feature\": \"ema\"})\n                                        log_feature_trade(\n                                            timestamp=datetime.now(timezone.utc).isoformat(),\n                                            feature=\"ema\",\n                                            order_type=\"sell\",\n                                            order_id=order[\"id\"],\n                                            price=price,\n                                            size=amount,\n                                            status=\"open\",\n                                            profit=\"\"\n                                        )\n                                        logger.info(f\"[EMA] Logged feature trade for SELL order: id={order['id']}\")\n                                    except Exception as e:\n                                        logger.error(f\"[EMA] Failed to place automated SELL order: {e}\")\n                                else:\n                                    logger.info(f\"[EMA] Sell condition MET but DCA logic does NOT allow. Waiting for buy.\")\n\n                        # --- ATR ---\n                        atr_val = recent_trade_data[\"atr\"].iloc[-1] if \"atr\" in recent_trade_data else None\n                        if atr_val is not None:\n                            if 'get_balances' in globals():\n                                eth_balance, usd_balance = get_balances()\n                            else:\n                                eth_balance, usd_balance = 0, 0\n                            position_size = getattr(config, \"POSITION_SIZE\", 0.0018)\n                            # Buy: price drops by more than ATR from last close\n                            last_close = recent_trade_data[\"close\"].iloc[-2] if \"close\" in recent_trade_data and len(recent_trade_data[\"close\"]) > 1 else None\n                            if is_buy and last_close is not None and price_val is not None and price_val < last_close - atr_val and can_place_feature_order_dynamic(\"atr\") and can_place_more_orders() and usd_balance > price_val * position_size:\n                                if can_place_feature_order('atr', 'buy', price_val):\n                                    logger.info(f\"[ATR] Buy condition MET: price={price_val:.2f} < last_close - ATR={last_close - atr_val:.2f}\")\n                                    try:\n                                        amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                        price = float(exchange.price_to_precision(config.SYMBOL, price_val))\n                                        order = exchange.create_limit_buy_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                                        order = exchange.fetch_order(order[\"id\"])\n                                        bot_state[\"buy_orders\"].append({**order, \"feature\": \"atr\"})\n                                        log_feature_trade(\n                                            timestamp=datetime.now(timezone.utc).isoformat(),\n                                            feature=\"atr\",\n                                            order_type=\"buy\",\n                                            order_id=order[\"id\"],\n                                            price=price,\n                                            size=amount,\n                                            status=\"open\",\n                                            profit=\"\"\n                                        )\n                                        logger.info(f\"[ATR] Logged feature trade for BUY order: id={order['id']}\")\n                                    except Exception as e:\n                                        logger.error(f\"[ATR] Failed to place automated BUY order: {e}\")\n                                else:\n                                    logger.info(f\"[ATR] Buy condition MET but DCA logic does NOT allow. Waiting for sell.\")\n                            # Sell: price rises by more than ATR from last close\n                            elif not is_buy and last_close is not None and price_val is not None and price_val > last_close + atr_val and can_place_feature_order_dynamic(\"atr\") and can_place_more_orders() and eth_balance > position_size:\n                                if can_place_feature_order('atr', 'sell', price_val):\n                                    logger.info(f\"[ATR] Sell condition MET: price={price_val:.2f} > last_close + ATR={last_close + atr_val:.2f}\")\n                                    try:\n                                        amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                        price = float(exchange.price_to_precision(config.SYMBOL, price_val))\n                                        order = exchange.create_limit_sell_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                                        order = exchange.fetch_order(order[\"id\"])\n                                        bot_state[\"sell_orders\"].append({**order, \"feature\": \"atr\"})\n                                        log_feature_trade(\n                                            timestamp=datetime.now(timezone.utc).isoformat(),\n                                            feature=\"atr\",\n                                            order_type=\"sell\",\n                                            order_id=order[\"id\"],\n                                            price=price,\n                                            size=amount,\n                                            status=\"open\",\n                                            profit=\"\"\n                                        )\n                                        logger.info(f\"[ATR] Logged feature trade for SELL order: id={order['id']}\")\n                                    except Exception as e:\n                                        logger.error(f\"[ATR] Failed to place automated SELL order: {e}\")\n                                else:\n                                    logger.info(f\"[ATR] Sell condition MET but DCA logic does NOT allow. Waiting for buy.\")\n\n                        # --- Volatility ---\n                        volatility_val = recent_trade_data[\"volatility\"].iloc[-1] if \"volatility\" in recent_trade_data else None\n                        if volatility_val is not None:\n                            if 'get_balances' in globals():\n                                eth_balance, usd_balance = get_balances()\n                            else:\n                                eth_balance, usd_balance = 0, 0\n                            position_size = getattr(config, \"POSITION_SIZE\", 0.0018)\n                            # Buy: volatility spikes above threshold\n                            volatility_threshold = getattr(config, \"VOLATILITY_THRESHOLD\", 0.2)\n                            if is_buy and volatility_val > volatility_threshold and can_place_feature_order_dynamic(\"volatility\") and can_place_more_orders() and usd_balance > price_val * position_size:\n                                if can_place_feature_order('volatility', 'buy', price_val):\n                                    logger.info(f\"[VOLATILITY] Buy condition MET: volatility={volatility_val:.4f} > threshold={volatility_threshold:.4f}\")\n                                    try:\n                                        amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                        price = float(exchange.price_to_precision(config.SYMBOL, price_val))\n                                        order = exchange.create_limit_buy_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                                        order = exchange.fetch_order(order[\"id\"])\n                                        bot_state[\"buy_orders\"].append({**order, \"feature\": \"volatility\"})\n                                        log_feature_trade(\n                                            timestamp=datetime.now(timezone.utc).isoformat(),\n                                            feature=\"volatility\",\n                                            order_type=\"buy\",\n                                            order_id=order[\"id\"],\n                                            price=price,\n                                            size=amount,\n                                            status=\"open\",\n                                            profit=\"\"\n                                        )\n                                        logger.info(f\"[VOLATILITY] Logged feature trade for BUY order: id={order['id']}\")\n                                    except Exception as e:\n                                        logger.error(f\"[VOLATILITY] Failed to place automated BUY order: {e}\")\n                                else:\n                                    logger.info(f\"[VOLATILITY] Buy condition MET but DCA logic does NOT allow. Waiting for sell.\")\n                            # Sell: volatility drops below threshold\n                            elif not is_buy and volatility_val < volatility_threshold and can_place_feature_order_dynamic(\"volatility\") and can_place_more_orders() and eth_balance > position_size:\n                                if can_place_feature_order('volatility', 'sell', price_val):\n                                    logger.info(f\"[VOLATILITY] Sell condition MET: volatility={volatility_val:.4f} < threshold={volatility_threshold:.4f}\")\n                                    try:\n                                        amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                        price = float(exchange.price_to_precision(config.SYMBOL, price_val))\n                                        order = exchange.create_limit_sell_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                                        order = exchange.fetch_order(order[\"id\"])\n                                        bot_state[\"sell_orders\"].append({**order, \"feature\": \"volatility\"})\n                                        log_feature_trade(\n                                            timestamp=datetime.now(timezone.utc).isoformat(),\n                                            feature=\"volatility\",\n                                            order_type=\"sell\",\n                                            order_id=order[\"id\"],\n                                            price=price,\n                                            size=amount,\n                                            status=\"open\",\n                                            profit=\"\"\n                                        )\n                                        logger.info(f\"[VOLATILITY] Logged feature trade for SELL order: id={order['id']}\")\n                                    except Exception as e:\n                                        logger.error(f\"[VOLATILITY] Failed to place automated SELL order: {e}\")\n                                else:\n                                    logger.info(f\"[VOLATILITY] Sell condition MET but DCA logic does NOT allow. Waiting for buy.\")\n\n                        def can_place_feature_order(feature, side, current_price):\n                            state = bot_state['feature_trade_state'][feature]\n                            # Add patience: require more spacing for buys/sells\n                            min_spacing = 0.005  # 0.5% default, can be tuned\n                            if state['last_side'] is None:\n                                if side == 'buy':\n                                    logger.info(f\"[DCA {feature.upper()}] No previous trade, allowing buy order\")\n                                    return True\n                                else:\n                                    logger.info(f\"[DCA {feature.upper()}] No previous trade, sell order blocked (requires buy first)\")\n                                    return False\n                            if side == 'sell' and state['last_side'] == 'buy' and state['last_price']:\n                                can_sell = current_price >= state['last_price'] * (1 + min_spacing)\n                                logger.info(f\"[DCA {feature.upper()}] Sell check: current_price={current_price:.2f}, \"\n                                            f\"last_buy_price={state['last_price']:.2f}, threshold={state['last_price'] * (1 + min_spacing):.2f}, \"\n                                            f\"can_sell={can_sell}\")\n                                return can_sell\n                            if side == 'buy' and state['last_side'] == 'sell' and state['last_price']:\n                                can_buy = current_price <= state['last_price'] * (1 - min_spacing)\n                                logger.info(f\"[DCA {feature.upper()}] Buy check: current_price={current_price:.2f}, \"\n                                            f\"last_sell_price={state['last_price']:.2f}, threshold={state['last_price'] * (1 - min_spacing):.2f}, \"\n                                            f\"can_buy={can_buy}\")\n                                return can_buy\n                            logger.info(f\"[DCA {feature.upper()}] Cannot place {side} order: last_side={state['last_side']}, \"\n                                        f\"last_price={state['last_price']}\")\n                            return False\n\n                        # --- VWAP ---\n                        vwap_val = recent_trade_data[\"vwap\"].iloc[-1] if \"vwap\" in recent_trade_data else None\n                        if vwap_val is not None:\n                            if 'get_balances' in globals():\n                                eth_balance, usd_balance = get_balances()\n                            else:\n                                eth_balance, usd_balance = 0, 0\n                            position_size = getattr(config, \"POSITION_SIZE\", 0.0018)\n                            # Buy: price crosses above VWAP\n                            if is_buy and price_val is not None and price_val > vwap_val and can_place_feature_order_dynamic(\"vwap\") and can_place_more_orders() and usd_balance > price_val * position_size:\n                                if can_place_feature_order('vwap', 'buy', price_val):\n                                    logger.info(f\"[VWAP] Buy condition MET: price={price_val:.2f} > VWAP={vwap_val:.2f}\")\n                                    try:\n                                        amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                        price = float(exchange.price_to_precision(config.SYMBOL, price_val))\n                                        order = exchange.create_limit_buy_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                                        order = exchange.fetch_order(order[\"id\"])\n                                        bot_state[\"buy_orders\"].append({**order, \"feature\": \"vwap\"})\n                                        log_feature_trade(\n                                            timestamp=datetime.now(timezone.utc).isoformat(),\n                                            feature=\"vwap\",\n                                            order_type=\"buy\",\n                                            order_id=order[\"id\"],\n                                            price=price,\n                                            size=amount,\n                                            status=\"open\",\n                                            profit=\"\"\n                                        )\n                                        logger.info(f\"[VWAP] Logged feature trade for BUY order: id={order['id']}\")\n                                    except Exception as e:\n                                        logger.error(f\"[VWAP] Failed to place automated BUY order: {e}\")\n                                else:\n                                    logger.info(f\"[VWAP] Buy condition MET but DCA logic does NOT allow. Waiting for sell.\")\n                            # Sell: price crosses below VWAP\n                            elif not is_buy and price_val is not None and price_val < vwap_val and can_place_feature_order_dynamic(\"vwap\") and can_place_more_orders() and eth_balance > position_size:\n                                if can_place_feature_order('vwap', 'sell', price_val):\n                                    logger.info(f\"[VWAP] Sell condition MET: price={price_val:.2f} < VWAP={vwap_val:.2f}\")\n                                    try:\n                                        amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                        price = float(exchange.price_to_precision(config.SYMBOL, price_val))\n                                        order = exchange.create_limit_sell_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                                        order = exchange.fetch_order(order[\"id\"])\n                                        bot_state[\"sell_orders\"].append({**order, \"feature\": \"vwap\"})\n                                        log_feature_trade(\n                                            timestamp=datetime.now(timezone.utc).isoformat(),\n                                            feature=\"vwap\",\n                                            order_type=\"sell\",\n                                            order_id=order[\"id\"],\n                                            price=price,\n                                            size=amount,\n                                            status=\"open\",\n                                            profit=\"\"\n                                        )\n                                        logger.info(f\"[VWAP] Logged feature trade for SELL order: id={order['id']}\")\n                                    except Exception as e:\n                                        logger.error(f\"[VWAP] Failed to place automated SELL order: {e}\")\n                                else:\n                                    logger.info(f\"[VWAP] Sell condition MET but DCA logic does NOT allow. Waiting for buy.\")\n\n                        # Remove any duplicate can_place_more_orders definitions below this point (if present)\n\n                        # Helper: get balances\n                        def get_balances():\n                            try:\n                                eth_balance, usd_balance = sync_balances(exchange)\n                                return eth_balance, usd_balance\n                            except Exception as e:\n                                logger.error(f\"[ORDER MGMT] Failed to fetch balances: {e}\")\n                                return 0, 0\n\n                        # --- RSI ---\n                        if rsi_val is not None:\n                            eth_balance, usd_balance = get_balances()\n                            position_size = getattr(config, \"POSITION_SIZE\", 0.0018)\n                            # Buy: only if enough USD, not at cap, and total order cap not reached\n                            if is_buy and rsi_val < 30 and can_place_feature_order_dynamic(\"rsi\") and can_place_more_orders() and usd_balance > price_val * position_size:\n                                if can_place_feature_order('rsi', 'buy', price_val):\n                                    logger.info(f\"[RSI DCA] Buy condition MET and DCA logic allows: RSI={rsi_val:.2f}, open_orders={feature_order_counts['rsi']}\")\n                                    retry_count = 0\n                                    max_retries = 5\n                                    min_tick = getattr(exchange, 'markets', {}).get(config.SYMBOL, {}).get('precision', {}).get('price', 0.01)\n                                    min_tick = float(min_tick) if min_tick else 0.01\n                                    price = float(exchange.price_to_precision(config.SYMBOL, price_val))\n                                    while retry_count < max_retries:\n                                        try:\n                                            orderbook = exchange.fetch_order_book(config.SYMBOL)\n                                            best_bid = float(orderbook['bids'][0][0]) if orderbook['bids'] else None\n                                            best_ask = float(orderbook['asks'][0][0]) if orderbook['asks'] else None\n                                            logger.info(f\"[RSI] Order book: best_bid={best_bid if best_bid else 'N/A'}, best_ask={best_ask if best_ask else 'N/A'}\")\n                                            if best_bid is not None and best_ask is not None:\n                                                mid_price = (best_bid + best_ask) / 2\n                                                new_price = min(mid_price - min_tick, best_ask - min_tick)\n                                                price = float(exchange.price_to_precision(config.SYMBOL, new_price))\n                                            if best_ask is not None and price < best_ask:\n                                                amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                                logger.info(f\"[RSI] Preparing BUY order: price={price:.2f}, amount={amount}\")\n                                                order = exchange.create_limit_buy_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                                                order = exchange.fetch_order(order[\"id\"])\n                                                bot_state[\"buy_orders\"].append({**order, \"feature\": \"rsi\"})\n                                                logger.info(f\"[RSI] Automated BUY order placed: id={order['id']}, price={price:.2f}, size={amount}, feature=rsi\")\n                                                if count_open_feature_orders(bot_state, \"rsi\", \"buy\") >= 8:\n                                                    logger.info(f\"[RSI] Skipping BUY: open feature orders at cap (8)\")\n                                                    break\n                                                log_feature_trade(\n                                                    timestamp=datetime.now(timezone.utc).isoformat(),\n                                                    feature=\"rsi\",\n                                                    order_type=\"buy\",\n                                                    order_id=order[\"id\"],\n                                                    price=price,\n                                                    size=amount,\n                                                    status=\"open\",\n                                                    profit=\"\"\n                                                )\n                                                logger.info(f\"[RSI] Logged feature trade for BUY order: id={order['id']}\")\n                                                break\n                                            else:\n                                                logger.warning(f\"[RSI] Buy price {price:.2f} not below best ask {best_ask if best_ask else 'N/A'}, retrying...\")\n                                                time.sleep(5)\n                                            retry_count += 1\n                                        except Exception as e:\n                                            if \"INVALID_LIMIT_PRICE_POST_ONLY\" in str(e):\n                                                retry_count += 1\n                                                logger.warning(f\"[RSI] Buy order post-only error, retrying with lower price: {price:.2f} (attempt {retry_count}/{max_retries})\")\n                                                time.sleep(5)\n                                            else:\n                                                logger.error(f\"[RSI] Failed to place automated BUY order: {e}\")\n                                                break\n                                    else:\n                                        logger.warning(f\"[RSI] Skipped buy: could not place post-only order after {max_retries} retries. Last attempted price: {price:.2f}\")\n                                else:\n                                    logger.info(f\"[RSI DCA] Buy condition MET but DCA logic does NOT allow: RSI={rsi_val:.2f}. Waiting for sell.\")\n                            elif not is_buy and rsi_val > 70 and can_place_feature_order_dynamic(\"rsi\") and can_place_more_orders() and eth_balance > position_size:\n                                if can_place_feature_order('rsi', 'sell', price_val):\n                                    logger.info(f\"[RSI DCA] Sell condition MET and DCA logic allows: RSI={rsi_val:.2f}, open_orders={feature_order_counts['rsi']}\")\n                                    retry_count = 0\n                                    max_retries = 5\n                                    min_tick = getattr(exchange, 'markets', {}).get(config.SYMBOL, {}).get('precision', {}).get('price', 0.01)\n                                    min_tick = float(min_tick) if min_tick else 0.01\n                                    price = float(exchange.price_to_precision(config.SYMBOL, price_val))\n                                    while retry_count < max_retries:\n                                        try:\n                                            orderbook = exchange.fetch_order_book(config.SYMBOL)\n                                            best_bid = float(orderbook['bids'][0][0]) if orderbook['bids'] else None\n                                            best_ask = float(orderbook['asks'][0][0]) if orderbook['asks'] else None\n                                            logger.info(f\"[RSI] Order book: best_bid={best_bid if best_bid else 'N/A'}, best_ask={best_ask if best_ask else 'N/A'}\")\n                                            if best_bid is not None and best_ask is not None:\n                                                mid_price = (best_bid + best_ask) / 2\n                                                new_price = max(mid_price + min_tick, best_bid + min_tick)\n                                                price = float(exchange.price_to_precision(config.SYMBOL, new_price))\n                                            if best_bid is not None and price >= best_bid + min_tick:\n                                                amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                                logger.info(f\"[RSI] Preparing SELL order: price={price:.2f}, amount={amount}\")\n                                                order = exchange.create_limit_sell_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                                                order = exchange.fetch_order(order[\"id\"])\n                                                bot_state[\"sell_orders\"].append({**order, \"feature\": \"rsi\"})\n                                                logger.info(f\"[RSI] Automated SELL order placed: id={order['id']}, price={price:.2f}, size={amount}, feature=rsi\")\n                                                if count_open_feature_orders(bot_state, \"rsi\", \"sell\") >= 8:\n                                                    logger.info(f\"[RSI] Skipping SELL: open feature orders at cap (8)\")\n                                                    break\n                                                log_feature_trade(\n                                                    timestamp=datetime.now(timezone.utc).isoformat(),\n                                                    feature=\"rsi\",\n                                                    order_type=\"sell\",\n                                                    order_id=order[\"id\"],\n                                                    price=price,\n                                                    size=amount,\n                                                    status=\"open\",\n                                                    profit=\"\"\n                                                )\n                                                logger.info(f\"[RSI] Logged feature trade for SELL order: id={order['id']}\")\n                                                break\n                                            else:\n                                                logger.warning(f\"[RSI] Sell price {price:.2f} not above best bid {best_bid if best_bid else 'N/A'} + min_tick, retrying...\")\n                                                time.sleep(5)\n                                                if retry_count >= 2 and best_bid is not None and best_ask is not None:\n                                                    mid_price = (best_bid + best_ask) / 2\n                                                    new_price = max(mid_price + min_tick, best_bid + min_tick)\n                                                    price = float(exchange.price_to_precision(config.SYMBOL, new_price))\n                                                    logger.warning(f\"[RSI] Readjusting sell price to mid: {mid_price:.2f}, new price: {price:.2f}\")\n                                            retry_count += 1\n                                        except Exception as e:\n                                            if \"INVALID_LIMIT_PRICE_POST_ONLY\" in str(e):\n                                                retry_count += 1\n                                                price = float(exchange.price_to_precision(config.SYMBOL, price + min_tick))\n                                                logger.warning(f\"[RSI] Sell order post-only error, retrying with higher price: {price:.2f} (attempt {retry_count}/{max_retries})\")\n                                                time.sleep(5)\n                                            else:\n                                                logger.error(f\"[RSI] Failed to place automated SELL order: {e}\")\n                                                break\n                                    else:\n                                        logger.warning(f\"[RSI] Skipped sell: could not place post-only order after {max_retries} retries. Last attempted price: {price:.2f}\")\n                                else:\n                                    logger.info(f\"[RSI DCA] Sell condition MET but DCA logic does NOT allow: RSI={rsi_val:.2f}. Waiting for buy.\")\n\n                        # --- Bollinger ---\n                        if price_val is not None and lower_val is not None and upper_val is not None:\n                            eth_balance, usd_balance = get_balances()\n                            position_size = getattr(config, \"POSITION_SIZE\", 0.0018)\n                            if is_buy and price_val <= lower_val and can_place_feature_order_dynamic(\"bollinger\") and can_place_more_orders() and usd_balance > price_val * position_size:\n                                if can_place_feature_order('bollinger', 'buy', price_val):\n                                    logger.info(f\"[BOLLINGER DCA] Buy condition MET and DCA logic allows: Price={price_val:.2f}, Lower={lower_val:.2f}, open_orders={feature_order_counts['bollinger']}\")\n                                    retry_count = 0\n                                    max_retries = 5\n                                    min_tick = getattr(exchange, 'markets', {}).get(config.SYMBOL, {}).get('precision', {}).get('price', 0.01)\n                                    min_tick = float(min_tick) if min_tick else 0.01\n                                    price = float(exchange.price_to_precision(config.SYMBOL, price_val))\n                                    while retry_count < max_retries:\n                                        try:\n                                            orderbook = exchange.fetch_order_book(config.SYMBOL)\n                                            best_bid = float(orderbook['bids'][0][0]) if orderbook['bids'] else None\n                                            best_ask = float(orderbook['asks'][0][0]) if orderbook['asks'] else None\n                                            logger.info(f\"[BOLLINGER] Order book: best_bid={best_bid if best_bid else 'N/A'}, best_ask={best_ask if best_ask else 'N/A'}\")\n                                            if best_bid is not None and best_ask is not None:\n                                                mid_price = (best_bid + best_ask) / 2\n                                                new_price = min(mid_price - min_tick, best_ask - min_tick)\n                                                price = float(exchange.price_to_precision(config.SYMBOL, new_price))\n                                            if best_ask is not None and price < best_ask:\n                                                amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                                logger.info(f\"[BOLLINGER] Preparing BUY order: price={price:.2f}, amount={amount}\")\n                                                order = exchange.create_limit_buy_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                                                order = exchange.fetch_order(order[\"id\"])\n                                                bot_state[\"buy_orders\"].append({**order, \"feature\": \"bollinger\"})\n                                                logger.info(f\"[BOLLINGER] Automated BUY order placed: id={order['id']}, price={price:.2f}, size={amount}, feature=bollinger\")\n                                                if count_open_feature_orders(bot_state, \"bollinger\", \"buy\") >= 8:\n                                                    logger.info(f\"[BOLLINGER] Skipping BUY: open feature orders at cap (8)\")\n                                                    break\n                                                log_feature_trade(\n                                                    timestamp=datetime.now(timezone.utc).isoformat(),\n                                                    feature=\"bollinger\",\n                                                    order_type=\"buy\",\n                                                    order_id=order[\"id\"],\n                                                    price=price,\n                                                    size=amount,\n                                                    status=\"open\",\n                                                    profit=\"\"\n                                                )\n                                                logger.info(f\"[BOLLINGER] Logged feature trade for BUY order: id={order['id']}\")\n                                                break\n                                            else:\n                                                logger.warning(f\"[BOLLINGER] Buy price {price:.2f} not below best ask {best_ask if best_ask else 'N/A'}, retrying...\")\n                                                time.sleep(1)\n                                                if retry_count >= 2 and best_bid is not None and best_ask is not None:\n                                                    mid_price = (best_bid + best_ask) / 2\n                                                    new_price = min(mid_price - min_tick, best_ask - min_tick)\n                                                    price = float(exchange.price_to_precision(config.SYMBOL, new_price))\n                                                    logger.warning(f\"[BOLLINGER] Readjusting buy price to mid: {mid_price:.2f}, new price: {price:.2f}\")\n                                            retry_count += 1\n                                        except Exception as e:\n                                            if \"INVALID_LIMIT_PRICE_POST_ONLY\" in str(e):\n                                                retry_count += 1\n                                                price = float(exchange.price_to_precision(config.SYMBOL, price - min_tick))\n                                                logger.warning(f\"[BOLLINGER] Buy order post-only error, retrying with lower price: {price:.2f} (attempt {retry_count}/{max_retries})\")\n                                                time.sleep(1)\n                                            else:\n                                                logger.error(f\"[BOLLINGER] Failed to place automated BUY order: {e}\")\n                                                break\n                                    else:\n                                        logger.warning(f\"[BOLLINGER] Skipped buy: could not place post-only order after {max_retries} retries. Last attempted price: {price:.2f}\")\n                                else:\n                                    logger.info(f\"[BOLLINGER DCA] Buy condition MET but DCA logic does NOT allow: Price={price_val:.2f}. Waiting for sell.\")\n                            elif not is_buy and price_val >= upper_val and can_place_feature_order_dynamic(\"bollinger\") and can_place_more_orders() and eth_balance > position_size:\n                                if can_place_feature_order('bollinger', 'sell', price_val):\n                                    logger.info(f\"[BOLLINGER DCA] Sell condition MET and DCA logic allows: Price={price_val:.2f}, Upper={upper_val:.2f}, open_orders={feature_order_counts['bollinger']}\")\n                                    retry_count = 0\n                                    max_retries = 5\n                                    min_tick = getattr(exchange, 'markets', {}).get(config.SYMBOL, {}).get('precision', {}).get('price', 0.01)\n                                    min_tick = float(min_tick) if min_tick else 0.01\n                                    price = float(exchange.price_to_precision(config.SYMBOL, price_val))\n                                    while retry_count < max_retries:\n                                        try:\n                                            orderbook = exchange.fetch_order_book(config.SYMBOL)\n                                            best_bid = float(orderbook['bids'][0][0]) if orderbook['bids'] else None\n                                            best_ask = float(orderbook['asks'][0][0]) if orderbook['asks'] else None\n                                            logger.info(f\"[BOLLINGER] Order book: best_bid={best_bid if best_bid else 'N/A'}, best_ask={best_ask if best_ask else 'N/A'}\")\n                                            if best_bid is not None and best_ask is not None:\n                                                mid_price = (best_bid + best_ask) / 2\n                                                new_price = max(mid_price + min_tick, best_bid + min_tick)\n                                                price = float(exchange.price_to_precision(config.SYMBOL, new_price))\n                                            if best_bid is not None and price >= best_bid + min_tick:\n                                                amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                                logger.info(f\"[BOLLINGER] Preparing SELL order: price={price:.2f}, amount={amount}\")\n                                                order = exchange.create_limit_sell_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                                                order = exchange.fetch_order(order[\"id\"])\n                                                bot_state[\"sell_orders\"].append({**order, \"feature\": \"bollinger\"})\n                                                logger.info(f\"[BOLLINGER] Automated SELL order placed: id={order['id']}, price={price:.2f}, size={amount}, feature=bollinger\")\n                                                if count_open_feature_orders(bot_state, \"bollinger\", \"sell\") >= 8:\n                                                    logger.info(f\"[BOLLINGER] Skipping SELL: open feature orders at cap (8)\")\n                                                    break\n                                                log_feature_trade(\n                                                    timestamp=datetime.now(timezone.utc).isoformat(),\n                                                    feature=\"bollinger\",\n                                                    order_type=\"sell\",\n                                                    order_id=order[\"id\"],\n                                                    price=price,\n                                                    size=amount,\n                                                    status=\"open\",\n                                                    profit=\"\"\n                                                )\n                                                logger.info(f\"[BOLLINGER] Logged feature trade for SELL order: id={order['id']}\")\n                                                break\n                                            else:\n                                                logger.warning(f\"[BOLLINGER] Sell price {price:.2f} not above best bid {best_bid if best_bid else 'N/A'} + min_tick, retrying...\")\n                                                time.sleep(1)\n                                                if retry_count >= 2 and best_bid is not None and best_ask is not None:\n                                                    mid_price = (best_bid + best_ask) / 2\n                                                    new_price = max(mid_price + min_tick, best_bid + min_tick)\n                                                    price = float(exchange.price_to_precision(config.SYMBOL, new_price))\n                                                    logger.warning(f\"[BOLLINGER] Readjusting sell price to mid: {mid_price:.2f}, new price: {price:.2f}\")\n                                            retry_count += 1\n                                        except Exception as e:\n                                            if \"INVALID_LIMIT_PRICE_POST_ONLY\" in str(e):\n                                                retry_count += 1\n                                                price = float(exchange.price_to_precision(config.SYMBOL, price + min_tick))\n                                                logger.warning(f\"[BOLLINGER] Sell order post-only error, retrying with higher price: {price:.2f} (attempt {retry_count}/{max_retries})\")\n                                                time.sleep(1)\n                                            else:\n                                                logger.error(f\"[BOLLINGER] Failed to place automated SELL order: {e}\")\n                                                break\n                                    else:\n                                        logger.warning(f\"[BOLLINGER] Skipped sell: could not place post-only order after {max_retries} retries. Last attempted price: {price:.2f}\")\n                                else:\n                                    logger.info(f\"[BOLLINGER DCA] Sell condition MET but DCA logic does NOT allow: Price={price_val:.2f}. Waiting for buy.\")\n\n                        # --- MACD ---\n                        if macd_val is not None and macd_signal_val is not None:\n                            eth_balance, usd_balance = get_balances()\n                            position_size = getattr(config, \"POSITION_SIZE\", 0.0018)\n                            if is_buy and macd_val > macd_signal_val and can_place_feature_order_dynamic(\"macd\") and can_place_more_orders() and usd_balance > price_val * position_size:\n                                if can_place_feature_order('macd', 'buy', price_val):\n                                    logger.info(f\"[MACD DCA] Buy condition MET and DCA logic allows: MACD={macd_val:.4f}, Signal={macd_signal_val:.4f}, open_orders={feature_order_counts['macd']}\")\n                                    retry_count = 0\n                                    max_retries = 5\n                                    min_tick = getattr(exchange, 'markets', {}).get(config.SYMBOL, {}).get('precision', {}).get('price', 0.01)\n                                    min_tick = float(min_tick) if min_tick else 0.01\n                                    price = float(exchange.price_to_precision(config.SYMBOL, price_val))\n                                    while retry_count < max_retries:\n                                        try:\n                                            orderbook = exchange.fetch_order_book(config.SYMBOL)\n                                            best_bid = float(orderbook['bids'][0][0]) if orderbook['bids'] else None\n                                            best_ask = float(orderbook['asks'][0][0]) if orderbook['asks'] else None\n                                            logger.info(f\"[MACD] Order book: best_bid={best_bid if best_bid else 'N/A'}, best_ask={best_ask if best_ask else 'N/A'}\")\n                                            if best_bid is not None and best_ask is not None:\n                                                mid_price = (best_bid + best_ask) / 2\n                                                new_price = min(mid_price - min_tick, best_ask - min_tick)\n                                                price = float(exchange.price_to_precision(config.SYMBOL, new_price))\n                                            if best_ask is not None and price < best_ask:\n                                                amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                                logger.info(f\"[MACD] Preparing BUY order: price={price:.2f}, amount={amount}\")\n                                                order = exchange.create_limit_buy_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                                                order = exchange.fetch_order(order[\"id\"])\n                                                bot_state[\"buy_orders\"].append({**order, \"feature\": \"macd\"})\n                                                logger.info(f\"[MACD] Automated BUY order placed: id={order['id']}, price={price:.2f}, size={amount}, feature=macd\")\n                                                if count_open_feature_orders(bot_state, \"macd\", \"buy\") >= 8:\n                                                    logger.info(f\"[MACD] Skipping BUY: open feature orders at cap (8)\")\n                                                    break\n                                                log_feature_trade(\n                                                    timestamp=datetime.now(timezone.utc).isoformat(),\n                                                    feature=\"macd\",\n                                                    order_type=\"buy\",\n                                                    order_id=order[\"id\"],\n                                                    price=price,\n                                                    size=amount,\n                                                    status=\"open\",\n                                                    profit=\"\"\n                                                )\n                                                logger.info(f\"[MACD] Logged feature trade for BUY order: id={order['id']}\")\n                                                break\n                                            else:\n                                                logger.warning(f\"[MACD] Buy price {price:.2f} not below best ask {best_ask if best_ask else 'N/A'}, retrying...\")\n                                                time.sleep(1)\n                                                if retry_count >= 2 and best_bid is not None and best_ask is not None:\n                                                    mid_price = (best_bid + best_ask) / 2\n                                                    new_price = min(mid_price - min_tick, best_ask - min_tick)\n                                                    price = float(exchange.price_to_precision(config.SYMBOL, new_price))\n                                                    logger.warning(f\"[MACD] Readjusting buy price to mid: {mid_price:.2f}, new price: {price:.2f}\")\n                                            retry_count += 1\n                                        except Exception as e:\n                                            if \"INVALID_LIMIT_PRICE_POST_ONLY\" in str(e):\n                                                retry_count += 1\n                                                price = float(exchange.price_to_precision(config.SYMBOL, price - min_tick))\n                                                logger.warning(f\"[MACD] Buy order post-only error, retrying with lower price: {price:.2f} (attempt {retry_count}/{max_retries})\")\n                                                time.sleep(1)\n                                            else:\n                                                logger.error(f\"[MACD] Failed to place automated BUY order: {e}\")\n                                                break\n                                    else:\n                                        logger.warning(f\"[MACD] Skipped buy: could not place post-only order after {max_retries} retries. Last attempted price: {price:.2f}\")\n                                else:\n                                    logger.info(f\"[MACD DCA] Buy condition MET but DCA logic does NOT allow: MACD={macd_val:.4f}. Waiting for sell.\")\n                            elif not is_buy and macd_val < macd_signal_val and can_place_feature_order_dynamic(\"macd\") and can_place_more_orders() and eth_balance > position_size:\n                                if can_place_feature_order('macd', 'sell', price_val):\n                                    logger.info(f\"[MACD DCA] Sell condition MET and DCA logic allows: MACD={macd_val:.4f}, Signal={macd_signal_val:.4f}, open_orders={feature_order_counts['macd']}\")\n                                    retry_count = 0\n                                    max_retries = 5\n                                    min_tick = getattr(exchange, 'markets', {}).get(config.SYMBOL, {}).get('precision', {}).get('price', 0.01)\n                                    min_tick = float(min_tick) if min_tick else 0.01\n                                    price = float(exchange.price_to_precision(config.SYMBOL, price_val))\n                                    while retry_count < max_retries:\n                                        try:\n                                            orderbook = exchange.fetch_order_book(config.SYMBOL)\n                                            best_bid = float(orderbook['bids'][0][0]) if orderbook['bids'] else None\n                                            best_ask = float(orderbook['asks'][0][0]) if orderbook['asks'] else None\n                                            logger.info(f\"[MACD] Order book: best_bid={best_bid if best_bid else 'N/A'}, best_ask={best_ask if best_ask else 'N/A'}\")\n                                            if best_bid is not None and best_ask is not None:\n                                                mid_price = (best_bid + best_ask) / 2\n                                                new_price = max(mid_price + min_tick, best_bid + min_tick)\n                                                price = float(exchange.price_to_precision(config.SYMBOL, new_price))\n                                            if best_bid is not None and price >= best_bid + min_tick:\n                                                amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                                logger.info(f\"[MACD] Preparing SELL order: price={price:.2f}, amount={amount}\")\n                                                order = exchange.create_limit_sell_order(config.SYMBOL, amount, price, params={\"post_only\": True})\n                                                order = exchange.fetch_order(order[\"id\"])\n                                                bot_state[\"sell_orders\"].append({**order, \"feature\": \"macd\"})\n                                                logger.info(f\"[MACD] Automated SELL order placed: id={order['id']}, price={price:.2f}, size={amount}, feature=macd\")\n                                                if count_open_feature_orders(bot_state, \"macd\", \"sell\") >= 8:\n                                                    logger.info(f\"[MACD] Skipping SELL: open feature orders at cap (8)\")\n                                                    break\n                                                log_feature_trade(\n                                                    timestamp=datetime.now(timezone.utc).isoformat(),\n                                                    feature=\"macd\",\n                                                    order_type=\"sell\",\n                                                    order_id=order[\"id\"],\n                                                    price=price,\n                                                    size=amount,\n                                                    status=\"open\",\n                                                    profit=\"\"\n                                                )\n                                                logger.info(f\"[MACD] Logged feature trade for SELL order: id={order['id']}\")\n                                                break\n                                            else:\n                                                logger.warning(f\"[MACD] Sell price {price:.2f} not above best bid {best_bid if best_bid else 'N/A'} + min_tick, retrying...\")\n                                                time.sleep(1)\n                                                if retry_count >= 2 and best_bid is not None and best_ask is not None:\n                                                    mid_price = (best_bid + best_ask) / 2\n                                                    new_price = max(mid_price + min_tick, best_bid + min_tick)\n                                                    price = float(exchange.price_to_precision(config.SYMBOL, new_price))\n                                                    logger.warning(f\"[MACD] Readjusting sell price to mid: {mid_price:.2f}, new price: {price:.2f}\")\n                                            retry_count += 1\n                                        except Exception as e:\n                                            if \"INVALID_LIMIT_PRICE_POST_ONLY\" in str(e):\n                                                retry_count += 1\n                                                price = float(exchange.price_to_precision(config.SYMBOL, price + min_tick))\n                                                logger.warning(f\"[MACD] Sell order post-only error, retrying with higher price: {price:.2f} (attempt {retry_count}/{max_retries})\")\n                                                time.sleep(1)\n                                            else:\n                                                logger.error(f\"[MACD] Failed to place automated SELL order: {e}\")\n                                                break\n                                    else:\n                                        logger.warning(f\"[MACD] Skipped sell: could not place post-only order after {max_retries} retries. Last attempted price: {price:.2f}\")\n                                else:\n                                    logger.info(f\"[MACD DCA] Sell condition MET but DCA logic does NOT allow: MACD={macd_val:.4f}. Waiting for buy.\")\n\n                        check_order_type_start_time = time.time()\n                        orders_to_remove = []\n                        feature_orders_to_remove = []\n                        base_orders_to_remove = []\n                        for index, order in enumerate(order_list):\n                            grid_level = index + 1\n                            if not order or \"id\" not in order or not isinstance(order, dict):\n                                logger.warning(f\"[ORDER MGMT] Skipping invalid {order_type} order at grid_level {grid_level}: {order}\")\n                                orders_to_remove.append(order)\n                                continue\n\n                            feature_label = order.get(\"feature\", \"base\")\n                            if feature_label == \"base\":\n                                logger.info(f\"[BASE ORDER] Processing {order_type} order: id={order['id']}, grid_level={grid_level}\")\n                            else:\n                                logger.info(f\"[FEATURE ORDER] Processing {order_type} order: id={order['id']}, grid_level={grid_level}, feature={feature_label}\")\n\n                            # Log feature-based order check details\n                            if feature_label == \"rsi\":\n                                rsi_val = recent_trade_data[\"rsi\"].iloc[-1] if \"rsi\" in recent_trade_data else None\n                                logger.info(f\"[RSI CHECK] Order id={order['id']}, grid_level={grid_level}, RSI={rsi_val if rsi_val is not None else 'N/A'}, Buy if < 30, Sell if > 70\")\n                            elif feature_label == \"bollinger\":\n                                price_val = recent_trade_data[\"close\"].iloc[-1] if \"close\" in recent_trade_data else None\n                                lower_val = recent_trade_data[\"bollinger_lower\"].iloc[-1] if \"bollinger_lower\" in recent_trade_data else None\n                                upper_val = recent_trade_data[\"bollinger_upper\"].iloc[-1] if \"bollinger_upper\" in recent_trade_data else None\n                                logger.info(f\"[BOLLINGER CHECK] Order id={order['id']}, grid_level={grid_level}, Price={price_val if price_val is not None else 'N/A'}, Lower Band={lower_val if lower_val is not None else 'N/A'}, Upper Band={upper_val if upper_val is not None else 'N/A'}\")\n                            elif feature_label == \"macd\":\n                                macd_val = recent_trade_data[\"macd\"].iloc[-1] if \"macd\" in recent_trade_data else None\n                                macd_signal_val = recent_trade_data[\"macd_signal\"].iloc[-1] if \"macd_signal\" in recent_trade_data else None\n                                logger.info(f\"[MACD CHECK] Order id={order['id']}, grid_level={grid_level}, MACD={macd_val if macd_val is not None else 'N/A'}, Signal={macd_signal_val if macd_signal_val is not None else 'N/A'}, Buy if MACD > Signal, Sell if MACD < Signal\")\n                            else:\n                                logger.info(f\"[BASE CHECK] Order id={order['id']}, grid_level={grid_level}, price={order.get('price', 'N/A')}\")\n\n                            # Profit and order closed logging for all features\n                            if order.get(\"status\") == config.CHECK_ORDER_STATUS:\n                                profit = None\n                                if feature_label in [\"rsi\", \"bollinger\", \"macd\"]:\n                                    if order_type == \"sell\":\n                                        buy_price = buy_prices.get(order[\"id\"])\n                                        if buy_price is not None:\n                                            profit = float(order.get(\"price\", 0)) - float(buy_price)\n                                            logger.info(f\"[PROFIT] {feature_label.upper()} sell order id={order['id']} closed. Buy price={buy_price:.2f}, Sell price={order.get('price', 0):.2f}, Profit={profit:.2f}\")\n                                            bot_state['feature_trade_state'][feature_label]['last_side'] = 'sell'\n                                            bot_state['feature_trade_state'][feature_label]['last_price'] = float(order.get(\"price\", 0))\n                                            logger.info(f\"[DCA {feature_label.upper()}] Updated feature_trade_state: last_side=sell, last_price={float(order.get('price', 0)):.2f}\")\n                                        else:\n                                            logger.info(f\"[PROFIT] {feature_label.upper()} sell order id={order['id']} closed. Buy price unknown.\")\n                                    else:\n                                        logger.info(f\"[ORDER CLOSED] {feature_label.upper()} buy order id={order['id']} closed at price={order.get('price', 0):.2f}\")\n                                        bot_state['feature_trade_state'][feature_label]['last_side'] = 'buy'\n                                        bot_state['feature_trade_state'][feature_label]['last_price'] = float(order.get(\"price\", 0))\n                                        logger.info(f\"[DCA {feature_label.upper()}] Updated feature_trade_state: last_side=buy, last_price={float(order.get('price', 0)):.2f}\")\n\n                            try:\n                                order_update = exchange.fetch_order(order[\"id\"], config.SYMBOL)\n                                if not order_update or not isinstance(order_update, dict):\n                                    logger.error(f\"Failed to fetch {order_type} order {order['id']}, feature={feature_label}, marking for removal\")\n                                    orders_to_remove.append(order)\n                                    continue\n\n                                order_price = float(order_update.get(\"price\", order.get(\"price\", current_price)))\n                                logger.info(f\"{order_type.capitalize()} order status: id={order['id']}, status={order_update['status']}, \"\n                                            f\"price={order_price:.2f}, grid_level={grid_level}, feature={feature_label}\")\n\n                                if order_update[\"status\"] != order.get(\"status\"):\n                                    logger.info(f\"{order_type.capitalize()} order status updated: id={order['id']}, \"\n                                                f\"old_status={order.get('status', 'unknown')}, new_status={order_update['status']}, \"\n                                                f\"price={order_price:.2f}, feature={feature_label}\")\n                                    order[\"status\"] = order_update[\"status\"]\n\n                                if order_update[\"status\"] == \"canceled\":\n                                    logger.info(f\"{order_type.capitalize()} order already canceled: id={order['id']}, price={order_price:.4f}, \"\n                                                f\"grid_level={grid_level}, feature={feature_label}\")\n                                    orders_to_remove.append(order)\n                                    orders_to_send.append(\n                                        {\n                                            \"type\": \"order\",\n                                            \"id\": order[\"id\"],\n                                            \"status\": \"canceled\",\n                                            \"side\": order_type,\n                                            \"price\": float(order_price),\n                                            \"timestamp\": int(current_time * 1000),\n                                        }\n                                    )\n                                    logger.info(f\"Added canceled {order_type} order to WebSocket: id={order['id']}, status=canceled, feature={feature_label}\")\n                                    continue\n\n                                # Check if order is out of range using current_price\n                                price_diff = current_price - order_price if is_buy else order_price - current_price\n                                logger.info(f\"Out-of-range check: {order_type} order id={order['id']}, price={order_price:.2f}, \"\n                                            f\"current_price={current_price:.2f}, grid_base_price={grid_base_price:.2f}, \"\n                                            f\"price_diff={price_diff:.2f}, max_order_range={max_order_range:.2f}\")\n                                if price_diff > max_order_range:\n                                    try:\n                                        cancelled = cancel_orders(exchange, [order], config.SYMBOL)\n                                        if cancelled:\n                                            logger.info(f\"Canceled out-of-range {order_type} order: id={order['id']}, \"\n                                                        f\"price={order_price:.2f}, grid_level={grid_level}, feature={feature_label}, \"\n                                                        f\"max_order_range={max_order_range:.2f}\")\n                                            orders_to_remove.append(order)\n                                            orders_to_send.append(\n                                                {\n                                                    \"type\": \"order\",\n                                                    \"id\": order[\"id\"],\n                                                    \"status\": \"canceled\",\n                                                    \"side\": order_type,\n                                                    \"price\": float(order_price),\n                                                    \"timestamp\": int(current_time * 1000),\n                                                }\n                                            )\n                                            logger.info(f\"Added canceled out-of-range {order_type} order to WebSocket: id={order['id']}, \"\n                                                        f\"status=canceled, feature={feature_label}\")\n                                        else:\n                                            logger.warning(f\"Failed to cancel out-of-range {order_type} order: id={order['id']}, \"\n                                                        f\"feature={feature_label}\")\n                                    except Exception as cancel_error:\n                                        logger.error(f\"Failed to cancel out-of-range {order_type} order {order['id']}, \"\n                                                    f\"feature={feature_label}: {cancel_error}\")\n                                    continue\n\n                                # Handle executed orders\n                                if order_update[\"status\"] == config.CHECK_ORDER_STATUS:\n                                    closed_orders.append(order_update)\n                                    closed_order_ids.append(order[\"id\"])\n                                    size = float(order_update.get(\"filled\", config.POSITION_SIZE))\n                                    logger.info(f\"{order_type.capitalize()} order executed: id={order['id']}, price={order_price:.2f}, \"\n                                                f\"size={size:.6f}, grid_level={grid_level}, feature={feature_label}\")\n\n                                    if is_buy:\n                                        buy_prices[order[\"id\"]] = order_price\n                                        eth_balance, _ = sync_balances(exchange)\n                                        logger.info(f\"Post-buy balance: ETH={eth_balance:.6f}\")\n                                        sell_size = min(eth_balance, config.POSITION_SIZE)\n                                        feature = order.get(\"feature\", \"base\")\n                                        feature_order_id = order.get(\"feature_order_id\") if feature != \"base\" else None\n                                        new_sell_order = place_sell_after_buy(\n                                            exchange, order[\"id\"], order_price, sell_size,\n                                            feature=feature, feature_order_id=feature_order_id\n                                        )\n                                        if new_sell_order and isinstance(new_sell_order, dict):\n                                            bot_state[\"sell_orders\"].append(new_sell_order)\n                                            orders_to_send.append(\n                                                {\n                                                    \"type\": \"order\",\n                                                    \"id\": new_sell_order[\"id\"],\n                                                    \"status\": new_sell_order[\"status\"],\n                                                    \"side\": \"sell\",\n                                                    \"price\": float(new_sell_order[\"price\"]),\n                                                    \"timestamp\": int(current_time * 1000),\n                                                }\n                                            )\n                                            logger.info(f\"Placed new sell order after buy: id={new_sell_order['id']}, \"\n                                                        f\"price={float(new_sell_order['price']):.2f}, size={sell_size:.6f}, \"\n                                                        f\"grid_level={len(bot_state['sell_orders'])}, feature={new_sell_order.get('feature', 'base')}, feature_order_id={new_sell_order.get('feature_order_id')}\")\n                                        else:\n                                            logger.warning(f\"Failed to place sell order after buy: buy_order_id={order['id']}, \"\n                                                        f\"attempted_size={sell_size:.6f}, feature={feature_label}\")\n                                        last_trade_time = current_time\n                                        logger.info(f\"Updated last_trade_time to {last_trade_time:.0f} after buy execution\")\n                                    else:\n                                        buy_price = buy_prices.pop(order[\"id\"], None)\n                                        if buy_price:\n                                            log_trade_profit(buy_price, order_price, size, order[\"id\"])\n                                            logger.info(f\"Logged trade profit for sell order: id={order['id']}, \"\n                                                        f\"buy_price={buy_price:.2f}, sell_price={order_price:.2f}, size={size:.6f}, \"\n                                                        f\"feature={feature_label}\")\n                                        else:\n                                            logger.warning(f\"No buy price mapped for sell order: id={order['id']}, \"\n                                                        f\"price={order_price:.2f}, feature={feature_label}\")\n                                        eth_balance, usd_balance = sync_balances(exchange)\n                                        logger.info(f\"Post-sell balance: ETH={eth_balance:.6f}, USD={usd_balance:.2f}\")\n                                        required_usd = size * order_price\n                                        if usd_balance < required_usd:\n                                            logger.warning(f\"Insufficient USD to place buy after sell: available={usd_balance:.2f}, \"\n                                                        f\"required={required_usd:.2f}, feature={feature_label}\")\n                                        else:\n                                            feature = order.get(\"feature\", \"base\")\n                                            feature_order_id = order.get(\"feature_order_id\") if feature != \"base\" else None\n                                            new_buy_order = place_buy_after_sell(\n                                                exchange, order[\"id\"], order_price, size,\n                                                feature=feature, feature_order_id=feature_order_id\n                                            )\n                                            if new_buy_order and isinstance(new_buy_order, dict):\n                                                bot_state[\"buy_orders\"].append(new_buy_order)\n                                                orders_to_send.append(\n                                                    {\n                                                        \"type\": \"order\",\n                                                        \"id\": new_buy_order[\"id\"],\n                                                        \"status\": new_buy_order[\"status\"],\n                                                        \"side\": \"buy\",\n                                                        \"price\": float(new_buy_order[\"price\"]),\n                                                        \"timestamp\": int(current_time * 1000),\n                                                    }\n                                                )\n                                                logger.info(f\"Placed new buy order after sell: id={new_buy_order['id']}, \"\n                                                            f\"price={float(new_buy_order['price']):.2f}, size={size:.6f}, \"\n                                                            f\"grid_level={len(bot_state['buy_orders'])}, feature={new_buy_order.get('feature', 'base')}, feature_order_id={new_buy_order.get('feature_order_id')}\")\n                                            else:\n                                                logger.warning(f\"Failed to place buy order after sell: sell_order_id={order['id']}, \"\n                                                            f\"attempted_size={size:.6f}, feature={feature_label}\")\n                                        last_trade_time = current_time\n                                        logger.info(f\"Updated last_trade_time to {last_trade_time:.0f} after sell execution\")\n\n                                    orders_to_send.append(\n                                        {\n                                            \"type\": \"order\",\n                                            \"id\": order[\"id\"],\n                                            \"status\": order_update[\"status\"],\n                                            \"side\": order_type,\n                                            \"price\": float(order_price),\n                                            \"timestamp\": int(current_time * 1000),\n                                        }\n                                    )\n                                    logger.info(f\"Added executed {order_type} order to WebSocket: id={order['id']}, \"\n                                                f\"status={order_update['status']}, feature={feature_label}\")\n\n                            except ccxt.RateLimitExceeded:\n                                logger.warning(f\"Rate limit exceeded checking {order_type} order {order['id']}, \"\n                                            f\"feature={feature_label}, waiting 5 seconds\")\n                                time.sleep(5)\n                            except Exception as order_error:\n                                logger.error(f\"Error processing {order_type} order {order['id']} at grid_level {grid_level}, \"\n                                            f\"feature={feature_label}: {order_error}\")\n                                if \"401\" in str(order_error):\n                                    logger.error(f\"Authentication error (401) for {order_type} order {order['id']}, \"\n                                                f\"feature={feature_label}, waiting 5 seconds\")\n                                    time.sleep(5)\n\n                        # --- Clean up orders (symmetrical for buy/sell) ---\n                        for order in orders_to_remove:\n                            if order in order_list:\n                                order_list.remove(order)\n                                feature_label = order.get(\"feature\", \"base\")\n                                feature_order_id = order.get(\"feature_order_id\", None)\n                                if feature_label == \"base\":\n                                    logger.info(f\"[BASE ORDER] Removed invalid or failed {order_type} order from list: id={order.get('id', 'unknown')}\")\n                                else:\n                                    logger.info(f\"[FEATURE ORDER] Removed invalid or failed {order_type} order from list: id={order.get('id', 'unknown')}, feature={feature_label}, feature_order_id={feature_order_id}\")\n                        # Remove closed orders from both buy and sell lists, preserving feature key\n                        bot_state[\"buy_orders\"] = [\n                            order for order in bot_state[\"buy_orders\"] if order.get(\"id\") not in closed_order_ids\n                        ]\n                        bot_state[\"sell_orders\"] = [\n                            order for order in bot_state[\"sell_orders\"] if order.get(\"id\") not in closed_order_ids\n                        ]\n                        logger.info(f\"[ORDER MGMT] Post-check {order_type} orders: {len(order_list)} remaining after removing {len(orders_to_remove)} orders\")\n\n                        # --- Log summary of open orders by type (symmetrical for buy/sell) ---\n                        base_open = sum(1 for o in order_list if o.get(\"feature\", \"base\") == \"base\" and o.get(\"status\", \"open\") == \"open\")\n                        feature_names = [\"rsi\", \"bollinger\", \"macd\", \"ema\", \"atr\", \"volatility\", \"vwap\"]\n                        feature_open = {f: sum(1 for o in order_list if o.get(\"feature\") == f and o.get(\"status\", \"open\") == \"open\") for f in feature_names}\n                        # Log all open feature order IDs for traceability\n                        for f in feature_names:\n                            open_ids = [o.get(\"id\") for o in order_list if o.get(\"feature\") == f and o.get(\"status\", \"open\") == \"open\"]\n                            open_feature_ids = [o.get(\"feature_order_id\") for o in order_list if o.get(\"feature\") == f and o.get(\"status\", \"open\") == \"open\"]\n                            if open_ids:\n                                logger.info(f\"[ORDER MGMT] {order_type.upper()} open {f.upper()} orders: ids={open_ids}, feature_order_ids={open_feature_ids}\")\n                        logger.info(f\"[ORDER MGMT] {order_type.upper()} open base orders: {base_open}, feature orders: {feature_open}\")\n                        logger.info(f\"[ORDER MGMT] {order_type.capitalize()} order check completed in {time.time() - check_order_type_start_time:.2f} seconds\")\n\n                        # --- Log absence of feature-based orders (symmetrical for buy/sell) ---\n                        for feature_name in expanded_feature_list:\n                            has_feature_order = any(order.get(\"feature\") == feature_name and order.get(\"status\", \"open\") == \"open\" for order in order_list if isinstance(order, dict))\n                            if not has_feature_order:\n                                logger.info(f\"[ORDER MGMT] No open {order_type} orders for feature: {feature_name.upper()}\")\n\n                        # --- Ensure all order placement functions set 'feature' and 'feature_order_id' key for both buy and sell ---\n                        # (This is a reminder for the rest of the code: when placing new orders after DCA, always set 'feature' and 'feature_order_id' key)\n\n                        # --- DEBUG: Warn if no feature orders are present after placement attempts ---\n                        if all(feature_open[f] == 0 for f in feature_names):\n                            logger.warning(f\"[ORDER MGMT] No open feature orders detected for {order_type.upper()} after order check. If you expect feature orders, check placement logic and feature tagging.\")\n\n                        # Example for place_buy_after_sell and place_sell_after_buy (should be defined elsewhere):\n                        # def place_buy_after_sell(..., feature=None, feature_order_id=None):\n                        #     ...\n                        #     order = ...\n                        #     if feature:\n                        #         order[\"feature\"] = feature\n                        #     if feature_order_id:\n                        #         order[\"feature_order_id\"] = feature_order_id\n                        #     ...\n                        # def place_sell_after_buy(..., feature=None, feature_order_id=None):\n                        #     ...\n                        #     order = ...\n                        #     if feature:\n                        #         order[\"feature\"] = feature\n                        #     if feature_order_id:\n                        #         order[\"feature_order_id\"] = feature_order_id\n                        #     ...\n\n                        # (If these functions are not yet symmetrical, update them to always set the 'feature' and 'feature_order_id' key for both buy and sell orders.)\n\n                    # Check and cancel excess orders if total exceeds MAX_NUM_GRID_LINES\n                    total_orders = len(bot_state[\"buy_orders\"]) + len(bot_state[\"sell_orders\"])\n                    max_grid_lines = config.MAX_NUM_GRID_LINES  # 52\n                    logger.info(f\"Total orders: {total_orders}, MAX_NUM_GRID_LINES: {max_grid_lines}\")\n                    if total_orders > max_grid_lines:\n                        logger.info(f\"Total orders ({total_orders}) exceeds MAX_NUM_GRID_LINES ({max_grid_lines}), initiating cancellation of excess orders\")\n                        excess_count = total_orders - max_grid_lines\n                        logger.info(f\"Calculated excess orders to cancel: {excess_count}\")\n\n                        # Combine buy and sell orders, sort by timestamp (newest first)\n                        all_orders = [\n                            {**order, \"side\": \"buy\"} for order in bot_state[\"buy_orders\"]\n                        ] + [\n                            {**order, \"side\": \"sell\"} for order in bot_state[\"sell_orders\"]\n                        ]\n                        all_orders.sort(key=lambda x: x.get(\"timestamp\", 0), reverse=True)\n                        logger.info(f\"Combined and sorted {len(all_orders)} orders by timestamp (newest first)\")\n\n                        # Calculate target buy/sell counts for 50/50 balance\n                        buy_count = len(bot_state[\"buy_orders\"])\n                        sell_count = len(bot_state[\"sell_orders\"])\n                        logger.info(f\"Current order distribution: Buy orders={buy_count}, Sell orders={sell_count}\")\n                        target_each = max_grid_lines // 2  # Aim for equal buy/sell\n                        logger.info(f\"Target for each side (buy/sell): {target_each}\")\n                        buy_to_cancel = max(0, buy_count - target_each)\n                        sell_to_cancel = max(0, sell_count - target_each)\n                        logger.info(f\"Initial cancellation plan: Cancel {buy_to_cancel} buy orders, {sell_to_cancel} sell orders\")\n\n                        # Adjust if total cancellations are less than excess_count\n                        if buy_to_cancel + sell_to_cancel < excess_count:\n                            remaining = excess_count - (buy_to_cancel + sell_to_cancel)\n                            logger.info(f\"Additional cancellations needed: {remaining}\")\n                            if buy_count > sell_count:\n                                buy_to_cancel += remaining\n                                logger.info(f\"Assigning {remaining} additional cancellations to buy orders (buy_count={buy_count} > sell_count={sell_count})\")\n                            else:\n                                sell_to_cancel += remaining\n                                logger.info(f\"Assigning {remaining} additional cancellations to sell orders (sell_count={sell_count} >= buy_count={buy_count})\")\n                        logger.info(f\"Final cancellation plan: Cancel {buy_to_cancel} buy orders, {sell_to_cancel} sell orders\")\n\n                        # Select orders to cancel, prioritizing newest and balancing buy/sell\n                        orders_to_cancel = []\n                        buy_cancelled = 0\n                        sell_cancelled = 0\n                        for order in all_orders:\n                            if order[\"side\"] == \"buy\" and buy_cancelled < buy_to_cancel:\n                                orders_to_cancel.append(order)\n                                buy_cancelled += 1\n                            elif order[\"side\"] == \"sell\" and sell_cancelled < sell_to_cancel:\n                                orders_to_cancel.append(order)\n                                sell_cancelled += 1\n                            if len(orders_to_cancel) >= excess_count:\n                                break\n                        logger.info(f\"Selected {len(orders_to_cancel)} orders for cancellation: {buy_cancelled} buy, {sell_cancelled} sell\")\n\n                        # Cancel selected orders\n                        for order in orders_to_cancel:\n                            try:\n                                cancelled = cancel_orders(exchange, [order], config.SYMBOL)\n                                if cancelled:\n                                    logger.info(f\"Cancelled excess {order['side']} order: id={order['id']}, \"\n                                                f\"price={order.get('price', 0):.2f}, feature={order.get('feature', 'base')}\")\n                                    orders_to_remove.append(order)\n                                    orders_to_send.append(\n                                        {\n                                            \"type\": \"order\",\n                                            \"id\": order[\"id\"],\n                                            \"status\": \"canceled\",\n                                            \"side\": order[\"side\"],\n                                            \"timestamp\": int(current_time * 1000),\n                                            \"price\": float(order.get(\"price\", 0)),\n                                        }\n                                    )\n                                    logger.info(f\"Added canceled excess {order['side']} order to WebSocket: id={order['id']}, \"\n                                                f\"status=canceled, feature={order.get('feature', 'base')}\")\n                                    if order[\"side\"] == \"buy\":\n                                        bot_state[\"buy_orders\"] = [o for o in bot_state[\"buy_orders\"] if o[\"id\"] != order[\"id\"]]\n                                        logger.info(f\"Removed cancelled buy order id={order['id']} from bot_state['buy_orders']\")\n                                    else:\n                                        bot_state[\"sell_orders\"] = [o for o in bot_state[\"sell_orders\"] if o[\"id\"] != order[\"id\"]]\n                                        logger.info(f\"Removed cancelled sell order id={order['id']} from bot_state['sell_orders']\")\n                                else:\n                                    logger.warning(f\"Failed to cancel excess {order['side']} order: id={order['id']}, \"\n                                                f\"feature={order.get('feature', 'base')}\")\n                            except Exception as e:\n                                logger.error(f\"Failed to cancel excess {order['side']} order id={order['id']}: {e}\")\n\n                    logger.info(f\"Active grid after checks: Buy orders={len(bot_state['buy_orders'])}, Sell orders={len(bot_state['sell_orders'])}\")\n\n                    # Log data structures\n                    logger.info(f\"recent_trade_data columns: {recent_trade_data.columns.tolist()}, rows: {len(recent_trade_data)}\")\n                    logger.info(f\"feature_cache columns: {bot_state['feature_cache'].columns.tolist()}, rows={len(bot_state['feature_cache'])}\")\n\n                    logger.info(f\"Total order checking time: {time.time() - check_orders_start_time:.2f} seconds\")\n                except Exception as e:\n                    logger.error(f\"Error in order checking process: {e}\")\n\n                # 6 ML Predictions\n                try:\n                    # Update live data from WebSocket\n                    ohlcv_df, raw_trades_for_ohlcv_df, updated = _update_live_data_from_websocket(\n                        websocket_manager, ohlcv_df, raw_trades_for_ohlcv_df\n                    )\n                    logger.info(f\"Updated WebSocket data: ohlcv_df={len(ohlcv_df)} rows, feature_cache={len(bot_state['feature_cache'])} rows\")\n\n                    # Sync recent_trade_data\n                    recent_trade_data = bot_state[\"feature_cache\"].tail(config.SKLEARN_LOOKBACK).copy()\n                    logger.info(f\"recent_trade_data columns: {recent_trade_data.columns.tolist()}, rows: {len(recent_trade_data)}\")\n\n                    # Define dynamic defaults\n                    close_mean = ohlcv_df[\"close\"].mean() if not ohlcv_df.empty else current_price\n                    defaults = {\n                        \"rsi\": ohlcv_df[\"rsi\"].mean() if not ohlcv_df.empty and \"rsi\" in ohlcv_df else 50.0,\n                        \"ema\": close_mean,\n                        \"volatility\": ohlcv_df[\"volatility\"].mean() if not ohlcv_df.empty and \"volatility\" in ohlcv_df else 0.1,\n                        \"macd\": 0.0,\n                        \"macd_signal\": 0.0,\n                        \"bollinger_upper\": close_mean,\n                        \"bollinger_lower\": close_mean,\n                        \"momentum\": 0.0,\n                        \"volume_trend\": 0.0,\n                        \"atr\": close_mean * 0.01,\n                        \"vwap\": close_mean,\n                        \"trades\": int(ohlcv_df[\"trades\"].mean()) if not ohlcv_df.empty and \"trades\" in ohlcv_df else 0,\n                        \"close\": close_mean,\n                        \"volume\": ohlcv_df[\"volume\"].mean() if not ohlcv_df.empty and \"volume\" in ohlcv_df else 0.0,\n                        \"price_spread\": 0.0,\n                        \"returns\": 0.0,\n                        \"volume_change\": 0.0,\n                        \"trade_intensity\": 0.0\n                    }\n                    logger.info(\"Defined dynamic defaults using WebSocket data\")\n\n                    # Ensure required features\n                    required_features = [\n                        \"close\", \"volume\", \"trades\", \"rsi\", \"ema\", \"volatility\", \"macd\", \"macd_signal\",\n                        \"bollinger_upper\", \"bollinger_lower\", \"momentum\", \"volume_trend\", \"atr\", \"vwap\",\n                        \"price_spread\", \"returns\", \"volume_change\", \"trade_intensity\"\n                    ]\n                    for feature in required_features:\n                        if feature not in recent_trade_data:\n                            logger.warning(f\"Adding missing feature {feature} with default\")\n                            recent_trade_data[feature] = defaults.get(feature, 0.0)\n                        if recent_trade_data[feature].isna().any():\n                            logger.info(f\"Filling {recent_trade_data[feature].isna().sum()} NaN values in {feature}\")\n                            recent_trade_data[feature] = recent_trade_data[feature].ffill().bfill().fillna(defaults.get(feature, 0.0))\n\n                    # Filter to required features\n                    recent_trade_data = recent_trade_data[required_features].copy()\n                    logger.debug(f\"Filtered recent_trade_data to {len(recent_trade_data)} rows with features: {recent_trade_data.columns.tolist()}\")\n\n                    # Validate timestamps\n                    if \"timestamp\" not in recent_trade_data:\n                        logger.warning(\"Adding timestamp column\")\n                        recent_trade_data[\"timestamp\"] = ohlcv_df[\"timestamp\"].iloc[-len(recent_trade_data):].reindex(recent_trade_data.index).fillna(pd.Timestamp.now(tz=\"UTC\"))\n                    if recent_trade_data[\"timestamp\"].isna().any():\n                        logger.warning(\"Fixing NaN timestamps\")\n                        recent_trade_data[\"timestamp\"] = recent_trade_data[\"timestamp\"].fillna(pd.Timestamp.now(tz=\"UTC\"))\n                    recent_trade_data[\"timestamp\"] = pd.to_datetime(recent_trade_data[\"timestamp\"], errors=\"coerce\").dt.tz_convert(\"UTC\")\n\n                    # Pad recent_trade_data if necessary\n                    if len(recent_trade_data) < config.SKLEARN_LOOKBACK:\n                        logger.warning(f\"Padding recent_trade_data: {len(recent_trade_data)} rows, need {config.SKLEARN_LOOKBACK}\")\n                        padding_rows = config.SKLEARN_LOOKBACK - len(recent_trade_data)\n                        padding_data = bot_state[\"feature_cache\"][required_features].tail(padding_rows + len(recent_trade_data)).head(padding_rows).copy()\n                        for feature in required_features:\n                            if feature not in padding_data:\n                                padding_data[feature] = defaults.get(feature, 0.0)\n                            padding_data[feature] = padding_data[feature].ffill().bfill().fillna(defaults.get(feature, 0.0))\n                        recent_trade_data = pd.concat([padding_data, recent_trade_data], ignore_index=True).tail(config.SKLEARN_LOOKBACK)\n\n                    logger.info(f\"Prepared ML data: rows={len(recent_trade_data)}, features={required_features}\")\n\n                    # Run ML predictions\n                    log_ref_timestamp = recent_trade_data['timestamp'].iloc[-1] if not recent_trade_data.empty else pd.Timestamp.now(tz=\"UTC\")\n                    log_ref_current_close = recent_trade_data['close'].iloc[-1] if not recent_trade_data.empty else current_price\n\n                    sklearn_predicted = last_sklearn_prediction\n                    if bot_state.get(\"sklearn_rf_model\"):\n                        try:\n                            sklearn_predicted = predict_sklearn_price(\n                                bot_state[\"sklearn_rf_model\"],\n                                bot_state[\"scaler_sklearn_rf\"],\n                                config.SKLEARN_LOOKBACK,\n                                recent_trade_data,\n                                current_price,\n                                last_sklearn_prediction,\n                            )\n                            logger.info(\n                                f\"Sklearn Prediction: timestamp={log_ref_timestamp}, \"\n                                f\"predicted_price={sklearn_predicted:.2f}, current_close={log_ref_current_close:.2f}\"\n                            )\n                        except Exception as e:\n                            logger.error(f\"Sklearn prediction failed: {e}\")\n                            sklearn_predicted = last_sklearn_prediction or current_price\n\n                    pytorch_predicted = last_pytorch_prediction\n                    if bot_state.get(\"pytorch_model\"):\n                        try:\n                            pytorch_predicted = predict_pytorch_price(\n                                bot_state[\"pytorch_model\"],\n                                bot_state[\"pytorch_scaler\"],\n                                bot_state[\"pytorch_target_scaler\"],\n                                config.PYTORCH_LOOKBACK,\n                                recent_trade_data,\n                                current_price,\n                                last_pytorch_prediction,\n                            )\n                            logger.info(\n                                f\"Pytorch Prediction: timestamp={log_ref_timestamp}, \"\n                                f\"predicted_price={pytorch_predicted:.2f}, current_close={log_ref_current_close:.2f}\"\n                            )\n                        except Exception as e:\n                            logger.error(f\"Pytorch prediction failed: {e}\")\n                            pytorch_predicted = last_pytorch_prediction or current_price\n\n                    xgb_predicted = last_xgb_prediction\n                    if bot_state.get(\"xgb_model\"):\n                        try:\n                            xgb_predicted = predict_xgboost_price(\n                                bot_state[\"xgb_model\"],\n                                bot_state[\"xgb_scaler\"],\n                                60,  # Fixed lookback to match training\n                                recent_trade_data,\n                                current_price,\n                                last_xgb_prediction,\n                            )\n                            logger.info(\n                                f\"XGBoost Prediction: timestamp={log_ref_timestamp}, \"\n                                f\"predicted_price={xgb_predicted:.2f}, current_close={log_ref_current_close:.2f}\"\n                            )\n                        except Exception as e:\n                            logger.error(f\"XGBoost prediction failed: {e}\")\n                            xgb_predicted = last_xgb_prediction or current_price\n\n                    meta_predicted = log_ref_current_close\n                    if bot_state.get(\"meta_model\") and bot_state.get(\"meta_scaler\") and all(np.isfinite([sklearn_predicted, pytorch_predicted, xgb_predicted])):\n                        volatility = (\n                            recent_trade_data[\"volatility\"].iloc[-1]\n                            if \"volatility\" in recent_trade_data and not recent_trade_data.empty and not pd.isna(recent_trade_data[\"volatility\"].iloc[-1])\n                            else defaults[\"volatility\"]\n                        )\n                        try:\n                            meta_predicted = predict_meta_model(\n                                bot_state[\"meta_model\"],\n                                bot_state[\"meta_scaler\"],\n                                sklearn_predicted,\n                                pytorch_predicted,\n                                xgb_predicted,\n                                volatility,\n                                current_close=log_ref_current_close\n                            )\n                            logger.info(\n                                f\"Meta-Model Prediction: timestamp={log_ref_timestamp}, \"\n                                f\"predicted_price={meta_predicted:.2f}, current_close={log_ref_current_close:.2f}\"\n                            )\n                        except Exception as e:\n                            logger.error(f\"Meta-model prediction failed: {e}\")\n                            valid_preds = [p for p in [sklearn_predicted, pytorch_predicted, xgb_predicted] if np.isfinite(p)]\n                            meta_predicted = np.mean(valid_preds) if valid_preds else log_ref_current_close\n\n                    # Validate predictions\n                    valid_predictions = [\n                        p for p in [sklearn_predicted, pytorch_predicted, xgb_predicted, meta_predicted]\n                        if np.isfinite(p) and 1000 < p < 10000\n                    ]\n                    if not valid_predictions:\n                        logger.warning(\"No valid ML predictions, using current price\")\n                        sklearn_predicted = pytorch_predicted = xgb_predicted = meta_predicted = current_price\n                    else:\n                        avg_prediction = sum(valid_predictions) / len(valid_predictions)\n                        sklearn_predicted = sklearn_predicted if np.isfinite(sklearn_predicted) and 1000 < sklearn_predicted < 10000 else avg_prediction\n                        pytorch_predicted = pytorch_predicted if np.isfinite(pytorch_predicted) and 1000 < pytorch_predicted < 10000 else avg_prediction\n                        xgb_predicted = xgb_predicted if np.isfinite(xgb_predicted) and 1000 < xgb_predicted < 10000 else avg_prediction\n                        meta_predicted = meta_predicted if np.isfinite(meta_predicted) and 1000 < meta_predicted < 10000 else avg_prediction\n\n                    # Update prediction history\n                    prediction_history = bot_state.get(\n                        \"prediction_history\",\n                        pd.DataFrame(\n                            columns=[\n                                \"sklearn_pred\", \"pytorch_pred\", \"xgb_pred\",\n                                \"current_price\", \"volatility\", \"actual_price\"\n                            ]\n                        ),\n                    )\n                    new_entry = pd.DataFrame(\n                        {\n                            \"sklearn_pred\": [sklearn_predicted],\n                            \"pytorch_pred\": [pytorch_predicted],\n                            \"xgb_pred\": [xgb_predicted],\n                            \"current_price\": [current_price],\n                            \"volatility\": [\n                                recent_trade_data[\"volatility\"].iloc[-1]\n                                if \"volatility\" in recent_trade_data and not recent_trade_data.empty and not pd.isna(recent_trade_data[\"volatility\"].iloc[-1])\n                                else defaults[\"volatility\"]\n                            ],\n                            \"actual_price\": [\n                                recent_trade_data[\"close\"].iloc[-1]\n                                if not recent_trade_data.empty\n                                else current_price\n                            ],\n                        }\n                    )\n                    prediction_history = pd.concat([prediction_history, new_entry], ignore_index=True).tail(config.PREDICTIONS_LIMIT)\n                    bot_state[\"prediction_history\"] = prediction_history\n                    logger.debug(f\"Updated prediction_history: {len(prediction_history)} rows\")\n                    last_sklearn_prediction = sklearn_predicted\n                    last_pytorch_prediction = pytorch_predicted\n                    last_xgb_prediction = xgb_predicted\n                except Exception as ml_error:\n                    logger.error(f\"Error in ML predictions: {ml_error}\")\n                    sklearn_predicted = last_sklearn_prediction or current_price\n                    pytorch_predicted = last_pytorch_prediction or current_price\n                    xgb_predicted = last_xgb_prediction or current_price\n                    meta_predicted = current_price\n\n                # Online Updates (separate block)\n                if len(recent_trade_data) >= config.PYTORCH_LOOKBACK:\n                    try:\n                        # Sklearn SGD update\n                        X_sgd = recent_trade_data.tail(config.SKLEARN_LOOKBACK)[required_features]\n                        y_sgd = recent_trade_data[\"close\"].tail(config.SKLEARN_LOOKBACK).values\n                        logger.debug(f\"Sklearn SGD update: X shape={X_sgd.shape}, y shape={y_sgd.shape}\")\n                        if bot_state.get(\"sklearn_sgd_model\"):\n                            bot_state[\"sklearn_sgd_model\"] = online_update_sklearn(\n                                bot_state[\"sklearn_sgd_model\"],\n                                bot_state[\"scaler_sklearn_sgd\"],\n                                X_sgd,\n                                y_sgd,\n                                lookback=config.SKLEARN_LOOKBACK\n                            )\n                            logger.info(\"Sklearn SGD model updated online\")\n                        else:\n                            logger.error(\"SGDRegressor model not initialized\")\n\n                        # PyTorch update\n                        X_pytorch = recent_trade_data.tail(config.PYTORCH_LOOKBACK)[required_features]\n                        y_pytorch = recent_trade_data[\"close\"].tail(config.PYTORCH_LOOKBACK)\n                        logger.debug(f\"PyTorch update: X shape={X_pytorch.shape}, y shape={y_pytorch.shape}\")\n                        if bot_state.get(\"pytorch_model\"):\n                            bot_state[\"pytorch_model\"] = online_update_pytorch(\n                                bot_state[\"pytorch_model\"],\n                                bot_state[\"pytorch_scaler\"],\n                                bot_state[\"pytorch_target_scaler\"],\n                                X_pytorch,\n                                y_pytorch,\n                                config.DEVICE\n                            )\n                            logger.info(\"PyTorch model updated online\")\n                        else:\n                            logger.error(\"PyTorch model not initialized\")\n\n                        logger.info(\"Performed online model updates\")\n                    except Exception as update_error:\n                        logger.error(f\"Error in online model updates: {update_error}\")\n\n                # 7. Adjust Parameters\n                old_grid_size = config.GRID_SIZE\n                old_position_size = config.POSITION_SIZE\n                try:\n                    if sklearn_predicted and pytorch_predicted and xgb_predicted and meta_predicted:\n                        logger.info(\n                            f\"ML Predictions: Sklearn={sklearn_predicted:.2f}, PyTorch={pytorch_predicted:.2f}, \"\n                            f\"XGBoost={xgb_predicted:.2f}, Meta={meta_predicted:.2f}, Current Price={current_price:.2f}\"\n                        )\n                        logger.info(\n                            f\"Config Parameters: ML_CONFIDENCE_THRESHOLD={config.ML_CONFIDENCE_THRESHOLD:.2f}, \"\n                            f\"VOLATILITY_THRESHOLD={config.VOLATILITY_THRESHOLD:.2f}, ML_TREND_WEIGHT={config.ML_TREND_WEIGHT:.2f}, \"\n                            f\"ML_GRID_ADJUST_FACTOR={config.ML_GRID_ADJUST_FACTOR:.3f}, ML_POSITION_ADJUST_FACTOR={config.ML_POSITION_ADJUST_FACTOR:.3f}\"\n                        )\n                        logger.info(\n                            f\"Initial Parameters: GRID_SIZE={initial_grid_size:.2f}, POSITION_SIZE={initial_position_size:.6f}\"\n                        )\n\n                        # Accumulate MSEs\n                        meta_metrics = bot_state.get(\"meta_metrics\", {\n                            \"sklearn_mse\": [],\n                            \"pytorch_mse\": [],\n                            \"xgb_mse\": [],\n                            \"meta_mse\": []\n                        })\n                        actual_price = recent_data[\"close\"].iloc[-1] if not recent_data.empty else current_price\n                        meta_metrics[\"sklearn_mse\"].append((sklearn_predicted - actual_price) ** 2)\n                        meta_metrics[\"pytorch_mse\"].append((pytorch_predicted - actual_price) ** 2)\n                        meta_metrics[\"xgb_mse\"].append((xgb_predicted - actual_price) ** 2)\n                        meta_metrics[\"meta_mse\"].append((meta_predicted - actual_price) ** 2)\n                        # Limit size to prevent memory issues\n                        for key in meta_metrics:\n                            meta_metrics[key] = meta_metrics[key][-config.PREDICTION_HISTORY_MAX_ROWS:]\n                        bot_state[\"meta_metrics\"] = meta_metrics\n\n                        # Validate and initialize meta_metrics\n                        if not isinstance(meta_metrics, dict) or not all(\n                            key in meta_metrics for key in [\"sklearn_mse\", \"pytorch_mse\", \"xgb_mse\", \"meta_mse\"]\n                        ):\n                            logger.warning(f\"Invalid meta_metrics structure: {meta_metrics}, initializing default\")\n                            meta_metrics = {\n                                \"sklearn_mse\": [],\n                                \"pytorch_mse\": [],\n                                \"xgb_mse\": [],\n                                \"meta_mse\": []\n                            }\n                            bot_state[\"meta_metrics\"] = meta_metrics\n\n                        # Format Meta Metrics\n                        model_rows = {\n                            \"Sklearn\": len(meta_metrics[\"sklearn_mse\"]),\n                            \"PyTorch\": len(meta_metrics[\"pytorch_mse\"]),\n                            \"XGBoost\": len(meta_metrics[\"xgb_mse\"]),\n                            \"Meta\": len(meta_metrics[\"meta_mse\"])\n                        }\n                        model_values = {\n                            \"Sklearn\": {\n                                \"Recent\": meta_metrics[\"sklearn_mse\"][-1] if meta_metrics[\"sklearn_mse\"] else float(\"inf\"),\n                                \"Average\": np.mean(meta_metrics[\"sklearn_mse\"]) if meta_metrics[\"sklearn_mse\"] else float(\"inf\")\n                            },\n                            \"PyTorch\": {\n                                \"Recent\": meta_metrics[\"pytorch_mse\"][-1] if meta_metrics[\"pytorch_mse\"] else float(\"inf\"),\n                                \"Average\": np.mean(meta_metrics[\"pytorch_mse\"]) if meta_metrics[\"pytorch_mse\"] else float(\"inf\")\n                            },\n                            \"XGBoost\": {\n                                \"Recent\": meta_metrics[\"xgb_mse\"][-1] if meta_metrics[\"xgb_mse\"] else float(\"inf\"),\n                                \"Average\": np.mean(meta_metrics[\"xgb_mse\"]) if meta_metrics[\"xgb_mse\"] else float(\"inf\")\n                            },\n                            \"Meta\": {\n                                \"Recent\": meta_metrics[\"meta_mse\"][-1] if meta_metrics[\"meta_mse\"] else float(\"inf\"),\n                                \"Average\": np.mean(meta_metrics[\"meta_mse\"]) if meta_metrics[\"meta_mse\"] else float(\"inf\")\n                            }\n                        }\n                        logger.info(\n                            f\"Meta Metrics - Model Rows: Sklearn={model_rows['Sklearn']} rows, PyTorch={model_rows['PyTorch']} rows, \"\n                            f\"XGBoost={model_rows['XGBoost']} rows, Meta={model_rows['Meta']} rows\"\n                        )\n                        logger.info(\n                            f\"Meta Metrics - Model Values: \"\n                            f\"Sklearn(Recent={model_values['Sklearn']['Recent']:.6f}, Avg={model_values['Sklearn']['Average']:.6f}), \"\n                            f\"PyTorch(Recent={model_values['PyTorch']['Recent']:.6f}, Avg={model_values['PyTorch']['Average']:.6f}), \"\n                            f\"XGBoost(Recent={model_values['XGBoost']['Recent']:.6f}, Avg={model_values['XGBoost']['Average']:.6f}), \"\n                            f\"Meta(Recent={model_values['Meta']['Recent']:.6f}, Avg={model_values['Meta']['Average']:.6f})\"\n                        )\n\n                        mse_values = {\n                            \"sklearn\": model_values[\"Sklearn\"][\"Average\"],\n                            \"pytorch\": model_values[\"PyTorch\"][\"Average\"],\n                            \"xgboost\": model_values[\"XGBoost\"][\"Average\"],\n                            \"meta\": model_values[\"Meta\"][\"Average\"]\n                        }\n\n                        best_mse = min([v for v in mse_values.values() if v != float(\"inf\")] or [1.0])\n                        inverse_mse = {}\n                        for k, v in mse_values.items():\n                            if v != float(\"inf\"):\n                                inverse_mse[k] = 1.0 / max(v, 1e-6)\n                                if k == \"meta\" and v <= 2.0 * best_mse:\n                                    inverse_mse[k] = max(inverse_mse[k], 0.1 * sum(inverse_mse.values()))\n                            else:\n                                inverse_mse[k] = 0.0\n                        total_inverse = sum(inverse_mse.values())\n                        mse_weights = (\n                            {k: v / total_inverse for k, v in inverse_mse.items()}\n                            if total_inverse > 0\n                            else {\n                                \"sklearn\": config.SKLEARN_WEIGHT,\n                                \"pytorch\": config.PYTORCH_WEIGHT,\n                                \"xgboost\": config.XGB_WEIGHT,\n                                \"meta\": config.META_WEIGHT,\n                            }\n                        )\n\n                        config_weights = {\n                            \"sklearn\": config.SKLEARN_WEIGHT,\n                            \"pytorch\": config.PYTORCH_WEIGHT,\n                            \"xgboost\": config.XGB_WEIGHT,\n                            \"meta\": config.META_WEIGHT,\n                        }\n                        logger.info(\n                            f\"Config Weights: Sklearn={config_weights['sklearn']:.3f}, PyTorch={config_weights['pytorch']:.3f}, \"\n                            f\"XGBoost={config_weights['xgboost']:.3f}, Meta={config_weights['meta']:.3f}\"\n                        )\n                        model_weights = {\n                            k: 0.5 * config_weights[k] + 0.5 * mse_weights[k]\n                            for k in [\"sklearn\", \"pytorch\", \"xgboost\", \"meta\"]\n                        }\n                        total_weight = sum(model_weights.values())\n                        if total_weight > 0:\n                            model_weights = {k: v / total_weight for k, v in model_weights.items()}\n                        else:\n                            model_weights = {\n                                \"sklearn\": config.SKLEARN_WEIGHT,\n                                \"pytorch\": config.PYTORCH_WEIGHT,\n                                \"xgboost\": config.XGB_WEIGHT,\n                                \"meta\": config.META_WEIGHT,\n                            }\n                        logger.info(\n                            f\"Final Model Weights: Sklearn={model_weights['sklearn']:.3f}, PyTorch={model_weights['pytorch']:.3f}, \"\n                            f\"XGBoost={model_weights['xgboost']:.3f}, Meta={model_weights['meta']:.3f}\"\n                        )\n\n                        # Check for static meta-model predictions\n                        if meta_predicted is not None and np.isfinite(meta_predicted):\n                            bot_state[\"recent_meta_outputs\"].append(meta_predicted)\n                        \n                        meta_predictions_list = list(bot_state[\"recent_meta_outputs\"])\n                        if not meta_predictions_list:\n                            meta_predictions_list = [meta_predicted if meta_predicted is not None and np.isfinite(meta_predicted) else current_price]\n\n                        meta_variance = np.var(meta_predictions_list) if len(meta_predictions_list) > 1 else 0.0\n                        logger.info(f\"Meta-model prediction variance: {meta_variance:.6f}\")\n                        if meta_variance < 0.01:\n                            logger.warning(f\"Static meta-model predictions detected: variance={meta_variance:.6f}, reducing meta weight\")\n                            model_weights['meta'] = model_weights['meta'] * 0.5\n                            total_other = sum([v for k, v in model_weights.items() if k != 'meta'])\n                            for k in ['sklearn', 'pytorch', 'xgboost']:\n                                model_weights[k] = model_weights[k] * (1.0 / total_other) if total_other > 0 else model_weights[k]\n                            logger.info(\n                                f\"Adjusted Model Weights: Sklearn={model_weights['sklearn']:.3f}, PyTorch={model_weights['pytorch']:.3f}, \"\n                                f\"XGBoost={model_weights['xgboost']:.3f}, Meta={model_weights['meta']:.3f}\"\n                            )\n\n                        sklearn_trend = (\n                            (sklearn_predicted - current_price) * config.ML_TREND_WEIGHT * model_weights[\"sklearn\"]\n                        )\n                        pytorch_trend = (\n                            (pytorch_predicted - current_price) * config.ML_TREND_WEIGHT * model_weights[\"pytorch\"]\n                        )\n                        xgb_trend = (\n                            (xgb_predicted - current_price) * config.ML_TREND_WEIGHT * model_weights[\"xgboost\"]\n                        )\n                        meta_trend = (\n                            (meta_predicted - current_price) * config.ML_TREND_WEIGHT * model_weights[\"meta\"]\n                        )\n                        current_trend = current_price - previous_price if previous_price else 0.0\n                        logger.debug(\n                            f\"Weighted Trend Calculations: Sklearn=({sklearn_predicted:.2f}-{current_price:.2f})*{config.ML_TREND_WEIGHT}*{model_weights['sklearn']:.3f}={sklearn_trend:.2f}, \"\n                            f\"PyTorch=({pytorch_predicted:.2f}-{current_price:.2f})*{config.ML_TREND_WEIGHT}*{model_weights['pytorch']:.3f}={pytorch_trend:.2f}, \"\n                            f\"XGBoost=({xgb_predicted:.2f}-{current_price:.2f})*{config.ML_TREND_WEIGHT}*{model_weights['xgboost']:.3f}={xgb_trend:.2f}, \"\n                            f\"Meta=({meta_predicted:.2f}-{current_price:.2f})*{config.ML_TREND_WEIGHT}*{model_weights['meta']:.3f}={meta_trend:.2f}\"\n                        )\n                        logger.info(\n                            f\"Trend Contributions: Sklearn={sklearn_trend:.2f}, PyTorch={pytorch_trend:.2f}, \"\n                            f\"XGBoost={xgb_trend:.2f}, Meta={meta_trend:.2f}, Current={current_trend:.2f}\"\n                        )\n\n                        volatility = (\n                            ohlcv_df[\"volatility\"].iloc[-1]\n                            if not ohlcv_df.empty\n                            and \"volatility\" in ohlcv_df.columns\n                            and not pd.isna(ohlcv_df[\"volatility\"].iloc[-1])\n                            and ohlcv_df[\"volatility\"].iloc[-1] >= config.VOLATILITY_THRESHOLD\n                            else config.LOG_DEFAULT_VOLATILITY\n                        )\n                        logger.info(f\"Volatility: {volatility:.2f}% (threshold={config.VOLATILITY_THRESHOLD:.2f})\")\n\n                        historical_mean = historical_data['volume'].mean() if not historical_data.empty else 0.0\n                        volume_factor = (\n                            min(\n                                config.VOLUME_FACTOR_MAX,\n                                max(\n                                    config.VOLUME_FACTOR_MIN,\n                                    current_volume / historical_mean,\n                                ),\n                            )\n                            if not historical_data.empty and historical_mean > 0\n                            else 1.0\n                        )\n                        logger.info(\n                            f\"Volume Factor: {volume_factor:.2f} (current_volume={current_volume:.2f}, \"\n                            f\"historical_mean={historical_mean:.2f})\"\n                        )\n\n                        up_votes = (\n                            (1 if meta_trend > 0 else 0) * abs(meta_trend)\n                            + (1 if sklearn_trend > 0 else 0) * abs(sklearn_trend)\n                            + (1 if pytorch_trend > 0 else 0) * abs(pytorch_trend)\n                            + (1 if xgb_trend > 0 else 0) * abs(xgb_trend)\n                            + (1 if current_trend > 0 else 0) * abs(current_trend)\n                        )\n                        down_votes = (\n                            (1 if meta_trend < 0 else 0) * abs(meta_trend)\n                            + (1 if sklearn_trend < 0 else 0) * abs(sklearn_trend)\n                            + (1 if pytorch_trend < 0 else 0) * abs(pytorch_trend)\n                            + (1 if xgb_trend < 0 else 0) * abs(xgb_trend)\n                            + (1 if current_trend < 0 else 0) * abs(current_trend)\n                        )\n                        total_confidence = up_votes + down_votes\n                        up_confidence = up_votes / total_confidence if total_confidence > 0 else 0.5\n                        down_confidence = down_votes / total_confidence if total_confidence > 0 else 0.5\n                        logger.info(\n                            f\"Trend Voting: Up Votes={up_votes:.2f}, Down Votes={down_votes:.2f}, \"\n                            f\"Up Confidence={up_confidence:.2f}, Down Confidence={down_confidence:.2f}\"\n                        )\n\n                        grid_adjust_factor = 1.0 + (volatility / 100) * config.VOLATILITY_GRID_FACTOR\n                        position_adjust_factor = 1.0 + (volatility / 100) * config.VOLATILITY_POSITION_FACTOR\n                        logger.info(\n                            f\"Adjustment Factors: Grid={grid_adjust_factor:.3f}, Position={position_adjust_factor:.3f}\"\n                        )\n\n                        max_usd_position = (\n                            bot_state[\"initial_usd\"] / (config.NUM_BUY_GRID_LINES * current_price)\n                            if bot_state.get(\"initial_usd\", 0) > 0\n                            else config.MAX_POSITION_SIZE\n                        )\n                        max_eth_position = (\n                            (bot_state[\"initial_usd\"] / config.ETH_BALANCE_DIVISOR)\n                            / current_price\n                            / config.NUM_SELL_GRID_LINES\n                            if bot_state.get(\"initial_usd\", 0) > 0\n                            else config.MAX_POSITION_SIZE\n                        )\n                        logger.info(\n                            f\"Position Limits: Max USD={max_usd_position:.6f}, Max ETH={max_eth_position:.6f}\"\n                        )\n\n                        if up_confidence > config.ML_CONFIDENCE_THRESHOLD:\n                            new_grid_size = old_grid_size * (\n                                1.0 + config.ML_GRID_ADJUST_FACTOR * grid_adjust_factor * volume_factor\n                            )\n                            config.GRID_SIZE = min(\n                                config.MAX_GRID_SIZE,\n                                max(config.MIN_GRID_SIZE, new_grid_size),\n                            )\n                            new_position_size = initial_position_size * (\n                                1.0 + config.ML_POSITION_ADJUST_FACTOR * position_adjust_factor * up_confidence\n                            )\n                            # Clamp new_position_size to MIN and MAX bounds\n                            new_position_size = max(\n                                config.MIN_POSITION_SIZE,\n                                min(config.MAX_POSITION_SIZE, new_position_size)\n                            )\n                            config.POSITION_SIZE = min(\n                                max_usd_position,\n                                max_eth_position,\n                                new_position_size,\n                            )\n                            # Ensure final POSITION_SIZE respects MIN_POSITION_SIZE\n                            config.POSITION_SIZE = max(config.MIN_POSITION_SIZE, config.POSITION_SIZE)\n                            logger.info(\n                                f\"ML Uptrend (confidence: {up_confidence:.2f}), GRID_SIZE: {old_grid_size:.2f} -> {config.GRID_SIZE:.2f}, \"\n                                f\"POSITION_SIZE: {old_position_size:.6f} -> {config.POSITION_SIZE:.6f}\"\n                            )\n                        elif down_confidence > config.ML_CONFIDENCE_THRESHOLD:\n                            new_grid_size = old_grid_size * (\n                                1.0 - config.ML_GRID_ADJUST_FACTOR * grid_adjust_factor * volume_factor\n                            )\n                            config.GRID_SIZE = max(config.MIN_GRID_SIZE, new_grid_size)\n                            new_position_size = initial_position_size * (\n                                1.0 - config.ML_POSITION_ADJUST_FACTOR * position_adjust_factor * down_confidence\n                            )\n                            # Clamp new_position_size to MIN and MAX bounds\n                            new_position_size = max(\n                                config.MIN_POSITION_SIZE,\n                                min(config.MAX_POSITION_SIZE, new_position_size)\n                            )\n                            config.POSITION_SIZE = max(\n                                config.MIN_POSITION_SIZE,\n                                min(\n                                    max_usd_position,\n                                    max_eth_position,\n                                    new_position_size,\n                                ),\n                            )\n                            logger.info(\n                                f\"ML Downtrend (confidence: {down_confidence:.2f}), GRID_SIZE: {old_grid_size:.2f} -> {config.GRID_SIZE:.2f}, \"\n                                f\"POSITION_SIZE: {old_position_size:.6f} -> {config.POSITION_SIZE:.6f}\"\n                            )\n\n                        if \"last_reset_grid_size\" not in bot_state:\n                            bot_state[\"last_reset_grid_size\"] = initial_grid_size\n\n                        last_reset_grid_size = bot_state[\"last_reset_grid_size\"]\n                        grid_change = (\n                            abs(config.GRID_SIZE - last_reset_grid_size) / last_reset_grid_size\n                            if last_reset_grid_size > 0\n                            else 0\n                        )\n                        position_change = (\n                            abs(config.POSITION_SIZE - initial_position_size) / initial_position_size\n                            if initial_position_size > 0\n                            else 0\n                        )\n\n                        if config.GRID_SIZE != old_grid_size:\n                            current_max_order_range = config.MAX_ORDER_RANGE * (config.GRID_SIZE / config.MIN_GRID_SIZE)\n                            current_stagnation_timeout = config.STAGNATION_TIMEOUT * (\n                                config.MIN_GRID_SIZE / config.GRID_SIZE\n                            )\n                            logger.info(\n                                f\"ML Grid adjusted - GRID_SIZE: {old_grid_size:.2f} -> {config.GRID_SIZE:.2f}, \"\n                                f\"MAX_ORDER_RANGE: {current_max_order_range:.2f}, STAGNATION_TIMEOUT: {current_stagnation_timeout:.0f}s, \"\n                                f\"Volatility: {volatility:.2f}%\"\n                            )\n                            bot_state[\"last_reset_grid_size\"] = config.GRID_SIZE\n                    else:\n                        logger.warning(\n                            f\"Missing ML predictions: Sklearn={'set' if sklearn_predicted else 'missing'}, \"\n                            f\"PyTorch={'set' if pytorch_predicted else 'missing'}, \"\n                            f\"XGBoost={'set' if xgb_predicted else 'missing'}, \"\n                            f\"Meta={'set' if meta_predicted else 'missing'}, skipping parameter adjustment\"\n                        )\n                except Exception as param_error:\n                    logger.error(f\"Error adjusting parameters: {param_error}\")\n                    config.GRID_SIZE = old_grid_size\n                    config.POSITION_SIZE = old_position_size\n\n                # 8. Send WebSocket Updates\n                try:\n                    valid_orders_to_send = []\n                    for order in orders_to_send:\n                        if not order or not isinstance(order, dict) or \"id\" not in order:\n                            logger.warning(f\"Skipping invalid order for WebSocket send: {order}\")\n                            continue\n                        valid_orders_to_send.append(order)\n\n                    timestamp = (\n                        recent_data[\"timestamp\"].iloc[-1]\n                        if \"timestamp\" in recent_data and pd.notna(recent_data[\"timestamp\"].iloc[-1])\n                        else pd.Timestamp.now(tz=\"UTC\")\n                    )\n                    orders_to_send.extend(\n                        [\n                            {\n                                \"type\": \"predictions\",\n                                \"timestamp\": int(current_time * 1000),\n                                \"sklearn_predicted\": float(last_sklearn_prediction),\n                                \"pytorch_predicted\": float(last_pytorch_prediction),\n                                \"xgb_predicted\": float(last_xgb_prediction),\n                            },\n                            {\n                                \"type\": \"pl_update\",\n                                \"timestamp\": int(current_time * 1000),\n                                \"total_pl\": float(config.TOTAL_PL),\n                            },\n                            {\n                                \"type\": \"status\",\n                                \"paused\": bot_state[\"paused\"],\n                                \"current_price\": float(current_price),\n                                \"buy_orders\": len(bot_state[\"buy_orders\"]),\n                                \"sell_orders\": len(bot_state[\"sell_orders\"]),\n                                \"total_pl\": float(config.TOTAL_PL),\n                                \"sklearn_prediction\": float(last_sklearn_prediction),\n                                \"pytorch_prediction\": float(last_pytorch_prediction),\n                                \"xgb_prediction\": float(last_xgb_prediction),\n                                \"eth_balance\": float(eth_balance),\n                                \"usd_balance\": float(usd_balance),\n                                \"grid_size\": float(config.GRID_SIZE),\n                                \"position_size\": float(config.POSITION_SIZE),\n                                \"num_buy_grid_lines\": int(config.NUM_BUY_GRID_LINES),\n                                \"num_sell_grid_lines\": int(config.NUM_SELL_GRID_LINES),\n                                \"min_grid_size\": float(config.MIN_GRID_SIZE),\n                                \"max_grid_size\": float(config.MAX_GRID_SIZE),\n                                \"check_order_frequency\": float(config.CHECK_ORDER_FREQUENCY),\n                                \"stagnation_timeout\": int(current_stagnation_timeout),\n                                \"max_order_range\": float(current_max_order_range),\n                                \"sklearn_accuracy\": float(\n                                    sum(prediction_accuracy[\"sklearn\"]) / max(len(prediction_accuracy[\"sklearn\"]), 1)\n                                ),\n                                \"pytorch_accuracy\": float(\n                                    sum(prediction_accuracy[\"pytorch\"]) / max(len(prediction_accuracy[\"pytorch\"]), 1)\n                                ),\n                                \"xgboost_accuracy\": float(\n                                    sum(prediction_accuracy[\"xgboost\"]) / max(len(prediction_accuracy[\"xgboost\"]), 1)\n                                ),\n                            },\n                            {\n                                \"type\": \"grid_trade\",\n                                \"timestamp\": timestamp.isoformat(),\n                                \"price\": float(ohlcv_df[\"close\"].iloc[-1] if not ohlcv_df.empty else current_price),\n                                \"volume\": float(\n                                    ohlcv_df[\"volume\"].iloc[-1]\n                                    if not ohlcv_df.empty and \"volume\" in ohlcv_df.columns\n                                    else 0.0\n                                ),\n                                \"trades\": int(\n                                    ohlcv_df[\"trades\"].iloc[-1]\n                                    if not ohlcv_df.empty and \"trades\" in ohlcv_df.columns\n                                    else 0\n                                ),\n                                \"rsi\": float(\n                                    ohlcv_df[\"rsi\"].iloc[-1]\n                                    if not ohlcv_df.empty and \"rsi\" in ohlcv_df.columns\n                                    else 50.0\n                                ),\n                                \"ema\": float(\n                                    ohlcv_df[\"ema\"].iloc[-1]\n                                    if not ohlcv_df.empty and \"ema\" in ohlcv_df.columns\n                                    else current_price\n                                ),\n                                \"volatility\": float(\n                                    ohlcv_df[\"volatility\"].iloc[-1]\n                                    if not ohlcv_df.empty and \"volatility\" in ohlcv_df.columns\n                                    else 0.1\n                                ),\n                                \"macd\": float(\n                                    ohlcv_df[\"macd\"].iloc[-1]\n                                    if not ohlcv_df.empty and \"macd\" in ohlcv_df.columns\n                                    else 0.0\n                                ),\n                                \"macd_signal\": float(\n                                    ohlcv_df[\"macd_signal\"].iloc[-1]\n                                    if not ohlcv_df.empty and \"macd_signal\" in ohlcv_df.columns\n                                    else 0.0\n                                ),\n                                \"bollinger_upper\": float(\n                                    ohlcv_df[\"bollinger_upper\"].iloc[-1]\n                                    if not ohlcv_df.empty and \"bollinger_upper\" in ohlcv_df.columns\n                                    else current_price\n                                ),\n                                \"bollinger_lower\": float(\n                                    ohlcv_df[\"bollinger_lower\"].iloc[-1]\n                                    if not ohlcv_df.empty and \"bollinger_lower\" in ohlcv_df.columns\n                                    else current_price\n                                ),\n                                \"momentum\": float(\n                                    ohlcv_df[\"momentum\"].iloc[-1]\n                                    if not ohlcv_df.empty and \"momentum\" in ohlcv_df.columns\n                                    else 0.0\n                                ),\n                                \"volume_trend\": float(\n                                    ohlcv_df[\"volume_trend\"].iloc[-1]\n                                    if not ohlcv_df.empty and \"volume_trend\" in ohlcv_df.columns\n                                    else 0.0\n                                ),\n                                \"predicted_price\": float(\n                                    ohlcv_df[\"predicted_price\"].iloc[-1]\n                                    if not ohlcv_df.empty and \"predicted_price\" in ohlcv_df.columns\n                                    else current_price\n                                ),\n                                \"grid_level\": int(\n                                    ohlcv_df[\"grid_level\"].iloc[-1]\n                                    if not ohlcv_df.empty and \"grid_level\" in ohlcv_df.columns\n                                    else 0\n                                ),\n                                \"source\": \"gridbot\",\n                            },\n                        ]\n                    )\n                    if closed_orders:\n                        closed_orders_dict = []\n                        for order in closed_orders:\n                            if order and isinstance(order, dict):\n                                closed_orders_dict.append(order_to_dict(order))\n                        orders_to_send.append({\"type\": \"closed_orders\", \"orders\": closed_orders_dict})\n                    for order in bot_state[\"buy_orders\"] + bot_state[\"sell_orders\"]:\n                        if order and isinstance(order, dict) and \"id\" in order:\n                            orders_to_send.append(order_to_dict(order))\n                        else:\n                            logger.warning(f\"Skipping invalid order for WebSocket send: {order}\")\n                    if current_time - last_heartbeat > config.HEARTBEAT_INTERVAL:\n                        orders_to_send.append({\"type\": \"heartbeat\", \"timestamp\": int(current_time * 1000)})\n                        last_heartbeat = current_time\n                    logger.info(\n                        f\"Sending WebSocket messages: predictions={last_sklearn_prediction:.2f}/{last_pytorch_prediction:.2f}/{last_xgb_prediction:.2f}, pl={config.TOTAL_PL:.4f}, orders={len(bot_state['buy_orders']) + len(bot_state['sell_orders'])}, closed_orders={len(closed_orders)}\"\n                    )\n                    websocket_manager.send(json.dumps(orders_to_send))\n                except Exception as websocket_error:\n                    logger.error(f\"Error sending WebSocket updates: {websocket_error}\")\n\n                # 9. Process WebSocket Commands\n                try:\n                    command_processed = websocket_manager.process_command()\n                    if command_processed:\n                        logger.info(\"Processed one WebSocket command, checking grid reset\")\n                    else:\n                        logger.debug(\"No WebSocket commands to process\")\n                except Exception as command_error:\n                    logger.error(f\"Error processing WebSocket command: {command_error}\")\n\n                \"\"\" # 10. Check Grid Stagnation and Rebalance\n                try:\n                    rebalance_start_time = time.time()\n                    logger.info(\"Starting grid stagnation check and rebalancing process\")\n\n                    current_price = get_current_price()\n                    time_since_last_trade = current_time - last_trade_time\n                    volatility = (\n                        ohlcv_df[\"volatility\"].iloc[-1]\n                        if not ohlcv_df.empty and \"volatility\" in ohlcv_df.columns\n                        else config.DEFAULT_VOLATILITY\n                    )\n                    logger.info(f\"Volatility calculated: {volatility:.4f}\")\n\n                    dynamic_stagnation_timeout = 10800  # Temporary: 30 minutes (1800s) for inactivity trigger\n                    total_orders = len(bot_state[\"buy_orders\"]) + len(bot_state[\"sell_orders\"])\n                    grid_base_price = bot_state.get(\"grid_base_price\", current_price)\n                    price_drift = abs(current_price - grid_base_price)\n                    eth_threshold = config.POSITION_SIZE * config.NUM_SELL_GRID_LINES * config.REBALANCE_ETH_THRESHOLD\n                    dynamic_price_drift_threshold = (\n                        config.GRID_SIZE * config.NUM_BUY_GRID_LINES * config.PRICE_DRIFT_THRESHOLD\n                    )\n                    min_reset_interval = max(config.MIN_RESET_INTERVAL, dynamic_stagnation_timeout * 0.5)  # Temporary: 900s (1800 * 0.5)\n\n                    logger.info(\n                        f\"Grid metrics: time_since_last_trade={time_since_last_trade:.0f}s, \"\n                        f\"dynamic_stagnation_timeout={dynamic_stagnation_timeout:.0f}s, \"\n                        f\"total_orders={total_orders}, price_drift={price_drift:.2f}, \"\n                        f\"eth_threshold={eth_threshold:.6f}, price_drift_threshold={dynamic_price_drift_threshold:.2f}\"\n                    )\n\n                    # Initialize last_reset_grid_size and initial_grid_settings if not set\n                    if \"last_reset_grid_size\" not in bot_state:\n                        bot_state[\"last_reset_grid_size\"] = config.GRID_SIZE\n                        logger.info(f\"Initialized last_reset_grid_size: {config.GRID_SIZE:.2f}\")\n                    if \"initial_grid_settings\" not in bot_state or not bot_state[\"initial_grid_settings\"].get(\"grid_base_price\"):\n                        bot_state[\"initial_grid_settings\"] = {\n                            \"grid_base_price\": current_price,\n                            \"grid_size\": config.GRID_SIZE,\n                            \"position_size\": config.POSITION_SIZE,\n                            \"num_buy_grid_lines\": config.NUM_BUY_GRID_LINES,\n                            \"num_sell_grid_lines\": config.NUM_SELL_GRID_LINES,\n                            \"start_time\": current_time,\n                        }\n                        logger.info(\n                            f\"Stored initial grid settings: base_price={current_price:.2f}, \"\n                            f\"grid_size={config.GRID_SIZE:.2f}, position_size={config.POSITION_SIZE:.6f}, \"\n                            f\"buy_lines={config.NUM_BUY_GRID_LINES}, sell_lines={config.NUM_SELL_GRID_LINES}\"\n                        )\n\n                    # Compute feature signals for rebalancing\n                    logger.info(\"Computing feature signals for rebalancing\")\n                    close_prices = ohlcv_df[\"close\"].tail(100)\n                    high_prices = ohlcv_df[\"high\"].tail(100)\n                    low_prices = ohlcv_df[\"low\"].tail(100)\n                    volume = ohlcv_df[\"volume\"].tail(100)\n                    feature_data = ohlcv_df.tail(100)\n\n                    macd, macd_signal = compute_macd(close_prices)\n                    upper_bb, lower_bb = compute_bollinger(close_prices)\n                    momentum = compute_momentum(close_prices)\n                    volume_trend = compute_volume_trend(volume)\n                    rsi = compute_rsi(close_prices)\n                    ema = compute_ema(close_prices)\n                    atr = compute_atr(high_prices, low_prices, close_prices)\n                    vwap = compute_vwap(feature_data)\n\n                    # Normalize feature signals\n                    features = [\n                        (macd.iloc[-1] - macd_signal.iloc[-1]) / (macd.std() + 1e-6),  # MACD histogram\n                        (close_prices.iloc[-1] - lower_bb.iloc[-1]) / (upper_bb.iloc[-1] - lower_bb.iloc[-1] + 1e-6),  # Bollinger position\n                        momentum.iloc[-1] / (momentum.std() + 1e-6),  # Momentum\n                        volume_trend.iloc[-1] / (volume_trend.std() + 1e-6),  # Volume Trend\n                        (rsi.iloc[-1] - 50) / (rsi.std() + 1e-6),  # RSI centered\n                        (close_prices.iloc[-1] - ema.iloc[-1]) / (ema.std() + 1e-6),  # EMA deviation\n                        atr.iloc[-1] / (atr.std() + 1e-6),  # ATR\n                        (close_prices.iloc[-1] - vwap.iloc[-1]) / (vwap.std() + 1e-6),  # VWAP deviation\n                    ]\n                    feature_weights = np.array(features) / (np.abs(features).sum() + 1e-6)\n                    logger.info(f\"Feature weights: {', '.join([f'{f:.4f}' for f in feature_weights])}\")\n\n                    # Determine grid lines for feature-based rebalancing\n                    base_buy_lines = 20\n                    base_sell_lines = 20\n                    feature_buy_lines = max(24, (config.NUM_BUY_GRID_LINES - base_buy_lines) // 8)\n                    feature_sell_lines = max(24, (config.NUM_SELL_GRID_LINES - base_sell_lines) // 8)\n                    num_features = len(features)\n                    lines_per_feature = max(8, (feature_buy_lines // num_features) // 2 * 2)\n\n                    logger.info(\n                        f\"Grid configuration: base_buy={base_buy_lines}, base_sell={base_sell_lines}, \"\n                        f\"feature_buy={feature_buy_lines}, feature_sell={feature_sell_lines}, \"\n                        f\"lines_per_feature={lines_per_feature}\"\n                    )\n\n                    # Stabilization logic based on initial grid\n                    initial_grid = bot_state[\"initial_grid_settings\"]\n                    time_since_start = current_time - initial_grid[\"start_time\"]\n                    price_drift_from_initial = abs(current_price - initial_grid[\"grid_base_price\"])\n                    stabilization_threshold = 350.0  # Temporary: $250 price swing threshold\n\n                    logger.info(\n                        f\"Stabilization metrics: time_since_start={time_since_start:.0f}s, \"\n                        f\"initial_price_drift={price_drift_from_initial:.2f}, stabilization_threshold={stabilization_threshold:.2f}, \"\n                        f\"initial_grid_base_price={initial_grid['grid_base_price']:.2f}\"\n                    )\n\n                    reset_triggers = []\n                    if (\n                        bot_state[\"needs_reset\"]\n                        and (current_time - last_reset_time) > min_reset_interval\n                        and time_since_start > 10800  # Temporary: 3 hour (10800s)\n                    ):\n                        reset_triggers.append(\"needs_reset=True\")\n                    if (\n                        time_since_last_trade > dynamic_stagnation_timeout\n                        and (current_time - last_reset_time) > min_reset_interval\n                        and time_since_start > 10800  # Temporary: 2 hour (7200s)\n                    ):\n                        reset_triggers.append(\n                            f\"stagnation={time_since_last_trade/60:.1f}m > timeout={dynamic_stagnation_timeout/60:.1f}m\"\n                        )\n                    if (\n                        total_orders > config.MAX_NUM_GRID_LINES\n                        and eth_balance >= eth_threshold\n                        and time_since_start > config.TIMESTAMP_VALIDATION\n                    ):\n                        reset_triggers.append(f\"total_orders={total_orders} > {config.MAX_NUM_GRID_LINES}\")\n                    if (\n                        eth_balance < eth_threshold\n                        and time_since_start > config.TIMESTAMP_VALIDATION\n                    ):\n                        reset_triggers.append(f\"eth_balance={eth_balance:.6f} < eth_threshold={eth_threshold:.6f}\")\n                    if (\n                        price_drift_from_initial > stabilization_threshold\n                        and time_since_start > 7200  # Temporary: 2 hour (7200s)\n                        and total_orders > config.MAX_NUM_GRID_LINES\n                    ):\n                        reset_triggers.append(\n                            f\"initial_price_drift={price_drift_from_initial:.2f} > stabilization_threshold={stabilization_threshold:.2f}\"\n                        )\n\n                    if reset_triggers:\n                        logger.info(\n                            f\"Resetting grid: triggers=[{', '.join(reset_triggers)}], \"\n                            f\"stagnation={time_since_last_trade / 60:.1f} minutes, \"\n                            f\"dynamic_timeout={dynamic_stagnation_timeout / 60:.1f} minutes, \"\n                            f\"total_orders={total_orders}, price_drift={price_drift:.2f}, \"\n                            f\"eth_balance={eth_balance:.6f}, eth_threshold={eth_threshold:.6f}\"\n                        )\n\n                        eth_balance, usd_balance = sync_balances(exchange)\n                        logger.info(\n                            f\"Pre-reset balances: ETH={eth_balance:.6f}, USD={usd_balance:.2f}, \"\n                            f\"Locked ETH={bot_state.get('locked_eth', 0.0):.6f}, Locked USD={bot_state.get('locked_usd', 0.0):.2f}\"\n                        )\n\n                        # Cancel existing orders\n                        cancel_start_time = time.time()\n                        all_orders = bot_state[\"buy_orders\"] + bot_state[\"sell_orders\"]\n                        cancelled = []\n                        if all_orders:\n                            logger.info(f\"Attempting to cancel {len(all_orders)} orders\")\n                            for attempt in range(config.CANCEL_ORDER_RETRIES):\n                                try:\n                                    if hasattr(exchange, \"cancel_orders\"):\n                                        cancelled = exchange.cancel_orders(\n                                            [order[\"id\"] for order in all_orders if order and \"id\" in order],\n                                            config.SYMBOL,\n                                        )\n                                        for order_id in cancelled:\n                                            logger.info(f\"Successfully cancelled order {order_id}\")\n                                        break\n                                    else:\n                                        cancelled = cancel_orders(exchange, all_orders, config.SYMBOL)\n                                        for cancelled_order in cancelled:\n                                            logger.info(f\"Successfully cancelled order {cancelled_order['id']}\")\n                                        break\n                                except Exception as cancel_error:\n                                    logger.error(\n                                        f\"Error cancelling orders (attempt {attempt + 1}/{config.CANCEL_ORDER_RETRIES}): {cancel_error}\"\n                                    )\n                                    if attempt + 1 == config.CANCEL_ORDER_RETRIES:\n                                        logger.error(\"Max cancellation retries reached, proceeding with reset\")\n                                    time.sleep(exchange.rateLimit / 1000)\n                        else:\n                            logger.info(\"No active orders to cancel, skipping batch cancellation\")\n                        logger.info(f\"Order cancellation completed in {time.time() - cancel_start_time:.2f} seconds\")\n\n                        bot_state[\"buy_orders\"].clear()\n                        bot_state[\"sell_orders\"].clear()\n                        buy_prices.clear()\n                        logger.info(\"Cleared buy and sell order lists and buy_prices\")\n\n                        eth_balance, usd_balance = sync_balances(exchange)\n                        locked_eth = bot_state.get(\"locked_eth\", 0.0)\n                        locked_usd = bot_state.get(\"locked_usd\", 0.0)\n                        if locked_eth > config.REBALANCE_ETH_THRESHOLD or locked_usd > config.MIN_USD_BALANCE:\n                            logger.warning(\n                                f\"Locked funds remain after cancellation: ETH={locked_eth:.6f}, USD={locked_usd:.2f}\"\n                            )\n                        logger.info(f\"Post-cancellation balances: ETH={eth_balance:.6f}, USD={usd_balance:.2f}\")\n\n                        # Update grid base price\n                        try:\n                            ticker = exchange.fetch_ticker(config.SYMBOL)\n                            grid_base_price = float(ticker[\"last\"])\n                            logger.info(f\"Grid base price updated to {grid_base_price:.2f} during reset\")\n                        except Exception as price_error:\n                            logger.error(f\"Error updating grid base price: {price_error}\")\n                            grid_base_price = current_price\n                            logger.info(f\"Fallback to current_price: {grid_base_price:.2f}\")\n\n                        # Adjust grid parameters\n                        config.GRID_SIZE = max(\n                            config.MIN_GRID_SIZE,\n                            min(config.MAX_GRID_SIZE, config.GRID_SIZE),\n                        )\n                        config.POSITION_SIZE = max(\n                            config.MIN_POSITION_SIZE,\n                            min(config.MAX_POSITION_SIZE, config.POSITION_SIZE),\n                        )\n                        config.NUM_BUY_GRID_LINES = max(\n                            config.MIN_NUM_GRID_LINES,\n                            min(config.MAX_NUM_GRID_LINES, config.NUM_BUY_GRID_LINES),\n                        )\n                        config.NUM_SELL_GRID_LINES = max(\n                            config.MIN_NUM_GRID_LINES,\n                            min(config.MAX_NUM_GRID_LINES, config.NUM_SELL_GRID_LINES),\n                        )\n                        logger.info(\n                            f\"Grid parameters adjusted: GRID_SIZE={config.GRID_SIZE:.2f}, \"\n                            f\"POSITION_SIZE={config.POSITION_SIZE:.6f}, \"\n                            f\"NUM_BUY_GRID_LINES={config.NUM_BUY_GRID_LINES}, \"\n                            f\"NUM_SELL_GRID_LINES={config.NUM_SELL_GRID_LINES}\"\n                        )\n\n                        # Replenish ETH if needed\n                        replenish_start_time = time.time()\n                        success = replenish_eth(\n                            exchange,\n                            config.TARGET_ETH_BUFFER * config.POSITION_SIZE * config.NUM_SELL_GRID_LINES,\n                        )\n                        if success:\n                            eth_balance, usd_balance = sync_balances(exchange)\n                            logger.info(\n                                f\"ETH replenishment successful: ETH={eth_balance:.6f}, USD={usd_balance:.2f}, \"\n                                f\"Target ETH={config.TARGET_ETH_BUFFER * config.POSITION_SIZE * config.NUM_SELL_GRID_LINES:.6f}\"\n                            )\n                        else:\n                            logger.info(\n                                f\"ETH replenishment not needed or failed: ETH={eth_balance:.6f}, Threshold={config.REPLENISH_ETH_THRESHOLD:.6f}\"\n                            )\n                        logger.info(f\"ETH replenishment completed in {time.time() - replenish_start_time:.2f} seconds\")\n\n                        # Check available funds\n                        required_usd = config.POSITION_SIZE * config.NUM_BUY_GRID_LINES * grid_base_price\n                        required_eth = config.POSITION_SIZE * config.NUM_SELL_GRID_LINES\n                        if usd_balance < required_usd * 0.8 or eth_balance < required_eth * 0.8:\n                            logger.warning(\n                                f\"Insufficient funds for full grid: USD={usd_balance:.2f} < {required_usd:.2f}, ETH={eth_balance:.6f} < {required_eth:.6f}\"\n                            )\n                            max_buy_lines = max(\n                                config.MIN_NUM_GRID_LINES,\n                                int(usd_balance / (config.POSITION_SIZE * grid_base_price)),\n                            )\n                            max_sell_lines = max(\n                                config.MIN_NUM_GRID_LINES,\n                                int(eth_balance / config.POSITION_SIZE),\n                            )\n                            config.NUM_BUY_GRID_LINES = min(max_buy_lines, config.NUM_BUY_GRID_LINES)\n                            config.NUM_SELL_GRID_LINES = min(max_sell_lines, config.NUM_SELL_GRID_LINES)\n                            logger.info(\n                                f\"Adjusted grid due to insufficient funds: NUM_BUY_GRID_LINES={config.NUM_BUY_GRID_LINES}, \"\n                                f\"NUM_SELL_GRID_LINES={config.NUM_SELL_GRID_LINES}\"\n                            )\n                            if (\n                                config.NUM_BUY_GRID_LINES < config.MIN_NUM_GRID_LINES\n                                or config.NUM_SELL_GRID_LINES < config.MIN_NUM_GRID_LINES\n                            ):\n                                logger.error(\"Grid lines too low, pausing bot\")\n                            #    bot_state[\"paused\"] = True\n                                return\n\n                        # Place orders\n                        order_placement_start_time = time.time()\n                        orders_to_send = []\n                        buy_order_ids = []\n                        logger.info(\"Placing base buy orders\")\n                        for grid_index in range(base_buy_lines):\n                            price = grid_base_price - (config.GRID_SIZE * (grid_index + 1))\n                            price = float(exchange.price_to_precision(config.SYMBOL, price))\n                            if (grid_base_price - price) <= config.MAX_ORDER_RANGE:\n                                amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                cost = float(amount) * price\n                                if usd_balance >= cost:\n                                    try:\n                                        order = exchange.create_limit_buy_order(\n                                            config.SYMBOL,\n                                            amount,\n                                            price,\n                                            params={\"post_only\": True},\n                                        )\n                                        fetched_order = exchange.fetch_order(order[\"id\"], config.SYMBOL)\n                                        order_price = float(fetched_order[\"price\"]) if fetched_order[\"price\"] else price\n                                        if fetched_order[\"status\"] == \"open\":\n                                            bot_state[\"buy_orders\"].append(fetched_order)\n                                            orders_to_send.append(\n                                                {\n                                                    \"type\": \"order\",\n                                                    \"id\": fetched_order[\"id\"],\n                                                    \"status\": fetched_order[\"status\"],\n                                                    \"side\": fetched_order[\"side\"],\n                                                    \"price\": float(order_price),\n                                                    \"timestamp\": int(time.time() * 1000),\n                                                }\n                                            )\n                                            buy_order_ids.append(fetched_order[\"id\"])\n                                            logger.info(\n                                                f\"Base buy order placed: id={fetched_order['id']}, price={price:.2f}, amount={amount}, cost={cost:.2f}\"\n                                            )\n                                        else:\n                                            logger.warning(\n                                                f\"Base buy order failed: id={fetched_order['id']}, status={fetched_order['status']}, price={price:.2f}\"\n                                            )\n                                    except Exception as buy_order_error:\n                                        logger.error(f\"Failed to place base buy order at {price:.2f}: {buy_order_error}\")\n                                else:\n                                    logger.warning(\n                                        f\"Insufficient USD for base buy order: available={usd_balance:.2f}, required={cost:.2f}, price={price:.2f}\"\n                                    )\n                            time.sleep(exchange.rateLimit / 1000)\n                        logger.info(f\"Placed {len(bot_state['buy_orders'])}/{base_buy_lines} base buy orders\")\n\n                        # Place feature-based buy orders with post-only compliance and cap of 8 per feature\n                        logger.info(\"Placing feature-based buy orders (strategy-driven, capped at 8 per feature, post-only compliant)\")\n                        feature_buy_caps = {\"rsi\": 8, \"bollinger\": 8, \"macd\": 8}\n                        open_feature_buy_counts = {k: 0 for k in feature_buy_caps}\n                        for order in bot_state[\"buy_orders\"]:\n                            feature = order.get(\"feature\")\n                            if feature in open_feature_buy_counts:\n                                open_feature_buy_counts[feature] += 1\n\n                        # Fetch order book for post-only compliance\n                        try:\n                            orderbook = exchange.fetch_order_book(config.SYMBOL)\n                            best_bid = float(orderbook['bids'][0][0]) if orderbook['bids'] else None\n                            best_ask = float(orderbook['asks'][0][0]) if orderbook['asks'] else None\n                            min_tick = getattr(exchange, 'markets', {}).get(config.SYMBOL, {}).get('precision', {}).get('price', 0.01)\n                            min_tick = float(min_tick) if min_tick else 0.01\n                        except Exception as ob_err:\n                            logger.warning(f\"Could not fetch order book for post-only compliance: {ob_err}\")\n                            best_bid = best_ask = None\n                            min_tick = 0.01\n\n                        # RSI\n                        logger.info(f\"[RSI CHECK] Current RSI: {rsi.iloc[-1]:.2f}, Buy if < 30\")\n                        if rsi.iloc[-1] < 30 and open_feature_buy_counts[\"rsi\"] < feature_buy_caps[\"rsi\"] and best_ask:\n                            retry_count = 0\n                            max_retries = 5\n                            while retry_count < max_retries:\n                                try:\n                                    orderbook = exchange.fetch_order_book(config.SYMBOL)\n                                    best_bid = float(orderbook['bids'][0][0]) if orderbook['bids'] else None\n                                    best_ask = float(orderbook['asks'][0][0]) if orderbook['asks'] else None\n                                    if best_bid is not None and best_ask is not None:\n                                        mid_price = (best_bid + best_ask) / 2\n                                        price = float(exchange.price_to_precision(config.SYMBOL, min(mid_price - min_tick, best_ask - min_tick)))\n                                    amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                    cost = float(amount) * price\n                                    if best_ask is not None and price < best_ask and usd_balance >= cost:\n                                        order = exchange.create_limit_buy_order(\n                                            config.SYMBOL, amount, price, params={\"post_only\": True}\n                                        )\n                                        fetched_order = exchange.fetch_order(order[\"id\"], config.SYMBOL)\n                                        if fetched_order[\"status\"] == \"open\":\n                                            fetched_order[\"feature\"] = \"rsi\"\n                                            bot_state[\"buy_orders\"].append(fetched_order)\n                                            orders_to_send.append({\n                                                \"type\": \"order\",\n                                                \"id\": fetched_order[\"id\"],\n                                                \"status\": fetched_order[\"status\"],\n                                                \"side\": fetched_order[\"side\"],\n                                                \"price\": float(fetched_order[\"price\"]),\n                                                \"timestamp\": int(time.time() * 1000),\n                                                \"feature\": \"rsi\"\n                                            })\n                                            buy_order_ids.append(fetched_order[\"id\"])\n                                            logger.info(f\"RSI buy order placed: id={fetched_order['id']}, price={price:.2f}, amount={amount}\")\n                                            break\n                                    else:\n                                        logger.warning(f\"[RSI] Buy price {price} not below best ask {best_ask}, retrying...\")\n                                        time.sleep(5)\n                                except Exception as e:\n                                    if \"INVALID_LIMIT_PRICE_POST_ONLY\" in str(e):\n                                        retry_count += 1\n                                        logger.warning(f\"[RSI] Buy order post-only error, retrying with lower price: {price:.2f} (attempt {retry_count}/{max_retries})\")\n                                        time.sleep(5)\n                                    else:\n                                        logger.error(f\"Failed to place RSI buy order: {e}\")\n                                        break\n                            else:\n                                logger.warning(f\"[RSI] Skipped buy: could not place post-only order after {max_retries} retries. Last attempted price: {price}\")\n\n                        # Bollinger\n                        logger.info(f\"[BOLLINGER CHECK] Current Price: {close_prices.iloc[-1]:.2f}, Lower Band: {lower_bb.iloc[-1]:.2f}, Upper Band: {upper_bb.iloc[-1]:.2f}\")\n                        if close_prices.iloc[-1] <= lower_bb.iloc[-1] and open_feature_buy_counts[\"bollinger\"] < feature_buy_caps[\"bollinger\"] and best_ask:\n                            retry_count = 0\n                            max_retries = 5\n                            while retry_count < max_retries:\n                                try:\n                                    orderbook = exchange.fetch_order_book(config.SYMBOL)\n                                    best_bid = float(orderbook['bids'][0][0]) if orderbook['bids'] else None\n                                    best_ask = float(orderbook['asks'][0][0]) if orderbook['asks'] else None\n                                    if best_bid is not None and best_ask is not None:\n                                        mid_price = (best_bid + best_ask) / 2\n                                        price = float(exchange.price_to_precision(config.SYMBOL, min(mid_price - min_tick, best_ask - min_tick, lower_bb.iloc[-1])))\n                                    amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                    cost = float(amount) * price\n                                    if best_ask is not None and price < best_ask and usd_balance >= cost:\n                                        order = exchange.create_limit_buy_order(\n                                            config.SYMBOL, amount, price, params={\"post_only\": True}\n                                        )\n                                        fetched_order = exchange.fetch_order(order[\"id\"], config.SYMBOL)\n                                        if fetched_order[\"status\"] == \"open\":\n                                            fetched_order[\"feature\"] = \"bollinger\"\n                                            bot_state[\"buy_orders\"].append(fetched_order)\n                                            orders_to_send.append({\n                                                \"type\": \"order\",\n                                                \"id\": fetched_order[\"id\"],\n                                                \"status\": fetched_order[\"status\"],\n                                                \"side\": fetched_order[\"side\"],\n                                                \"price\": float(fetched_order[\"price\"]),\n                                                \"timestamp\": int(time.time() * 1000),\n                                                \"feature\": \"bollinger\"\n                                            })\n                                            buy_order_ids.append(fetched_order[\"id\"])\n                                            logger.info(f\"Bollinger Band buy order placed: id={fetched_order['id']}, price={price:.2f}, amount={amount}\")\n                                            break\n                                    else:\n                                        logger.warning(f\"[BOLLINGER] Buy price {price} not below best ask {best_ask}, retrying...\")\n                                        time.sleep(5)\n                                except Exception as e:\n                                    if \"INVALID_LIMIT_PRICE_POST_ONLY\" in str(e):\n                                        retry_count += 1\n                                        logger.warning(f\"[BOLLINGER] Buy order post-only error, retrying with lower price: {price:.2f} (attempt {retry_count}/{max_retries})\")\n                                        time.sleep(5)\n                                    else:\n                                        logger.error(f\"Failed to place Bollinger Band buy order: {e}\")\n                                        break\n                            else:\n                                logger.warning(f\"[BOLLINGER] Skipped buy: could not place post-only order after {max_retries} retries. Last attempted price: {price}\")\n\n                        # MACD\n                        logger.info(f\"[MACD CHECK] Current MACD: {macd.iloc[-1]:.4f}, Signal: {macd_signal.iloc[-1]:.4f}, Buy if MACD > Signal\")\n                        if macd.iloc[-2] < macd_signal.iloc[-2] and macd.iloc[-1] > macd_signal.iloc[-1] and open_feature_buy_counts[\"macd\"] < feature_buy_caps[\"macd\"] and best_ask:\n                            retry_count = 0\n                            max_retries = 5\n                            while retry_count < max_retries:\n                                try:\n                                    orderbook = exchange.fetch_order_book(config.SYMBOL)\n                                    best_bid = float(orderbook['bids'][0][0]) if orderbook['bids'] else None\n                                    best_ask = float(orderbook['asks'][0][0]) if orderbook['asks'] else None\n                                    if best_bid is not None and best_ask is not None:\n                                        mid_price = (best_bid + best_ask) / 2\n                                        price = float(exchange.price_to_precision(config.SYMBOL, min(mid_price - min_tick, best_ask - min_tick, grid_base_price - config.GRID_SIZE * 0.5)))\n                                    amount = exchange.amount_to_precision(config.SYMBOL, config.POSITION_SIZE)\n                                    cost = float(amount) * price\n                                    if best_ask is not None and price < best_ask and usd_balance >= cost:\n                                        order = exchange.create_limit_buy_order(\n                                            config.SYMBOL, amount, price, params={\"post_only\": True}\n                                        )\n                                        fetched_order = exchange.fetch_order(order[\"id\"], config.SYMBOL)\n                                        if fetched_order[\"status\"] == \"open\":\n                                            fetched_order[\"feature\"] = \"macd\"\n                                            bot_state[\"buy_orders\"].append(fetched_order)\n                                            orders_to_send.append({\n                                                \"type\": \"order\",\n                                                \"id\": fetched_order[\"id\"],\n                                                \"status\": fetched_order[\"status\"],\n                                                \"side\": fetched_order[\"side\"],\n                                                \"price\": float(fetched_order[\"price\"]),\n                                                \"timestamp\": int(time.time() * 1000),\n                                                \"feature\": \"macd\"\n                                            })\n                                            buy_order_ids.append(fetched_order[\"id\"])\n                                            logger.info(f\"MACD buy order placed: id={fetched_order['id']}, price={price:.2f}, amount={amount}\")\n                                            break\n                                    else:\n                                        logger.warning(f\"[MACD] Buy price {price} not below best ask {best_ask}, retrying...\")\n                                        time.sleep(5)\n                                except Exception as e:\n                                    if \"INVALID_LIMIT_PRICE_POST_ONLY\" in str(e):\n                                        retry_count += 1\n                                        logger.warning(f\"[MACD] Buy order post-only error, retrying with lower price: {price:.2f} (attempt {retry_count}/{max_retries})\")\n                                        time.sleep(5)\n                                    else:\n                                        logger.error(f\"Failed to place MACD buy order: {e}\")\n                                        break\n                            else:\n                                logger.warning(f\"[MACD] Skipped buy: could not place post-only order after {max_retries} retries. Last attempted price: {price}\")\n\n                        eth_balance, _ = sync_balances(exchange)\n                        logger.info(f\"ETH balance before sell orders: {eth_balance:.6f}\")\n\n                        sell_order_ids = []\n                        logger.info(\"Placing base sell orders\")\n                        for grid_index in range(base_sell_lines):\n                            price = grid_base_price + (config.GRID_SIZE * (grid_index + 1))\n                            price = float(exchange.price_to_precision(config.SYMBOL, price))\n                            if (price - grid_base_price) <= config.MAX_ORDER_RANGE:\n                                amount = min(\n                                    eth_balance / max(1, base_sell_lines - grid_index),\n                                    config.POSITION_SIZE * config.SELL_SIZE_MULTIPLIER,\n                                )\n                                amount = float(exchange.amount_to_precision(config.SYMBOL, amount))\n                                if eth_balance >= amount and amount >= config.MIN_POSITION_SIZE:\n                                    try:\n                                        order = exchange.create_limit_sell_order(\n                                            config.SYMBOL,\n                                            amount,\n                                            price,\n                                            params={\"post_only\": True},\n                                        )\n                                        fetched_order = exchange.fetch_order(order[\"id\"], config.SYMBOL)\n                                        order_price = float(fetched_order[\"price\"]) if fetched_order[\"price\"] else price\n                                        if fetched_order[\"status\"] == \"open\":\n                                            bot_state[\"sell_orders\"].append(fetched_order)\n                                            orders_to_send.append(\n                                                {\n                                                    \"type\": \"order\",\n                                                    \"id\": fetched_order[\"id\"],\n                                                    \"status\": fetched_order[\"status\"],\n                                                    \"side\": fetched_order[\"side\"],\n                                                    \"price\": float(order_price),\n                                                    \"timestamp\": int(time.time() * 1000),\n                                                }\n                                            )\n                                            sell_order_ids.append(fetched_order[\"id\"])\n                                            eth_balance -= amount\n                                            buy_prices[fetched_order[\"id\"]] = grid_base_price\n                                            logger.info(\n                                                f\"Base sell order placed: id={fetched_order['id']}, price={price:.2f}, amount={amount}\"\n                                            )\n                                        else:\n                                            logger.warning(\n                                                f\"Base sell order failed: id={fetched_order['id']}, status={fetched_order['status']}, price={price:.2f}\"\n                                            )\n                                    except Exception as sell_order_error:\n                                        logger.error(f\"Failed to place base sell order at {price:.2f}: {sell_order_error}\")\n                                else:\n                                    logger.warning(\n                                        f\"Insufficient ETH for base sell order: available={eth_balance:.6f}, required={amount:.6f}, price={price:.2f}\"\n                                    )\n                            time.sleep(exchange.rateLimit / 1000)\n                        logger.info(f\"Placed {len(bot_state['sell_orders'])}/{base_sell_lines} base sell orders\")\n\n                        # Place feature-based sell orders with cap of 8 per feature\n                        logger.info(\"Placing feature-based sell orders (strategy-driven, capped at 2 per feature)\")\n                        feature_sell_caps = {\"rsi\": 8, \"bollinger\": 8, \"macd\": 8}\n                        # Count current open sell orders per feature\n                        open_feature_sell_counts = {k: 0 for k in feature_sell_caps}\n                        for order in bot_state[\"sell_orders\"]:\n                            feature = order.get(\"feature\")\n                            if feature in open_feature_sell_counts:\n                                open_feature_sell_counts[feature] += 1\n\n                        # RSI\n                        logger.info(f\"[RSI CHECK] Current RSI: {rsi.iloc[-1]:.2f}, Sell if > 70\")\n                        if rsi.iloc[-1] > 70 and open_feature_sell_counts[\"rsi\"] < feature_sell_caps[\"rsi\"] and best_bid:\n                            retry_count = 0\n                            max_retries = 5\n                            while retry_count < max_retries:\n                                price = float(exchange.price_to_precision(config.SYMBOL, max(grid_base_price + config.GRID_SIZE, best_bid + min_tick)))\n                                amount = min(\n                                    eth_balance,\n                                    config.POSITION_SIZE * config.SELL_SIZE_MULTIPLIER,\n                                )\n                                amount = float(exchange.amount_to_precision(config.SYMBOL, amount))\n                                if eth_balance >= amount and amount >= config.MIN_POSITION_SIZE and price >= best_bid + min_tick:\n                                    try:\n                                        order = exchange.create_limit_sell_order(\n                                            config.SYMBOL, amount, price, params={\"post_only\": True}\n                                        )\n                                        fetched_order = exchange.fetch_order(order[\"id\"], config.SYMBOL)\n                                        if fetched_order[\"status\"] == \"open\":\n                                            fetched_order[\"feature\"] = \"rsi\"\n                                            bot_state[\"sell_orders\"].append(fetched_order)\n                                            orders_to_send.append({\n                                                \"type\": \"order\",\n                                                \"id\": fetched_order[\"id\"],\n                                                \"status\": fetched_order[\"status\"],\n                                                \"side\": fetched_order[\"side\"],\n                                                \"price\": float(fetched_order[\"price\"]),\n                                                \"timestamp\": int(time.time() * 1000),\n                                                \"feature\": \"rsi\"\n                                            })\n                                            sell_order_ids.append(fetched_order[\"id\"])\n                                            eth_balance -= amount\n                                            buy_prices[fetched_order[\"id\"]] = grid_base_price\n                                            logger.info(f\"RSI sell order placed: id={fetched_order['id']}, price={price:.2f}, amount={amount}\")\n                                            break\n                                    except Exception as e:\n                                        if \"INVALID_LIMIT_PRICE_POST_ONLY\" in str(e):\n                                            retry_count += 1\n                                            price = float(exchange.price_to_precision(config.SYMBOL, price + min_tick))\n                                            logger.warning(f\"[RSI] Sell order post-only error, retrying with higher price: {price:.2f} (attempt {retry_count}/{max_retries})\")\n                                            time.sleep(5)\n                                        else:\n                                            logger.error(f\"Failed to place RSI sell order: {e}\")\n                                            break\n                                else:\n                                    logger.warning(f\"[RSI] Skipped sell: insufficient ETH or below min size or price not above best bid.\")\n                                    time.sleep(5)\n                                    break\n                            else:\n                                logger.warning(f\"[RSI] Skipped sell: could not place post-only order after {max_retries} retries. Last attempted price: {price}\")\n\n                        # Bollinger\n                        logger.info(f\"[BOLLINGER CHECK] Current Price: {close_prices.iloc[-1]:.2f}, Lower Band: {lower_bb.iloc[-1]:.2f}, Upper Band: {upper_bb.iloc[-1]:.2f}\")\n                        if close_prices.iloc[-1] >= upper_bb.iloc[-1] and open_feature_sell_counts[\"bollinger\"] < feature_sell_caps[\"bollinger\"] and best_bid:\n                            retry_count = 0\n                            max_retries = 5\n                            while retry_count < max_retries:\n                                price = float(exchange.price_to_precision(config.SYMBOL, max(upper_bb.iloc[-1], best_bid + min_tick)))\n                                amount = min(\n                                    eth_balance,\n                                    config.POSITION_SIZE * config.SELL_SIZE_MULTIPLIER,\n                                )\n                                amount = float(exchange.amount_to_precision(config.SYMBOL, amount))\n                                if eth_balance >= amount and amount >= config.MIN_POSITION_SIZE and price >= best_bid + min_tick:\n                                    try:\n                                        order = exchange.create_limit_sell_order(\n                                            config.SYMBOL, amount, price, params={\"post_only\": True}\n                                        )\n                                        fetched_order = exchange.fetch_order(order[\"id\"], config.SYMBOL)\n                                        if fetched_order[\"status\"] == \"open\":\n                                            fetched_order[\"feature\"] = \"bollinger\"\n                                            bot_state[\"sell_orders\"].append(fetched_order)\n                                            orders_to_send.append({\n                                                \"type\": \"order\",\n                                                \"id\": fetched_order[\"id\"],\n                                                \"status\": fetched_order[\"status\"],\n                                                \"side\": fetched_order[\"side\"],\n                                                \"price\": float(fetched_order[\"price\"]),\n                                                \"timestamp\": int(time.time() * 1000),\n                                                \"feature\": \"bollinger\"\n                                            })\n                                            sell_order_ids.append(fetched_order[\"id\"])\n                                            eth_balance -= amount\n                                            buy_prices[fetched_order[\"id\"]] = grid_base_price\n                                            logger.info(f\"Bollinger Band sell order placed: id={fetched_order['id']}, price={price:.2f}, amount={amount}\")\n                                            break\n                                    except Exception as e:\n                                        if \"INVALID_LIMIT_PRICE_POST_ONLY\" in str(e):\n                                            retry_count += 1\n                                            price = float(exchange.price_to_precision(config.SYMBOL, price + min_tick))\n                                            logger.warning(f\"[BOLLINGER] Sell order post-only error, retrying with higher price: {price:.2f} (attempt {retry_count}/{max_retries})\")\n                                            time.sleep(5)\n                                        else:\n                                            logger.error(f\"Failed to place Bollinger Band sell order: {e}\")\n                                            break\n                                else:\n                                    logger.warning(f\"[BOLLINGER] Skipped sell: insufficient ETH or below min size or price not above best bid.\")\n                                    time.sleep(5)\n                                    break\n                            else:\n                                logger.warning(f\"[BOLLINGER] Skipped sell: could not place post-only order after {max_retries} retries. Last attempted price: {price}\")\n\n                        # MACD\n                        logger.info(f\"[MACD CHECK] Current MACD: {macd.iloc[-1]:.4f}, Signal: {macd_signal.iloc[-1]:.4f}, Sell if MACD < Signal\")\n                        if macd.iloc[-2] > macd_signal.iloc[-2] and macd.iloc[-1] < macd_signal.iloc[-1] and open_feature_sell_counts[\"macd\"] < feature_sell_caps[\"macd\"] and best_bid:\n                            retry_count = 0\n                            max_retries = 5\n                            while retry_count < max_retries:\n                                price = float(exchange.price_to_precision(config.SYMBOL, max(grid_base_price + config.GRID_SIZE * 0.5, best_bid + min_tick)))\n                                amount = min(\n                                    eth_balance,\n                                    config.POSITION_SIZE * config.SELL_SIZE_MULTIPLIER,\n                                )\n                                amount = float(exchange.amount_to_precision(config.SYMBOL, amount))\n                                if eth_balance >= amount and amount >= config.MIN_POSITION_SIZE and price >= best_bid + min_tick:\n                                    try:\n                                        order = exchange.create_limit_sell_order(\n                                            config.SYMBOL, amount, price, params={\"post_only\": True}\n                                        )\n                                        fetched_order = exchange.fetch_order(order[\"id\"], config.SYMBOL)\n                                        if fetched_order[\"status\"] == \"open\":\n                                            fetched_order[\"feature\"] = \"macd\"\n                                            bot_state[\"sell_orders\"].append(fetched_order)\n                                            orders_to_send.append({\n                                                \"type\": \"order\",\n                                                \"id\": fetched_order[\"id\"],\n                                                \"status\": fetched_order[\"status\"],\n                                                \"side\": fetched_order[\"side\"],\n                                                \"price\": float(fetched_order[\"price\"]),\n                                                \"timestamp\": int(time.time() * 1000),\n                                                \"feature\": \"macd\"\n                                            })\n                                            sell_order_ids.append(fetched_order[\"id\"])\n                                            eth_balance -= amount\n                                            buy_prices[fetched_order[\"id\"]] = grid_base_price\n                                            logger.info(f\"MACD sell order placed: id={fetched_order['id']}, price={price:.2f}, amount={amount}\")\n                                            break\n                                    except Exception as e:\n                                        if \"INVALID_LIMIT_PRICE_POST_ONLY\" in str(e):\n                                            retry_count += 1\n                                            price = float(exchange.price_to_precision(config.SYMBOL, price + min_tick))\n                                            logger.warning(f\"[MACD] Sell order post-only error, retrying with higher price: {price:.2f} (attempt {retry_count}/{max_retries})\")\n                                            time.sleep(5)\n                                        else:\n                                            logger.error(f\"Failed to place MACD sell order: {e}\")\n                                            break\n                                else:\n                                    logger.warning(f\"[MACD] Skipped sell: insufficient ETH or below min size or price not above best bid.\")\n                                    time.sleep(5)\n                                    break\n                            else:\n                                logger.warning(f\"[MACD] Skipped sell: could not place post-only order after {max_retries} retries. Last attempted price: {price}\")\n\n                        logger.info(f\"Order placement completed in {time.time() - order_placement_start_time:.2f} seconds\")\n\n                        # Send orders to WebSocket\n                        try:\n                            websocket_manager.send(json.dumps(orders_to_send))\n                            logger.info(f\"Sent {len(orders_to_send)} orders to WebSocket during rebalance\")\n                            logger.info(\n                                f\"Grid rebalanced: {len(bot_state['buy_orders'])} buy orders, {len(bot_state['sell_orders'])} sell orders\"\n                            )\n                            logger.info(\n                                f\"Post-reset balances: ETH={eth_balance:.6f}, USD={usd_balance:.2f}, \"\n                                f\"Active buy orders={len(buy_order_ids)}, Active sell orders={len(sell_order_ids)}\"\n                            )\n                        except Exception as websocket_error:\n                            logger.error(f\"Error sending WebSocket orders during rebalance: {websocket_error}\")\n\n                        expected_orders = config.NUM_BUY_GRID_LINES + config.NUM_SELL_GRID_LINES\n                        actual_orders = len(bot_state[\"buy_orders\"]) + len(bot_state[\"sell_orders\"])\n                        if actual_orders < expected_orders * 0.8:\n                            logger.error(\n                                f\"Incomplete rebalance: {actual_orders}/{expected_orders} orders placed, pausing bot\"\n                            )\n                        #    bot_state[\"paused\"] = True\n                            return\n\n                        # Update initial_grid_settings post-reset\n                        bot_state[\"initial_grid_settings\"] = {\n                            \"grid_base_price\": current_price,\n                            \"grid_size\": config.GRID_SIZE,\n                            \"position_size\": config.POSITION_SIZE,\n                            \"num_buy_grid_lines\": config.NUM_BUY_GRID_LINES,\n                            \"num_sell_grid_lines\": config.NUM_SELL_GRID_LINES,\n                            \"start_time\": current_time,\n                        }\n                        logger.info(\n                            f\"Updated grid settings: base_price={current_price:.2f}, \"\n                            f\"grid_size={config.GRID_SIZE:.2f}, position_size={config.POSITION_SIZE:.6f}, \"\n                            f\"buy_lines={config.NUM_BUY_GRID_LINES}, sell_lines={config.NUM_SELL_GRID_LINES}\"\n                        )\n\n                        bot_state[\"needs_reset\"] = False\n                        last_reset_time = current_time\n                        last_trade_time = current_time\n                        bot_state[\"last_reset_grid_size\"] = config.GRID_SIZE\n                        logger.info(\n                            f\"Rebalance completed: last_reset_time={last_reset_time:.0f}, \"\n                            f\"last_reset_grid_size={bot_state['last_reset_grid_size']:.2f}\"\n                        )\n                    else:\n                        logger.info(\"No reset needed at this time\")\n\n                    logger.info(f\"Total rebalancing time: {time.time() - rebalance_start_time:.2f} seconds\")\n                except Exception as rebalance_error:\n                    logger.error(f\"Error checking grid stagnation: {rebalance_error}\") \"\"\"\n\n                # 11. Update Bot State\n                bot_state.update(\n                    {\n                        \"current_price\": current_price,\n                        \"total_pl\": bot_state[\"total_pl\"],\n                        \"last_sklearn_prediction\": last_sklearn_prediction,\n                        \"last_pytorch_prediction\": last_pytorch_prediction,\n                        \"last_xgb_prediction\": last_xgb_prediction,\n                        \"eth_balance\": eth_balance,\n                        \"usd_balance\": usd_balance,\n                    }\n                )\n\n                # Clean up trade_counts with type conversion\n                cutoff = pd.Timestamp.now(tz=\"UTC\") - pd.Timedelta(minutes=lookback)\n                trade_counts = {\n                    k: v for k, v in trade_counts.items()\n                    if pd.to_datetime(k, errors='coerce', utc=True) > cutoff and not pd.isna(pd.to_datetime(k, errors='coerce', utc=True))\n                }\n\n                logger.info(\n                    f\"Iteration {iteration_count}: Price={bot_state['current_price']:.2f}, \"\n                    f\"Orders={len(bot_state['buy_orders'])} buy/{len(bot_state['sell_orders'])} sell, \"\n                    f\"Feature Cache={len(bot_state['feature_cache'])} rows, \"\n                    f\"Last Retrain={datetime.fromtimestamp(bot_state['last_retrain_time']).strftime('%Y-%m-%d %H:%M:%S') if bot_state['last_retrain_time'] else 'Never'}\"\n                )\n\n                iteration_count += 1\n                time.sleep(config.CHECK_ORDER_FREQUENCY)\n\n            except Exception as loop_error:\n                logger.error(f\"Main loop error: {loop_error}\", exc_info=True)\n                time.sleep(config.CHECK_ORDER_FREQUENCY)\n\n    except Exception as main_error:\n        logger.error(f\"Fatal error: {main_error}\", exc_info=True)\n        shutdown_event.set()\n        raise\n    finally:\n        logger.info(\"Shutting down\")\n        cancel_orders(exchange, bot_state[\"buy_orders\"] + bot_state[\"sell_orders\"], config.SYMBOL)\n        websocket_manager.stop()\n        coinbase_thread.join()",
        "performance_issues": [
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "Nested loops detected - consider optimization",
          "Nested loops detected - consider optimization",
          "Nested loops detected - consider optimization",
          "Nested loops detected - consider optimization",
          "String concatenation in loop - consider join()",
          "String concatenation in loop - consider join()",
          "String concatenation in loop - consider join()",
          "String concatenation in loop - consider join()",
          "String concatenation in loop - consider join()",
          "String concatenation in loop - consider join()",
          "String concatenation in loop - consider join()",
          "String concatenation in loop - consider join()",
          "String concatenation in loop - consider join()",
          "String concatenation in loop - consider join()",
          "String concatenation in loop - consider join()",
          "String concatenation in loop - consider join()",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "String concatenation in loop - consider join()",
          "String concatenation in loop - consider join()",
          "Complex comprehension - consider breaking down",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "Complex comprehension - consider breaking down",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "List operations in loop - consider list comprehension",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "Complex comprehension - consider breaking down",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "Complex comprehension - consider breaking down",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "Long function - consider refactoring"
        ],
        "optimization_priority": 7,
        "estimated_impact": "medium"
      },
      "success": false,
      "original_performance": {
        "execution_time": 0.0,
        "memory_usage": null,
        "cpu_usage": null,
        "function_calls": 0,
        "profile_data": null
      },
      "optimized_performance": null,
      "improvement_ratio": null,
      "applied": false,
      "error": "LLM optimization failed: 'QwenAgentInterface' object has no attribute 'generate_targeted_optimization'"
    },
    {
      "candidate": {
        "function_name": "enforce_order_spacing",
        "file_path": "C:\\Users\\805Sk\\GridBotWorkspace\\automated_debugging_strategy\\GridbotBackup.py",
        "line_start": 4394,
        "line_end": 4470,
        "code_snippet": "def enforce_order_spacing(bot_state, min_spacing=2.0, feature_name=None, recent_trade_data=None):\n    \"\"\"\n    Enforce spacing only for feature orders (not base), grouped by feature, for each side. Base orders are left untouched.\n    Each feature's orders are spaced independently.\n    \"\"\"\n    try:\n        logger.info(\"[ORDER SPACING] --- Begin Spacing Enforcement ---\")\n        for side in [\"buy_orders\", \"sell_orders\"]:\n            orders = bot_state.get(side, [])\n            logger.info(f\"[ORDER SPACING] Checking {side}: {len(orders)} open orders.\")\n            # Group feature orders by feature (exclude base orders)\n            feature_orders = {}\n            for o in orders:\n                feature = o.get(\"feature\")\n                if feature and feature != \"base\":\n                    feature_orders.setdefault(feature, []).append(o)\n            logger.info(f\"[ORDER SPACING] {side}: {sum(len(v) for v in feature_orders.values())} feature orders across {len(feature_orders)} features.\")\n            for feature, orders_list in feature_orders.items():\n                logger.info(f\"[ORDER SPACING] {side} feature '{feature}': {len(orders_list)} orders before spacing check.\")\n                if len(orders_list) < 2:\n                    logger.info(f\"[ORDER SPACING] {side} feature '{feature}': Only one order, skipping spacing check.\")\n                    continue\n                # --- Corrected sorting and spacing logic ---\n                if side == \"buy_orders\":\n                    # For buys: sort descending (highest first), space downward\n                    sorted_orders = sorted(orders_list, key=lambda o: o.get(\"price\", 0), reverse=True)\n                else:\n                    # For sells: sort ascending (lowest first), space upward\n                    sorted_orders = sorted(orders_list, key=lambda o: o.get(\"price\", 0))\n                adjusted = False\n                prev_price = None\n                # Dynamic spacing: use feature value if provided, else min_spacing\n                dynamic_spacing = min_spacing\n                if feature_name and recent_trade_data is not None and feature_name in recent_trade_data.columns:\n                    try:\n                        dynamic_spacing = float(recent_trade_data[feature_name].iloc[-1])\n                        if not (0.01 <= dynamic_spacing <= 100):\n                            dynamic_spacing = min_spacing\n                    except Exception:\n                        dynamic_spacing = min_spacing\n                logger.info(f\"[ORDER SPACING] {side} feature '{feature}': Using spacing {dynamic_spacing:.2f}.\")\n                for idx, order in enumerate(sorted_orders):\n                    price = order.get(\"price\", 0)\n                    if prev_price is not None:\n                        if side == \"buy_orders\":\n                            # Each next buy should be at least dynamic_spacing LOWER than previous\n                            gap = prev_price - price\n                            logger.info(f\"[ORDER SPACING] Buy order id={order.get('id')}: price={price:.2f}, prev_price={prev_price:.2f}, gap={gap:.2f}\")\n                            if gap < dynamic_spacing:\n                                new_price = prev_price - dynamic_spacing\n                                logger.info(f\"[ORDER SPACING] Feature '{feature}' buy order id={order.get('id')} too close to previous (${price:.2f} vs ${prev_price:.2f}), adjusting to ${new_price:.2f} (spacing={dynamic_spacing:.2f})\")\n                                cancel_and_replace_order(order, new_price, side, bot_state)\n                                adjusted = True\n                                prev_price = new_price\n                            else:\n                                prev_price = price\n                        else:\n                            # Each next sell should be at least dynamic_spacing HIGHER than previous\n                            gap = price - prev_price\n                            logger.info(f\"[ORDER SPACING] Sell order id={order.get('id')}: price={price:.2f}, prev_price={prev_price:.2f}, gap={gap:.2f}\")\n                            if gap < dynamic_spacing:\n                                new_price = prev_price + dynamic_spacing\n                                logger.info(f\"[ORDER SPACING] Feature '{feature}' sell order id={order.get('id')} too close to previous (${price:.2f} vs ${prev_price:.2f}), adjusting to ${new_price:.2f} (spacing={dynamic_spacing:.2f})\")\n                                cancel_and_replace_order(order, new_price, side, bot_state)\n                                adjusted = True\n                                prev_price = new_price\n                            else:\n                                prev_price = price\n                    else:\n                        prev_price = price\n                if adjusted:\n                    logger.info(f\"[ORDER SPACING] {side} feature '{feature}' orders adjusted for spacing {dynamic_spacing:.2f}.\")\n                else:\n                    logger.info(f\"[ORDER SPACING] {side} feature '{feature}' orders already properly spaced.\")\n        logger.info(\"[ORDER SPACING] --- End Spacing Enforcement ---\")\n    except Exception as e:\n        logger.error(f\"[ORDER SPACING] Error enforcing order spacing: {e}\")",
        "performance_issues": [
          "Nested loops detected - consider optimization",
          "Nested loops detected - consider optimization",
          "Nested loops detected - consider optimization",
          "Nested loops detected - consider optimization",
          "List operations in loop - consider list comprehension",
          "Long function - consider refactoring"
        ],
        "optimization_priority": 6,
        "estimated_impact": "medium"
      },
      "success": false,
      "original_performance": {
        "execution_time": 0.0,
        "memory_usage": null,
        "cpu_usage": null,
        "function_calls": 0,
        "profile_data": null
      },
      "optimized_performance": null,
      "improvement_ratio": null,
      "applied": false,
      "error": "LLM optimization failed: 'QwenAgentInterface' object has no attribute 'generate_optimization'"
    },
    {
      "candidate": {
        "function_name": "online_update_sklearn",
        "file_path": "C:\\Users\\805Sk\\GridBotWorkspace\\automated_debugging_strategy\\GridbotBackup.py",
        "line_start": 1219,
        "line_end": 1272,
        "code_snippet": "def online_update_sklearn(model, scaler, X, y, lookback=80):\n    \"\"\"\n    Update SGDRegressor model online.\n    Args:\n        model: SGDRegressor model.\n        scaler (StandardScaler): Scaler for features.\n        X (pd.DataFrame): Input features (lookback periods).\n        y (np.ndarray): Target close prices.\n        lookback (int): Number of lookback periods (default: 80).\n    Returns:\n        SGDRegressor: Updated model.\n    \"\"\"\n    try:\n        features = [\n            \"close\", \"volume\", \"trades\", \"rsi\", \"ema\", \"volatility\", \"macd\", \"macd_signal\",\n            \"bollinger_upper\", \"bollinger_lower\", \"momentum\", \"volume_trend\", \"atr\", \"vwap\",\n            \"price_spread\", \"returns\", \"volume_change\", \"trade_intensity\"\n        ]\n        # Validate inputs\n        if not isinstance(X, pd.DataFrame):\n            logger.error(\"X must be a pandas DataFrame\")\n            return model\n        if len(X) < lookback:\n            logger.error(f\"Insufficient samples: X has {len(X)} rows, need {lookback}\")\n            return model\n        if not all(f in X.columns for f in features):\n            logger.error(f\"Missing features in X: {[f for f in features if f not in X.columns]}\")\n            return model\n\n        # Prepare sequence features for SGD\n        X_seq = []\n        for i in range(len(X) - lookback + 1):\n            X_seq.append(X[features].iloc[i:i + lookback].values.flatten())\n        X_seq = np.array(X_seq)\n        y_seq = y[-len(X_seq):]\n\n        if len(X_seq) == 0 or len(y_seq) == 0:\n            logger.error(\"Empty sequence data for SGD update\")\n            return model\n        if len(X_seq) != len(y_seq):\n            logger.error(f\"Sample mismatch: X has {len(X_seq)} samples, y has {len(y_seq)} samples\")\n            return model\n        if X_seq.shape[1] != lookback * len(features):\n            logger.error(f\"Feature mismatch: expected {lookback * len(features)} features, got {X_seq.shape[1]}\")\n            return model\n\n        # Scale features\n        X_scaled = scaler.transform(X_seq)\n        model.partial_fit(X_scaled, y_seq.ravel())\n        logger.info(\"SGDRegressor updated online\")\n        return model\n    except Exception as e:\n        logger.error(f\"Sklearn online update failed: {e}\")\n        return model",
        "performance_issues": [
          "List operations in loop - consider list comprehension",
          "Complex comprehension - consider breaking down",
          "Long function - consider refactoring"
        ],
        "optimization_priority": 5,
        "estimated_impact": "medium"
      },
      "success": false,
      "original_performance": {
        "execution_time": 0.0,
        "memory_usage": null,
        "cpu_usage": null,
        "function_calls": 0,
        "profile_data": null
      },
      "optimized_performance": null,
      "improvement_ratio": null,
      "applied": false,
      "error": "LLM optimization failed: 'QwenAgentInterface' object has no attribute 'generate_optimization'"
    },
    {
      "candidate": {
        "function_name": "fetch_trade_counts",
        "file_path": "C:\\Users\\805Sk\\GridBotWorkspace\\automated_debugging_strategy\\GridbotBackup.py",
        "line_start": 1586,
        "line_end": 1872,
        "code_snippet": "def fetch_trade_counts(exchange, symbol, historical_data=None, lookback_minutes=config.MIN_TRADE_MINUTES):\n    try:\n        logger.debug(f\"Fetching trade data for {symbol} over {lookback_minutes} minutes\")\n        until = int(time.time() * 1000)\n        since = until - (lookback_minutes * 60 * 1000)\n        all_trades = []\n        limit = 1000\n        target_minutes = config.MIN_TRADE_MINUTES\n        max_lookback = config.MAX_TRADE_LOOKBACK\n        max_trades = config.MAX_TRADES\n        max_retries = 7\n        retry_count = 0\n        minutes_covered = 0\n\n        while len(all_trades) < max_trades and lookback_minutes <= max_lookback and retry_count < max_retries:\n            trades = exchange.fetch_trades(symbol, since=since, limit=limit, params={\"until\": until})\n            logger.debug(\n                f\"Fetched {len(trades)} trades from {pd.Timestamp(since, unit='ms', tz='UTC')} to {pd.Timestamp(until, unit='ms', tz='UTC')}\"\n            )\n            if not trades:\n                logger.warning(\"No trades returned, increasing lookback\")\n                lookback_minutes = min(lookback_minutes * 1.5, max_lookback)\n                since = until - (lookback_minutes * 60 * 1000)\n                retry_count += 1\n                time.sleep(exchange.rateLimit / 1000)\n                continue\n            all_trades.extend(trades)\n            earliest_timestamp = min(t[\"timestamp\"] for t in trades)\n            until = earliest_timestamp - 1000\n            minutes_covered = (time.time() * 1000 - earliest_timestamp) / (60 * 1000)\n            logger.debug(f\"Minutes covered: {minutes_covered:.1f}\")\n            if minutes_covered >= target_minutes:\n                logger.info(f\"Reached target minutes: {minutes_covered:.1f}\")\n                break\n            if until <= since:\n                logger.info(\"Reached start of requested period\")\n                break\n            time.sleep(exchange.rateLimit / 1000)\n\n        if minutes_covered < target_minutes and lookback_minutes < max_lookback and retry_count < max_retries:\n            logger.info(f\"Minutes covered {minutes_covered:.1f} < {target_minutes}, retrying with extended lookback\")\n            lookback_minutes = min(lookback_minutes * 1.5, max_lookback)\n            since = until - (lookback_minutes * 60 * 1000)\n            additional_trades = exchange.fetch_trades(symbol, since=since, limit=limit, params={\"until\": until})\n            if additional_trades:\n                all_trades.extend(additional_trades)\n                logger.debug(f\"Added {len(additional_trades)} additional trades\")\n                earliest_timestamp = min(t[\"timestamp\"] for t in all_trades)\n                minutes_covered = (time.time() * 1000 - earliest_timestamp) / (60 * 1000)\n\n        logger.info(f\"Total trades fetched: {len(all_trades)} over {lookback_minutes} minutes\")\n        if len(all_trades) < config.MIN_TRADES:\n            logger.warning(f\"Fetched only {len(all_trades)} trades, may not cover enough time\")\n            with trade_lock:\n                if trades_cache:\n                    logger.info(\"Using WebSocket cache to supplement trades\")\n                    cache_trades = [\n                        {\n                            \"timestamp\": t[\"timestamp\"],\n                            \"price\": t[\"price\"],\n                            \"amount\": t[\"size\"],\n                        }\n                        for t in trades_cache\n                        if since <= t[\"timestamp\"] <= until\n                    ]\n                    all_trades.extend(cache_trades)\n                    logger.debug(f\"Added {len(cache_trades)} cached trades\")\n\n        # Validate trade data structure and log sample\n        required_keys = [\"timestamp\", \"price\", \"amount\"]\n        sample_trade = all_trades[0] if all_trades else {}\n        missing_keys = [key for key in required_keys if key not in sample_trade]\n        if missing_keys:\n            logger.error(f\"Trade data missing required keys: {missing_keys}, sample trade: {sample_trade}\")\n            return None\n        logger.debug(f\"Sample trades: {all_trades[:5]}\")\n\n        # Log raw timestamp range\n        raw_timestamps = [t[\"timestamp\"] for t in all_trades]\n        logger.debug(\n            f\"Raw timestamp range: min={min(raw_timestamps, default='N/A')}, max={max(raw_timestamps, default='N/A')}, sample={raw_timestamps[:5]}\"\n        )\n\n        df = pd.DataFrame(all_trades, columns=[\"timestamp\", \"price\", \"amount\"])\n        if df.empty:\n            logger.error(\"No trade data after processing\")\n            return None\n\n        # Log DataFrame state before timestamp conversion\n        logger.debug(\n            f\"Trade DataFrame before timestamp conversion: columns={df.columns.tolist()}, first_timestamp={df['timestamp'].iloc[0] if 'timestamp' in df and not df.empty else 'N/A'}\"\n        )\n\n        if \"timestamp\" not in df:\n            logger.error(\"Timestamp column missing in trade DataFrame\")\n            return None\n\n        # Parse timestamps\n        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\", errors=\"coerce\", utc=True)\n        if df[\"timestamp\"].isna().all():\n            logger.warning(\"Millisecond timestamp parsing failed, trying seconds\")\n            # Fallback to inferring format if unit-based parsing fails\n            df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\", utc=True)\n        if df[\"timestamp\"].isna().any():\n            logger.warning(\n                f\"Found {df['timestamp'].isna().sum()} invalid timestamps in trade data, filling with current time\"\n            )\n            df[\"timestamp\"] = df[\"timestamp\"].fillna(pd.Timestamp.now(tz=\"UTC\"))\n\n        # Validate timestamp recency\n        current_time = pd.Timestamp.now(tz=\"UTC\")\n        if df[\"timestamp\"].max() < current_time - pd.Timedelta(minutes=lookback_minutes):\n            logger.warning(f\"Timestamps are older than expected, max timestamp: {df['timestamp'].max()}\")\n\n        # Log parsed timestamp range\n        logger.debug(\n            f\"Parsed timestamp range: min={df['timestamp'].min()}, max={df['timestamp'].max()}, sample={df['timestamp'].head().tolist()}\"\n        )\n\n        df[\"minute\"] = df[\"timestamp\"].dt.floor(\"1min\")\n        trade_counts = df.groupby(\"minute\").size().reset_index(name=\"trades\")\n        trade_counts.rename(columns={\"minute\": \"timestamp\"}, inplace=True)\n        price_agg = df.groupby(\"minute\").agg({\"price\": [\"last\", \"max\", \"min\"], \"amount\": \"sum\"}).reset_index()\n        price_agg.columns = [\"timestamp\", \"close\", \"high\", \"low\", \"volume\"]\n        trade_counts = trade_counts.merge(price_agg, on=\"timestamp\", how=\"left\")\n        trade_counts[\"close\"] = trade_counts[\"close\"].ffill()\n        trade_counts[\"volume\"] = trade_counts[\"volume\"].ffill()\n        trade_counts[\"high\"] = trade_counts[\"high\"].ffill()\n        trade_counts[\"low\"] = trade_counts[\"low\"].ffill()\n        logger.debug(\n            f\"Aggregated trade data: {len(trade_counts)} minutes, total volume={trade_counts['volume'].sum():.2f}, columns={trade_counts.columns.tolist()}\"\n        )\n\n        if trade_counts[\"volume\"].sum() == 0 and historical_data is not None and not historical_data.empty:\n            last_volume = historical_data[\"volume\"].tail(1).iloc[0]\n            trade_counts[\"volume\"] = last_volume\n            logger.warning(f\"No volume in fetched trades, using historical volume: {last_volume:.2f}\")\n        elif trade_counts[\"volume\"].sum() == 0:\n            logger.warning(\"No volume in fetched trades and no historical data available, setting volume to 0.0\")\n\n        # Compute features individually with error handling\n        try:\n            logger.debug(\"Computing rsi\")\n            trade_counts[\"rsi\"] = compute_rsi(trade_counts[\"close\"], periods=config.RSI_PERIOD)\n        except Exception as e:\n            logger.error(f\"Error computing rsi: {e}\")\n            trade_counts[\"rsi\"] = config.LOG_DEFAULT_RSI\n        try:\n            logger.debug(\"Computing ema\")\n            trade_counts[\"ema\"] = compute_ema(trade_counts[\"close\"], span=config.EMA_SPAN)\n        except Exception as e:\n            logger.error(f\"Error computing ema: {e}\")\n            trade_counts[\"ema\"] = trade_counts[\"close\"].mean()\n        try:\n            logger.debug(\"Computing volatility\")\n            trade_counts[\"volatility\"] = (\n                trade_counts[\"close\"].pct_change().rolling(config.VOLATILITY_WINDOW, min_periods=1).std() * 100\n            )\n            trade_counts[\"volatility\"] = trade_counts[\"volatility\"].fillna(config.LOG_DEFAULT_VOLATILITY)\n        except Exception as e:\n            logger.error(f\"Error computing volatility: {e}\")\n            trade_counts[\"volatility\"] = config.LOG_DEFAULT_VOLATILITY\n        try:\n            logger.debug(\"Computing macd\")\n            trade_counts[\"macd\"], trade_counts[\"macd_signal\"] = compute_macd(\n                trade_counts[\"close\"],\n                fast=config.MACD_FAST,\n                slow=config.MACD_SLOW,\n                signal=config.MACD_SIGNAL,\n            )\n        except Exception as e:\n            logger.error(f\"Error computing macd: {e}\")\n            trade_counts[\"macd\"] = config.LOG_DEFAULT_MACD\n            trade_counts[\"macd_signal\"] = config.LOG_DEFAULT_MACD_SIGNAL\n        try:\n            logger.debug(\"Computing bollinger bands\")\n            trade_counts[\"bollinger_upper\"], trade_counts[\"bollinger_lower\"] = compute_bollinger(\n                trade_counts[\"close\"],\n                window=config.BOLLINGER_WINDOW,\n                num_std=config.BOLLINGER_NUM_STD,\n            )\n            trade_counts[\"bollinger_upper\"] = trade_counts[\"bollinger_upper\"].fillna(trade_counts[\"close\"].mean())\n            trade_counts[\"bollinger_lower\"] = trade_counts[\"bollinger_lower\"].fillna(trade_counts[\"close\"].mean())\n        except Exception as e:\n            logger.error(f\"Error computing bollinger bands: {e}\")\n            trade_counts[\"bollinger_upper\"] = trade_counts[\"close\"].mean()\n            trade_counts[\"bollinger_lower\"] = trade_counts[\"close\"].mean()\n        try:\n            logger.debug(\"Computing momentum\")\n            trade_counts[\"momentum\"] = compute_momentum(trade_counts[\"close\"], periods=config.MOMENTUM_PERIOD)\n        except Exception as e:\n            logger.error(f\"Error computing momentum: {e}\")\n            trade_counts[\"momentum\"] = config.LOG_DEFAULT_MOMENTUM\n        try:\n            logger.debug(\"Computing volume trend\")\n            trade_counts[\"volume_trend\"] = compute_volume_trend(trade_counts[\"volume\"])\n        except Exception as e:\n            logger.error(f\"Error computing volume trend: {e}\")\n            trade_counts[\"volume_trend\"] = config.LOG_DEFAULT_VOLUME_TREND\n        try:\n            logger.debug(\"Computing atr\")\n            trade_counts[\"atr\"] = compute_atr(\n                trade_counts[\"high\"],\n                trade_counts[\"low\"],\n                trade_counts[\"close\"],\n                periods=config.ATR_PERIOD,\n            )\n        except Exception as e:\n            logger.error(f\"Error computing atr: {e}\")\n            trade_counts[\"atr\"] = trade_counts[\"close\"].mean() * 0.01\n        try:\n            logger.debug(\"Computing vwap\")\n            trade_counts[\"vwap\"] = compute_vwap(trade_counts, period=config.VWAP_PERIOD)\n        except Exception as e:\n            logger.error(f\"Error computing vwap: {e}\")\n            trade_counts[\"vwap\"] = trade_counts[\"close\"].mean()\n        try:\n            logger.debug(\"Computing predicted price\")\n            trade_counts[\"predicted_price\"] = trade_counts[\"close\"].shift(-1).fillna(trade_counts[\"close\"].mean())\n        except Exception as e:\n            logger.error(f\"Error computing predicted price: {e}\")\n            trade_counts[\"predicted_price\"] = trade_counts[\"close\"].mean()\n        trade_counts[\"grid_level\"] = 0\n\n        # Log trade_counts state before final assignment\n        logger.debug(f\"trade_counts after feature computation: {trade_counts.head().to_dict()}\")\n\n        result = trade_counts[\n            [\n                \"timestamp\",\n                \"close\",\n                \"volume\",\n                \"trades\",\n                \"rsi\",\n                \"ema\",\n                \"volatility\",\n                \"macd\",\n                \"macd_signal\",\n                \"bollinger_upper\",\n                \"bollinger_lower\",\n                \"momentum\",\n                \"volume_trend\",\n                \"atr\",\n                \"vwap\",\n                \"predicted_price\",\n                \"grid_level\",\n                \"high\",\n                \"low\",\n            ]\n        ].copy()\n        result = (\n            result.bfill()\n            .ffill()\n            .fillna(\n                {\n                    \"rsi\": config.LOG_DEFAULT_RSI,\n                    \"ema\": result[\"close\"].mean(),\n                    \"volatility\": config.LOG_DEFAULT_VOLATILITY,\n                    \"macd\": config.LOG_DEFAULT_MACD,\n                    \"macd_signal\": config.LOG_DEFAULT_MACD_SIGNAL,\n                    \"bollinger_upper\": result[\"close\"].mean(),\n                    \"bollinger_lower\": result[\"close\"].mean(),\n                    \"momentum\": config.LOG_DEFAULT_MOMENTUM,\n                    \"volume_trend\": config.LOG_DEFAULT_VOLUME_TREND,\n                    \"atr\": result[\"close\"].mean() * 0.01,\n                    \"vwap\": result[\"close\"].mean(),\n                    \"predicted_price\": result[\"close\"].mean(),\n                    \"grid_level\": 0,\n                    \"trades\": config.DEFAULT_TRADE_COUNT,\n                    \"high\": result[\"close\"].mean(),\n                    \"low\": result[\"close\"].mean(),\n                }\n            )\n        )\n\n        minutes_covered = (result[\"timestamp\"].max() - result[\"timestamp\"].min()).total_seconds() / 60\n        logger.info(f\"Trades cover {minutes_covered:.1f} minutes\")\n        if minutes_covered < target_minutes:\n            logger.warning(f\"Fetched only {minutes_covered:.1f} minutes of trade data, needed {target_minutes}\")\n\n        logger.info(f\"Fetched {len(result)} minutes of trade data\")\n        return result\n    except Exception as e:\n        logger.error(\n            f\"Error fetching trade counts: {e}, trade_counts state: {trade_counts.head().to_dict() if 'trade_counts' in locals() and not trade_counts.empty else 'N/A'}, DataFrame state: {df.head().to_dict() if 'df' in locals() and not df.empty else 'N/A'}\"\n        )\n        return None",
        "performance_issues": [
          "Complex comprehension - consider breaking down",
          "Complex comprehension - consider breaking down",
          "List operations in loop - consider list comprehension",
          "Complex comprehension - consider breaking down",
          "Long function - consider refactoring"
        ],
        "optimization_priority": 5,
        "estimated_impact": "medium"
      },
      "success": false,
      "original_performance": {
        "execution_time": 0.0,
        "memory_usage": null,
        "cpu_usage": null,
        "function_calls": 0,
        "profile_data": null
      },
      "optimized_performance": null,
      "improvement_ratio": null,
      "applied": false,
      "error": "LLM optimization failed: 'QwenAgentInterface' object has no attribute 'generate_targeted_optimization'"
    },
    {
      "candidate": {
        "function_name": "train_sklearn_predictor",
        "file_path": "C:\\Users\\805Sk\\GridBotWorkspace\\automated_debugging_strategy\\GridbotBackup.py",
        "line_start": 2436,
        "line_end": 2587,
        "code_snippet": "def train_sklearn_predictor(data, trade_data=None, lookback=80):\n    \"\"\"\n    Train separate RandomForestRegressor and SGDRegressor models with individual scalers.\n    Args:\n        data (pd.DataFrame): Historical OHLCV data.\n        trade_data (pd.DataFrame): Trade count data.\n        lookback (int): Number of lookback periods (default: 80).\n    Returns:\n        tuple: (rf_model, rf_scaler, sgd_model, sgd_scaler, lookback)\n    \"\"\"\n    try:\n        if data is None or data.empty:\n            logger.warning(\"Input data is None or empty\")\n            return None, None, None, None, lookback\n        if len(data) < lookback + 2:\n            logger.warning(f\"Insufficient data for sklearn training: {len(data)} samples, need {lookback + 2}\")\n            return None, None, None, None, lookback\n\n        # Prepare data\n        data = data.copy()\n        required_columns = [\"close\", \"volume\", \"rsi\", \"ema\", \"volatility\", \"high\", \"low\"]\n        missing_columns = [col for col in required_columns if col not in data.columns]\n        if missing_columns:\n            logger.error(f\"Missing required columns in data: {missing_columns}\")\n            return None, None, None, None, lookback\n\n        # Ensure timestamp is valid\n        if (\n            \"timestamp\" not in data.columns\n            or data[\"timestamp\"].isna().all()\n            or not pd.api.types.is_datetime64_any_dtype(data[\"timestamp\"])\n        ):\n            logger.warning(\"Invalid or missing timestamps in data, setting to current time\")\n            data[\"timestamp\"] = pd.Timestamp.now(tz=\"UTC\")\n        data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], errors=\"coerce\").dt.tz_convert(\"UTC\")\n        data[\"timestamp\"] = data[\"timestamp\"].fillna(pd.Timestamp.now(tz=\"UTC\"))\n\n        # Merge with trade_data if provided\n        if trade_data is not None and not trade_data.empty and \"timestamp\" in trade_data.columns:\n            trade_data = trade_data.copy()\n            trade_data[\"timestamp\"] = pd.to_datetime(trade_data[\"timestamp\"], errors=\"coerce\").dt.tz_convert(\"UTC\")\n            trade_data[\"timestamp\"] = trade_data[\"timestamp\"].fillna(pd.Timestamp.now(tz=\"UTC\"))\n            trade_data_for_merge = trade_data[[\"timestamp\", \"trades\"]].rename(columns={\"trades\": \"new_trades\"})\n            data = data.merge(trade_data_for_merge, on=\"timestamp\", how=\"left\")\n            data[\"trades\"] = data[\"new_trades\"].combine_first(data.get(\"trades\", 0))\n            data.drop(columns=[\"new_trades\"], inplace=True)\n            data[\"trades\"] = data[\"trades\"].fillna(0).astype(int)\n        else:\n            logger.info(\"No valid trade_data provided, setting trades to 0\")\n            data[\"trades\"] = data.get(\"trades\", 0).fillna(0).astype(int)\n\n        # Prepare 18 features\n        data[\"macd\"], data[\"macd_signal\"] = compute_macd(data[\"close\"])\n        data[\"bollinger_upper\"], data[\"bollinger_lower\"] = compute_bollinger(data[\"close\"])\n        data[\"momentum\"] = compute_momentum(data[\"close\"])\n        data[\"volume_trend\"] = compute_volume_trend(data[\"volume\"])\n        data[\"atr\"] = compute_atr(data[\"high\"], data[\"low\"], data[\"close\"])\n        data[\"vwap\"] = compute_vwap(data)\n        data = compute_additional_features(data)\n        features = [\n            \"close\", \"volume\", \"trades\", \"rsi\", \"ema\", \"volatility\", \"macd\", \"macd_signal\",\n            \"bollinger_upper\", \"bollinger_lower\", \"momentum\", \"volume_trend\", \"atr\", \"vwap\",\n            \"price_spread\", \"returns\", \"volume_change\", \"trade_intensity\"\n        ]\n        data[\"target\"] = data[\"close\"].shift(-1).fillna(data[\"close\"].iloc[-1])\n\n        # Validate and fill NaN values\n        data = data[features + [\"target\"]].fillna(\n            {\n                \"rsi\": 50.0,\n                \"ema\": data[\"close\"].mean(),\n                \"volatility\": 0.1,\n                \"macd\": 0.0,\n                \"macd_signal\": 0.0,\n                \"bollinger_upper\": data[\"close\"].mean(),\n                \"bollinger_lower\": data[\"close\"].mean(),\n                \"momentum\": 0.0,\n                \"volume_trend\": 0.0,\n                \"atr\": data[\"close\"].mean() * 0.01,\n                \"vwap\": data[\"close\"].mean(),\n                \"price_spread\": 0.0,\n                \"returns\": 0.0,\n                \"volume_change\": 0.0,\n                \"trade_intensity\": 0.0,\n                \"trades\": 0,\n                \"target\": data[\"close\"].mean(),\n            }\n        )\n\n        # Validate numeric features\n        for feature in features + [\"target\"]:\n            if not pd.api.types.is_numeric_dtype(data[feature]):\n                logger.error(f\"Feature {feature} contains non-numeric values\")\n                return None, None, None, None, lookback\n\n        # RF Model: Single time step features\n        rf_scaler = StandardScaler()\n        rf_X = data[features]\n        rf_y = data[\"target\"]\n        rf_X_scaled = rf_scaler.fit_transform(rf_X)\n        rf_model = RandomForestRegressor(\n            n_estimators=config.SKLEARN_N_ESTIMATORS,\n            max_depth=config.SKLEARN_MAX_DEPTH,\n            random_state=42,\n        )\n        rf_model.fit(rf_X_scaled, rf_y)\n        rf_train_mse = mean_squared_error(rf_y, rf_model.predict(rf_X_scaled))\n\n        # Save RF scaler\n        rf_scaler_file = \"client_sklearn_rf_scaler.pkl\"\n        if os.path.exists(rf_scaler_file):\n            os.remove(rf_scaler_file)\n            logger.info(f\"Removed existing RF scaler file: {rf_scaler_file}\")\n        joblib.dump(rf_scaler, rf_scaler_file)\n        logger.info(f\"Saved RF scaler to {rf_scaler_file}\")\n\n        # SGD Model: Sequence features\n        sgd_scaler = StandardScaler()\n        target_scaler = StandardScaler()\n        X, y = [], []\n        for i in range(lookback, len(data)):\n            X.append(data[features].iloc[i - lookback:i].values.flatten())\n            y.append(data[\"target\"].iloc[i])\n        if not X or len(X) < 20:\n            logger.warning(f\"Too few training samples for SGD: {len(X)}\")\n            return None, None, None, None, lookback\n        X = np.array(X)\n        y = np.array(y).reshape(-1, 1)\n        sgd_X_scaled = sgd_scaler.fit_transform(X)\n        y_scaled = target_scaler.fit_transform(y)\n        sgd_model = SGDRegressor(random_state=42, max_iter=1000, tol=1e-3)\n        sgd_model.fit(sgd_X_scaled, y_scaled.ravel())\n        y_pred_scaled = sgd_model.predict(sgd_X_scaled)\n        y_pred = target_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n        sgd_train_mse = mean_squared_error(y, y_pred)\n\n        # Save SGD scaler\n        sgd_scaler_file = \"client_sklearn_sgd_scaler.pkl\"\n        if os.path.exists(sgd_scaler_file):\n            os.remove(sgd_scaler_file)\n            logger.info(f\"Removed existing SGD scaler file: {sgd_scaler_file}\")\n        joblib.dump(sgd_scaler, sgd_scaler_file)\n        logger.info(f\"Saved SGD scaler to {sgd_scaler_file}\")\n\n        logger.info(\n            f\"Sklearn RF trained: Samples={len(rf_X)}, MSE={rf_train_mse:.6f}, Features={features}\\n\"\n            f\"Sklearn SGD trained: Samples={len(X)}, MSE={sgd_train_mse:.6f}, Features={lookback * len(features)}\"\n        )\n        return rf_model, rf_scaler, sgd_model, sgd_scaler, lookback\n    except Exception as e:\n        logger.error(f\"Error training Sklearn model: {e}\")\n        return None, None, None, None, lookback",
        "performance_issues": [
          "Complex comprehension - consider breaking down",
          "List operations in loop - consider list comprehension",
          "List operations in loop - consider list comprehension",
          "Long function - consider refactoring"
        ],
        "optimization_priority": 5,
        "estimated_impact": "medium"
      },
      "success": false,
      "original_performance": {
        "execution_time": 0.0,
        "memory_usage": null,
        "cpu_usage": null,
        "function_calls": 0,
        "profile_data": null
      },
      "optimized_performance": null,
      "improvement_ratio": null,
      "applied": false,
      "error": "LLM optimization failed: 'QwenAgentInterface' object has no attribute 'generate_targeted_optimization'"
    }
  ]
}